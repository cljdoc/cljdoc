{:namespaces
 [{:platform "clj",
   :name "next.jdbc.sql.builder",
   :doc
   "Some utility functions for building SQL strings.\n\nThese were originally private functions in `next.jdbc.sql` but\nthey may proof useful to developers who want to write their own\n'SQL sugar' functions, such as a database-specific `upsert!` etc.",
   :path "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.sql.builder"}
  {:platform "clj",
   :name "next.jdbc.plan",
   :doc
   "Some helper functions that make common operations with `next.jdbc/plan`\nmuch easier.",
   :path "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.plan"}
  {:platform "clj",
   :name "next.jdbc.sql",
   :doc
   "Some utility functions that make common operations easier by\nproviding some syntactic sugar over `execute!`/`execute-one!`.\n\nThis is intended to provide a minimal level of parity with\n`clojure.java.jdbc` (`insert!`, `insert-multi!`, `query`, `find-by-keys`,\n`get-by-id`, `update!`, and `delete!`).\n\nFor anything more complex, use a library like HoneySQL\nhttps://github.com/jkk/honeysql to generate SQL + parameters.\n\nThe following options are supported:\n* `:table-fn` -- specify a function used to convert table names (strings)\n    to SQL entity names -- see the `next.jdbc.quoted` namespace for the\n    most common quoting strategy functions,\n* `:column-fn` -- specify a function used to convert column names (strings)\n    to SQL entity names -- see the `next.jdbc.quoted` namespace for the\n    most common quoting strategy functions.\n\nIn addition, `find-by-keys` supports `:order-by` to add an `ORDER BY`\nclause to the generated SQL.",
   :path "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.sql"}
  {:platform "clj",
   :name "next.jdbc.types",
   :doc
   "Provides convenience functions for wrapping values you pass into SQL\noperations that have per-instance implementations of `SettableParameter`\nso that `.setObject()` is called with the appropriate `java.sql.Types` value.",
   :path "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.types"}
  {:platform "clj",
   :name "next.jdbc.connection",
   :doc
   "Standard implementations of `get-datasource` and `get-connection`.\n\nAlso provides `dbtypes` as a map of all known database types, and\nthe `->pool` and `component` functions for creating pooled datasource\nobjects.",
   :path "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.connection"}
  {:platform "clj",
   :name "next.jdbc.result-set",
   :doc
   "An implementation of `ResultSet` handling functions.\n\nDefines the following protocols:\n* `DatafiableRow` -- for turning a row into something datafiable\n* `ReadableColumn` -- to read column values by label or index\n* `RowBuilder` -- for materializing a row\n* `ResultSetBuilder` -- for materializing a result set\n\nA broad range of result set builder implementation functions are provided.\n\nAlso provides the default implementations for `Executable` and\nthe default `datafy`/`nav` behavior for rows from a result set.\n\nSee also https://cljdoc.org/d/com.github.seancorfield/next.jdbc/CURRENT/api/next.jdbc.date-time\nfor implementations of `ReadableColumn` that provide automatic\nconversion of some SQL data types to Java Time objects.",
   :path "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.result-set"}
  {:platform "clj",
   :name "next.jdbc.specs",
   :doc
   "Specs for the core API of next.jdbc.\n\nThe functions from `next.jdbc`, `next.jdbc.sql`, and `next.jdbc.prepare`\nhave specs here.\n\nJust `:args` are spec'd. These specs are intended to aid development\nwith `next.jdbc` by catching simple errors in calling the library.\nThe `connectable` argument is currently just `any?` but both\n`get-datasource` and `get-connection` have stricter specs. If you\nextend `Sourceable` or `Connectable`, those specs will likely be too strict.\n\nIn addition, there is an `instrument` function that provides a simple\nway to instrument all of the `next.jdbc` functions, and `unstrument`\nto undo that.",
   :path "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.specs"}
  {:platform "clj",
   :name "next.jdbc.prepare",
   :doc
   "Mostly an implementation namespace for how `PreparedStatement` objects are\ncreated by the next generation java.jdbc library.\n\n`set-parameters` is public and may be useful if you have a `PreparedStatement`\nthat you wish to reuse and (re)set the parameters on it.\n\nDefines the `SettableParameter` protocol for converting Clojure values\nto database-specific values.\n\nSee also https://cljdoc.org/d/com.github.seancorfield/next.jdbc/CURRENT/api/next.jdbc.date-time\nfor implementations of `SettableParameter` that provide automatic\nconversion of Java Time objects to SQL data types.\n\nSee also https://cljdoc.org/d/com.github.seancorfield/next.jdbc/CURRENT/api/next.jdbc.types\nfor `as-xxx` functions that provide per-instance implementations of\n`SettableParameter` for each of the standard `java.sql.Types` values.",
   :path "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.prepare"}
  {:platform "clj",
   :name "next.jdbc.transaction",
   :doc
   "Implementation of SQL transaction logic.\n\nIn general, you cannot nest transactions. `clojure.java.jdbc` would\nignore any attempt to create a nested transaction, even tho' some\ndatabases do support it. `next.jdbc` allows you to call `with-transaction`\neven while you are inside an active transaction, but the behavior may\nvary across databases and the commit or rollback boundaries may not be\nwhat you expect. In order to avoid two transactions constructed on the\nsame connection from interfering with each other, `next.jdbc` locks on\nthe `Connection` object (this prevents concurrent transactions on separate\nthreads from interfering but will cause deadlock on a single thread --\nso beware).\n\nConsequently, this namespace exposes a dynamic variable, `*nested-tx*`,\nwhich can be used to vary the behavior when an attempt is made to start\na transaction when you are already inside a transaction.",
   :path "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.transaction"}
  {:platform "clj",
   :name "next.jdbc.optional",
   :doc
   "Builders that treat NULL SQL values as 'optional' and omit the\ncorresponding keys from the Clojure hash maps for the rows.",
   :path "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.optional"}
  {:platform "clj",
   :name "next.jdbc.quoted",
   :doc
   "Provides functions for use with the `:table-fn` and `:column-fn` options\nthat define how SQL entities should be quoted in strings constructed\nfrom Clojure data.",
   :path "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.quoted"}
  {:platform "clj",
   :name "next.jdbc.datafy",
   :doc
   "This namespace provides datafication of several JDBC object types,\nall within the `java.sql` package:\n\n* `Connection` -- datafies as a bean.\n* `DatabaseMetaData` -- datafies as a bean; six properties\n      are navigable to produce fully-realized datafiable result sets.\n* `ParameterMetaData` -- datafies as a vector of parameter descriptions.\n* `ResultSet` -- datafies as a bean; if the `ResultSet` has an associated\n      `Statement` and that in turn has an associated `Connection` then an\n      additional key of `:rows` is provided which is a datafied result set,\n      from `next.jdbc.result-set/datafiable-result-set` with default options.\n      This is provided as a convenience, purely for datafication of other\n      JDBC data types -- in normal `next.jdbc` usage, result sets are\n      datafied under full user control.\n* `ResultSetMetaData` -- datafies as a vector of column descriptions.\n* `Statement` -- datafies as a bean.\n\nBecause different database drivers may throw `SQLException` for various\nunimplemented or unavailable properties on objects in various states,\nthe default behavior is to return those exceptions using the `:qualify`\noption for `clojure.java.data/from-java-shallow`, so for a property\n`:foo`, if its corresponding getter throws an exception, it would instead\nbe returned as `:foo/exception`. This behavior can be overridden by\n`binding` `next.jdbc.datafy/*datafy-failure*` to any of the other options\nsupported: `:group`, `:omit`, or `:return`. See the `clojure.java.data`\ndocumentation for more details.",
   :path "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.datafy"}
  {:platform "clj",
   :name "next.jdbc.protocols",
   :doc
   "This is the extensible core of the next generation java.jdbc library.\n\n* `Sourceable` -- for producing `javax.sql.DataSource` objects,\n* `Connectable` -- for producing new `java.sql.Connection` objects,\n* `Executable` -- for executing SQL operations,\n* `Preparable` -- for producing new `java.sql.PreparedStatement` objects,\n* `Transactable` -- for executing SQL operations transactionally.",
   :path "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.protocols"}
  {:platform "clj",
   :name "next.jdbc.date-time",
   :doc
   "Optional namespace that extends `next.jdbc.prepare/SettableParameter`\nto various date/time types so that they will all be treated as SQL\ntimestamps (which also supports date and time column types) and has\nfunctions to extend `next.jdbc.result-set/ReadableColumn`.\n\nSimply requiring this namespace will extend the `SettableParameter` protocol\nto the four types listed below.\n\nIn addition, there are several `read-as-*` functions here that will\nextend `next.jdbc.result-set/ReadableColumn` to allow `java.sql.Date`\nand `java.sql.Timestamp` columns to be read as (converted to) various\nJava Time types automatically. The expectation is that you will call at\nmost one of these, at application startup, to enable the behavior you want.\n\nDatabase support for Java Time:\n* H2 and SQLite support conversion of Java Time (`Instant`, `LocalDate`,\n  `LocalDateTime`) out of the box,\n* Nearly all databases support conversion of `java.util.Date` out of\n  the box -- except PostgreSQL apparently!\n\nTypes supported by this namespace:\n* `java.time.Instant`\n* `java.time.LocalDate`\n* `java.time.LocalDateTime`\n* `java.util.Date` -- mainly for PostgreSQL\n\nPostgreSQL does not seem able to convert `java.util.Date` to a SQL\ntimestamp by default (every other database can!) so you'll probably\nneed to require this namespace, even if you don't use Java Time, when\nworking with PostgreSQL.",
   :path "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.date-time"}
  {:platform "clj",
   :name "next.jdbc",
   :doc
   "The public API of the next generation java.jdbc library.\n\nThe basic building blocks are the `java.sql`/`javax.sql` classes:\n* `DataSource` -- something to get connections from,\n* `Connection` -- an active connection to the database,\n* `PreparedStatement` -- SQL and parameters combined, from a connection,\n\nand the following functions and a macro:\n* `get-datasource` -- given a hash map describing a database or a JDBC\n    connection string, construct a `javax.sql.DataSource` and return it,\n* `get-connection` -- given a connectable, obtain a new `java.sql.Connection`\n    from it and return that,\n* `plan` -- given a connectable and SQL + parameters or a statement,\n    return a reducible that, when reduced will execute the SQL and consume\n    the `ResultSet` produced,\n* `execute!` -- given a connectable and SQL + parameters or a statement,\n    execute the SQL, consume the `ResultSet` produced, and return a vector\n    of hash maps representing the rows (@1); this can be datafied to allow\n    navigation of foreign keys into other tables (either by convention or\n    via a schema definition),\n* `execute-one!` -- given a connectable and SQL + parameters or a statement,\n    execute the SQL, consume the first row of the `ResultSet` produced, and\n    return a hash map representing that row; this can be datafied to allow\n    navigation of foreign keys into other tables (either by convention or\n    via a schema definition),\n* `execute-batch!` -- given a `PreparedStatement` and groups of parameters,\n    execute the statement in batch mode (via `.executeBatch`); given a\n    connectable, a SQL string, and groups of parameters, create a new\n    `PreparedStatement` from the SQL and execute it in batch mode.\n* `prepare` -- given a `Connection` and SQL + parameters, construct a new\n    `PreparedStatement`; in general this should be used with `with-open`,\n* `transact` -- the functional implementation of `with-transaction`,\n* `with-transaction` -- execute a series of SQL operations within a transaction.\n\n@1 result sets are built, by default, as vectors of hash maps, containing\n    qualified keywords as column names, but the row builder and result set\n    builder machinery is open and alternatives are provided to produce\n    unqualified keywords as column names, and to produce a vector the\n    column names followed by vectors of column values for each row, and\n    lower-case variants of each.\n\nThe following options are supported wherever a `Connection` is created:\n* `:auto-commit` -- either `true` or `false`,\n* `:read-only` -- either `true` or `false`,\n* `:connection` -- a hash map of camelCase properties to set, via reflection,\n    on the `Connection` object after it is created.\n\nThe following options are supported wherever a `Statement` or\n`PreparedStatement` is created:\n* `:concurrency` -- `:read-only`, `:updatable`,\n* `:cursors` -- `:close`, `:hold`\n* `:fetch-size` -- the fetch size value,\n* `:max-rows` -- the maximum number of rows to return,\n* `:result-type` -- `:forward-only`, `:scroll-insensitive`, `:scroll-sensitive`,\n* `:timeout` -- the query timeout,\n* `:statement` -- a hash map of camelCase properties to set, via reflection,\n    on the `Statement` or `PreparedStatement` object after it is created.\n\nIn addition, wherever a `PreparedStatement` is created, you may specify:\n* `:return-keys` -- either `true` or a vector of key names to return.",
   :path "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc"}],
 :defs
 [{:platform "clj",
   :type :var,
   :namespace "next.jdbc.types",
   :name "as-numeric",
   :arglists ([obj]),
   :doc
   "Wrap a Clojure value in a thunk with metadata to implement `set-parameter`\nso that `.setObject()` is called with the `java.sql.Types/NUMERIC` SQL type.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.types#as-numeric"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.specs",
   :name "instrument",
   :arglists ([]),
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.specs#instrument"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.types",
   :name "as-sqlxml",
   :arglists ([obj]),
   :doc
   "Wrap a Clojure value in a thunk with metadata to implement `set-parameter`\nso that `.setObject()` is called with the `java.sql.Types/SQLXML` SQL type.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.types#as-sqlxml"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.result-set",
   :name "as-unqualified-lower-arrays",
   :arglists ([rs opts]),
   :doc
   "Given a `ResultSet` and options, return a `RowBuilder` / `ResultSetBuilder`\nthat produces a vector of simple, lower-case column names followed by\nvectors of row values.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.result-set#as-unqualified-lower-arrays"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc",
   :name "plan",
   :arglists
   ([stmt] [connectable sql-params] [connectable sql-params opts]),
   :doc
   "General SQL execution function (for working with result sets).\n\nReturns a reducible that, when reduced, runs the SQL and yields the result.\nThe reducible is also foldable (in the `clojure.core.reducers` sense) but\nsee the **Tips & Tricks** section of the documentation for some important\ncaveats about that.\n\nCan be called on a `PreparedStatement`, a `Connection`, or something that can\nproduce a `Connection` via a `DataSource`.\n\nYour reducing function can read columns by name (string or simple keyword)\nfrom each row of the underlying `ResultSet` without realizing the row as\na Clojure hash map. `select-keys` can also be used without realizing the row.\nOperations that imply an actual Clojure data structure (such as `assoc`,\n`dissoc`, `seq`, `keys`, `vals`, etc) will realize the row into a hash map\nusing the supplied `:builder-fn` (or `as-maps` by default).\n\nIf your reducing function needs to produce a hash map without calling a\nfunction that implicitly realizes the row, you can call:\n\n`(next.jdbc.result-set/datafiable-row row connectable opts)`\n\npassing in the current row (passed to the reducing function), a `connectable`,\nand an `opts` hash map. These can be the same values that you passed to `plan`\n(or they can be different, depending on how you want the row to be built,\nand how you want any subsequent lazy navigation to be handled).",
   :members (),
   :path "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc#plan"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.result-set",
   :name "as-unqualified-lower-maps",
   :arglists ([rs opts]),
   :doc
   "Given a `ResultSet` and options, return a `RowBuilder` / `ResultSetBuilder`\nthat produces bare vectors of hash map rows, with simple, lower-case keys.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.result-set#as-unqualified-lower-maps"}
  {:platform "clj",
   :type :protocol,
   :namespace "next.jdbc.result-set",
   :name "ResultSetBuilder",
   :doc
   "Protocol for building result sets in various representations.\n\nDefault implementations for building vectors of hash maps and vectors of\ncolumn names and row values: `MapResultSetBuilder` & `ArrayResultSetBuilder`",
   :members
   ({:type :var,
     :name ->rs,
     :arglists ([_]),
     :doc "Called to create the basis of the result set.\n"}
    {:type :var,
     :name rs!,
     :arglists ([_ rs]),
     :doc "Called to finalize the result set once it is complete.\n"}
    {:type :var,
     :name with-row,
     :arglists ([_ rs row]),
     :doc "Called with the result set and the row to be added.\n"}),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.result-set#ResultSetBuilder"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.sql",
   :name "delete!",
   :arglists
   ([connectable table where-params]
    [connectable table where-params opts]),
   :doc
   "Syntactic sugar over `execute-one!` to make certain common deletes easier.\n\nGiven a connectable object, a table name, and either a hash map of columns\nand values to search on or a vector of a SQL where clause and parameters,\nperform a delete on the table.",
   :members (),
   :path "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.sql#delete!"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.plan",
   :name "select!",
   :arglists
   ([connectable cols sql-params] [connectable cols sql-params opts]),
   :doc
   "Execute the SQL and params using `next.jdbc/plan` and (by default)\nreturn a vector of rows with just the selected columns.\n\n`(plan/select! ds [:id :name] [\"select * from table\"])`\n\nIf the `cols` argument is a vector of columns to select, then it is\napplied as:\n\n`(into [] (map #(select-keys % cols)) (jdbc/plan ...))`\n\nOtherwise, the `cols` argument is used as a function and mapped over\nthe raw result set as:\n\n`(into [] (map cols) (jdbc/plan ...))`\n\nThe usual caveats apply about operations on a raw result set that\ncan be done without realizing the whole row.\n\nNote: this allows for the following usage, which returns a vector\nof all the values for a single column:\n\n`(plan/select! ds :id (jdbc/plan ...))`\n\nThe result is a vector by default, but can be changed using the\n`:into` option to provide the initial data structure into which\nthe selected columns are poured, e.g., `:into #{}`",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.plan#select!"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.result-set",
   :name "as-unqualified-modified-maps",
   :arglists ([rs opts]),
   :doc
   "Given a `ResultSet` and options, return a `RowBuilder` / `ResultSetBuilder`\nthat produces bare vectors of hash map rows, with simple, modified keys.\n\nRequires the `:label-fn` option.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.result-set#as-unqualified-modified-maps"}
  {:platform "clj",
   :type :protocol,
   :namespace "next.jdbc.result-set",
   :name "DatafiableRow",
   :doc
   "Protocol for making rows datafiable and therefore navigable.\n\nThe default implementation just adds metadata so that `datafy` can be\ncalled on the row, which will produce something that `nav` can be called\non, to lazily navigate through foreign key relationships into other tables.\n\nIf `datafiable-row` is called when reducing the result set produced by\n`next.jdbc/plan`, the row is fully-realized from the `ResultSet`\nfirst, using the `:builder-fn` (or `as-maps` by default).",
   :members
   ({:type :var,
     :name datafiable-row,
     :arglists ([this connectable opts]),
     :doc
     "Produce a datafiable representation of a row from a `ResultSet`.\n"}),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.result-set#DatafiableRow"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.result-set",
   :name "reducible-result-set",
   :arglists ([rs] [rs opts]),
   :doc
   "Given a `ResultSet`, return an `IReduceInit` that can be reduced. An\noptions hash map may be provided.\n\nYou are responsible for ensuring the `Connection` for this `ResultSet`\nremains open until the reduction is complete!",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.result-set#reducible-result-set"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.types",
   :name "as-double",
   :arglists ([obj]),
   :doc
   "Wrap a Clojure value in a thunk with metadata to implement `set-parameter`\nso that `.setObject()` is called with the `java.sql.Types/DOUBLE` SQL type.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.types#as-double"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.optional",
   :name "as-lower-maps",
   :arglists ([rs opts]),
   :doc
   "Given a `ResultSet` and options, return a `RowBuilder` / `ResultSetBuilder`\nthat produces bare vectors of hash map rows, with lower-case keys and nil\ncolumns omitted.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.optional#as-lower-maps"}
  {:platform "clj",
   :type :macro,
   :namespace "next.jdbc",
   :name "with-transaction",
   :arglists ([[sym transactable opts] & body]),
   :doc
   "Given a transactable object, gets a connection and binds it to `sym`,\nthen executes the `body` in that context, committing any changes if the body\ncompletes successfully, otherwise rolling back any changes made.\n\nThe options map supports:\n* `:isolation` -- `:none`, `:read-committed`, `:read-uncommitted`,\n    `:repeatable-read`, `:serializable`,\n* `:read-only` -- `true` / `false`,\n* `:rollback-only` -- `true` / `false`.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc#with-transaction"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.quoted",
   :name "mysql",
   :arglists ([s]),
   :doc "MySQL `quoting`\n",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.quoted#mysql"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.connection",
   :name "dbtypes",
   :doc
   "A map of all known database types (including aliases) to the class name(s)\nand port that `next.jdbc` supports out of the box. For databases that have\nnon-standard prefixes for the `:dbname` and/or `:host` values in the JDBC\nstring, this table includes `:dbname-separator` and/or `:host-prefix`. The\ndefault prefix for `:dbname` is either `/` or `:` and for `:host` it is `//`.\nFor local databases, with no `:host`/`:port` segment in their JDBC URL, a\nvalue of `:none` is provided for `:host` in this table.\n\nFor known database types, you can use `:dbtype` (and omit `:classname`).\n\nIf you want to use a database that is not in this list, you can specify\na new `:dbtype` along with the class name of the JDBC driver in `:classname`.\nYou will also need to specify `:port`. For example:\n\n   `{:dbtype \"acme\" :classname \"com.acme.JdbcDriver\" ...}`\n\nThe value of `:dbtype` should be the string that the driver is associated\nwith in the JDBC URL, i.e., the value that comes between the `jdbc:`\nprefix and the `://<host>...` part. In the above example, the JDBC URL\nthat would be generated would be `jdbc:acme://<host>:<port>/<dbname>`.\n\nIf you want `next.jdbc` to omit the host/port part of the URL, specify\n`:host :none`, which would produce a URL like: `jdbc:acme:<dbname>`,\nwhich allows you to work with local databases (or drivers that do not\nneed host/port information).\n\nThe default prefix for the host name (or IP address) is `//`. You\ncan override this via the `:host-prefix` option.\n\nThe default separator between the host/port and the database name is `/`.\nThe default separator between the subprotocol and the database name,\nfor local databases with no host/port, is `:`. You can override this\nvia the `:dbname-separator` option.\n\nJDBC drivers are not provided by `next.jdbc` -- you need to specify the\ndriver(s) you need as additional dependencies in your project. For\nexample:\n\n   `[com.acme/jdbc \"1.2.3\"] ; lein/boot`\n\nor:\n\n   `com.acme/jdbc {:mvn/version \"1.2.3\"} ; CLI/deps.edn`\n\nNote: the `:classname` value can be a string or a vector of strings. If\na vector of strings is provided, an attempt will be made to load each\nnamed class in order, until one succeeds. This allows for a given `:dbtype`\nto be used with different versions of a JDBC driver, if the class name\nhas changed over time (such as with MySQL).",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.connection#dbtypes"}
  {:platform "clj",
   :type :protocol,
   :namespace "next.jdbc.protocols",
   :name "Preparable",
   :doc
   "Protocol for producing a new `java.sql.PreparedStatement` that should\nbe closed after use. Can be used by `Executable` functions.\n\nImplementation is provided for `Connection` only.",
   :members
   ({:type :var,
     :name prepare,
     :arglists ([this sql-params opts]),
     :doc
     "Produce a new `java.sql.PreparedStatement` for use with `with-open`.\n"}),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.protocols#Preparable"}
  {:platform "clj",
   :type :protocol,
   :namespace "next.jdbc.protocols",
   :name "Sourceable",
   :doc
   "Protocol for producing a `javax.sql.DataSource`.\n\nImplementations are provided for strings, hash maps (`db-spec` structures),\nand also a `DataSource` (which just returns itself).\n\nExtension via metadata is supported.",
   :members
   ({:type :var,
     :name get-datasource,
     :arglists ([this]),
     :doc "Produce a `javax.sql.DataSource`.\n"}),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.protocols#Sourceable"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.sql",
   :name "insert!",
   :arglists
   ([connectable table key-map] [connectable table key-map opts]),
   :doc
   "Syntactic sugar over `execute-one!` to make inserting hash maps easier.\n\nGiven a connectable object, a table name, and a data hash map, inserts the\ndata as a single row in the database and attempts to return a map of generated\nkeys.",
   :members (),
   :path "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.sql#insert!"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.connection",
   :name "jdbc-url",
   :arglists ([db-spec]),
   :doc
   "Given a database spec (as a hash map), return a JDBC URL with all the\n  attributes added to the query string. The result is suitable for use in\n  calls to `->pool` and `component` as the `:jdbcUrl` key in the parameter\n  map for the connection pooling library.\n\n  This allows you to build a connection-pooled datasource that needs\n  additional settings that the pooling library does not support, such as\n  `:serverTimezone`:\n\n```clojure\n  (def db-spec {:dbtype .. :dbname .. :user .. :password ..\n                :serverTimezone \"UTC\"})\n  (def ds (next.jdbc.connection/->pool\n           HikariCP {:jdbcUrl (next.jdbc.connection/jdbc-url db-spec)\n                     :maximumPoolSize 15}))\n```\n\n  This also clearly separates the attributes that should be part of the\n  JDBC URL from the attributes that should be configured on the pool.\n\n  Since JDBC drivers can handle URL encoding differently, if you are\n  trying to pass attributes that might need encoding, you should make\n  sure they are properly URL-encoded as values in the database spec hash map.\n  This function does **not** attempt to URL-encode values for you!",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.connection#jdbc-url"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.types",
   :name "as-float",
   :arglists ([obj]),
   :doc
   "Wrap a Clojure value in a thunk with metadata to implement `set-parameter`\nso that `.setObject()` is called with the `java.sql.Types/FLOAT` SQL type.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.types#as-float"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.result-set",
   :name "get-lower-column-names",
   :arglists ([rsmeta opts]),
   :doc
   "Given `ResultSetMetaData`, return a vector of lower-case column names, each\nqualified by the table from which it came.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.result-set#get-lower-column-names"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc",
   :name "prepare",
   :arglists ([connection sql-params] [connection sql-params opts]),
   :doc
   "Given a connection to a database, and a vector containing SQL and any\n  parameters it needs, return a new `PreparedStatement`.\n\n  In general, this should be used via `with-open`:\n\n```clojure\n  (with-open [stmt (prepare spec sql-params opts)]\n    (run-some-ops stmt))\n```\n\n  See the list of options above (in the namespace docstring) for what can\n  be passed to prepare.",
   :members (),
   :path "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc#prepare"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.types",
   :name "as-smallint",
   :arglists ([obj]),
   :doc
   "Wrap a Clojure value in a thunk with metadata to implement `set-parameter`\nso that `.setObject()` is called with the `java.sql.Types/SMALLINT` SQL type.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.types#as-smallint"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.sql.builder",
   :name "for-query",
   :arglists ([table where-params opts]),
   :doc
   "Given a table name and either a hash map of column names and values or a\nvector of SQL (where clause) and its parameters, return a vector of the\nfull `SELECT` SQL string and its parameters.\n\nApplies any `:table-fn` / `:column-fn` supplied in the options.\n\nHandles pagination options (`:top`, `:limit` / `:offset`, or `:offset` /\n`:fetch`) for SQL Server, MySQL / SQLite, ANSI SQL respectively.\n\nBy default, this selects all columns, but if the `:columns` option is\npresent the select will only be those columns.\n\nIf `:suffix` is provided in `opts`, that string is appended to the\n`SELECT ...` statement.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.sql.builder#for-query"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.types",
   :name "as-distinct",
   :arglists ([obj]),
   :doc
   "Wrap a Clojure value in a thunk with metadata to implement `set-parameter`\nso that `.setObject()` is called with the `java.sql.Types/DISTINCT` SQL type.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.types#as-distinct"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.result-set",
   :name "as-modified-arrays",
   :arglists ([rs opts]),
   :doc
   "Given a `ResultSet` and options, return a `RowBuilder` / `ResultSetBuilder`\nthat produces a vector of modified column names followed by vectors of\nrow values.\n\nRequires both the `:qualifier-fn` and `:label-fn` options.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.result-set#as-modified-arrays"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.types",
   :name "as-other",
   :arglists ([obj]),
   :doc
   "Wrap a Clojure value in a thunk with metadata to implement `set-parameter`\nso that `.setObject()` is called with the `java.sql.Types/OTHER` SQL type.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.types#as-other"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.types",
   :name "as-binary",
   :arglists ([obj]),
   :doc
   "Wrap a Clojure value in a thunk with metadata to implement `set-parameter`\nso that `.setObject()` is called with the `java.sql.Types/BINARY` SQL type.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.types#as-binary"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.optional",
   :name "as-unqualified-modified-maps",
   :arglists ([rs opts]),
   :doc
   "Given a `ResultSet` and options, return a `RowBuilder` / `ResultSetBuilder`\nthat produces bare vectors of hash map rows, with simple, modified keys\nand nil columns omitted.\n\nRequires the `:label-fn` option.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.optional#as-unqualified-modified-maps"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.types",
   :name "as-nclob",
   :arglists ([obj]),
   :doc
   "Wrap a Clojure value in a thunk with metadata to implement `set-parameter`\nso that `.setObject()` is called with the `java.sql.Types/NCLOB` SQL type.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.types#as-nclob"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.types",
   :name "as-tinyint",
   :arglists ([obj]),
   :doc
   "Wrap a Clojure value in a thunk with metadata to implement `set-parameter`\nso that `.setObject()` is called with the `java.sql.Types/TINYINT` SQL type.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.types#as-tinyint"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.types",
   :name "as-rowid",
   :arglists ([obj]),
   :doc
   "Wrap a Clojure value in a thunk with metadata to implement `set-parameter`\nso that `.setObject()` is called with the `java.sql.Types/ROWID` SQL type.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.types#as-rowid"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc",
   :name "unqualified-snake-kebab-opts",
   :doc
   "A hash map of options that will convert Clojure identifiers to\nsnake_case SQL entities (`:table-fn`, `:column-fn`), and will convert\nSQL entities to unqualified kebab-case Clojure identifiers (`:builder-fn`).",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc#unqualified-snake-kebab-opts"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.quoted",
   :name "schema",
   :arglists ([quoting]),
   :doc
   "Given a quoting function, return a new quoting function that will\n  process schema-qualified names by quoting each segment:\n```clojure\n  (mysql (name :foo.bar)) ;=> `foo.bar`\n  ((schema mysql) (name :foo.bar)) ;=> `foo`.`bar`\n```",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.quoted#schema"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.types",
   :name "as-longnvarchar",
   :arglists ([obj]),
   :doc
   "Wrap a Clojure value in a thunk with metadata to implement `set-parameter`\nso that `.setObject()` is called with the `java.sql.Types/LONGNVARCHAR` SQL type.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.types#as-longnvarchar"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.sql.builder",
   :name "as-cols",
   :arglists ([cols opts]),
   :doc
   "Given a sequence of raw column names, return a string of all the\nformatted column names.\n\nIf a raw column name is a keyword, apply `:column-fn` to its name,\nfrom the options if present.\n\nIf a raw column name is a vector pair, treat it as an expression with\nan alias. If the first item is a keyword, apply `:column-fn` to its\nname, else accept it as-is. The second item should be a keyword and\nthat will have `:column-fn` applied to its name.\n\nThis allows columns to be specified as simple names, e.g., `:foo`,\nas simple aliases, e.g., `[:foo :bar]`, or as expressions with an\nalias, e.g., `[\"count(*)\" :total]`.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.sql.builder#as-cols"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.result-set",
   :name "builder-adapter",
   :arglists ([builder-fn column-by-index-fn]),
   :doc
   "Given any builder function (e.g., `as-lower-maps`) and a column reading\nfunction, return a new builder function that uses that column reading\nfunction instead of `.getObject` and `read-column-by-index` so you can\noverride the default behavior.\n\nThe default column-by-index-fn behavior would be equivalent to:\n\n    (defn default-column-by-index-fn\n      [builder ^ResultSet rs ^Integer i]\n      (read-column-by-index (.getObject rs i) (:rsmeta builder) i))\n\nYour column-by-index-fn can use the result set metadata `(:rsmeta builder)`\nand/or the (processed) column name `(nth (:cols builder) (dec i))` to\ndetermine whether to call `.getObject` or some other method to read the\ncolumn's value, and can choose whether or not to use the `ReadableColumn`\nprotocol-based value processor (and could add metadata to the value to\nsatisfy that protocol on a per-instance basis).",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.result-set#builder-adapter"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.types",
   :name "as-date",
   :arglists ([obj]),
   :doc
   "Wrap a Clojure value in a thunk with metadata to implement `set-parameter`\nso that `.setObject()` is called with the `java.sql.Types/DATE` SQL type.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.types#as-date"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.sql.builder",
   :name "for-order",
   :arglists ([order-by opts]),
   :doc "Given an `:order-by` vector, return an `ORDER BY` clause.\n",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.sql.builder#for-order"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc",
   :name "execute-one!",
   :arglists
   ([stmt] [connectable sql-params] [connectable sql-params opts]),
   :doc
   "General SQL execution function that returns just the first row of a result.\nFor any DDL or SQL statement that will return just an update count, this is\nthe preferred function to use.\n\nCan be called on a `PreparedStatement`, a `Connection`, or something that can\nproduce a `Connection` via a `DataSource`.\n\nNote: although this only returns the first row of a result set, it does not\nplace any limit on the result of the SQL executed.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc#execute-one!"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.specs",
   :name "unstrument",
   :arglists ([]),
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.specs#unstrument"}
  {:platform "clj",
   :type :protocol,
   :namespace "next.jdbc.prepare",
   :name "SettableParameter",
   :doc
   "Protocol for setting SQL parameters in statement objects, which\ncan convert from Clojure values. The default implementation just\ncalls `.setObject` on the parameter value. It can be extended to\nuse other methods of `PreparedStatement` to convert and set parameter\nvalues. Extension via metadata is supported.",
   :members
   ({:type :var,
     :name set-parameter,
     :arglists ([val stmt ix]),
     :doc
     "Convert a Clojure value into a SQL value and store it as the ix'th\nparameter in the given SQL statement object."}),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.prepare#SettableParameter"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.sql",
   :name "get-by-id",
   :arglists
   ([connectable table pk]
    [connectable table pk opts]
    [connectable table pk pk-name opts]),
   :doc
   "Syntactic sugar over `execute-one!` to make certain common queries easier.\n\nGiven a connectable object, a table name, and a primary key value, returns\na hash map of the first row that matches.\n\nBy default, the primary key is assumed to be `id` but that can be overridden\nin the five-argument call.\n\nAs with `find-by-keys`, you can specify `:columns` to return just a\nsubset of the columns in the returned row.\n\nTechnically, this also supports `:order-by`, `:top`, `:limit`, `:offset`,\nand `:fetch` -- like `find-by-keys` -- but they don't make as much sense\nhere since only one row is ever returned.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.sql#get-by-id"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.types",
   :name "as-null",
   :arglists ([obj]),
   :doc
   "Wrap a Clojure value in a thunk with metadata to implement `set-parameter`\nso that `.setObject()` is called with the `java.sql.Types/NULL` SQL type.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.types#as-null"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.result-set",
   :name "datafiable-result-set",
   :arglists ([rs] [rs conn-or-opts] [rs connectable opts]),
   :doc
   "Given a ResultSet, a connectable, and an options hash map, return a fully\nrealized, datafiable result set per the `:builder-fn` option passed in.\nIf no `:builder-fn` option is provided, `as-maps` is used as the default.\n\nThe connectable and the options can both be omitted. If connectable is\nomitted, `nil` is used and no foreign key navigation will be available\nfor any datafied result. If you want to pass a hash map as the connectable,\nyou must also pass an options hash map.\n\nThis can be used to process regular result sets or metadata result sets.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.result-set#datafiable-result-set"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.result-set",
   :name "as-unqualified-kebab-maps",
   :arglists ([rs opts]),
   :doc
   "Given a `ResultSet` and options, return a `RowBuilder` / `ResultSetBuilder`\nthat produces bare vectors of hash map rows, with simple, kebab-case keys.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.result-set#as-unqualified-kebab-maps"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.optional",
   :name "as-maps-adapter",
   :arglists ([builder-fn column-reader]),
   :doc
   "Given a map builder function (e.g., `as-lower-maps`) and a column reading\nfunction, return a new builder function that uses that column reading\nfunction instead of `.getObject` so you can override the default behavior.\n\nThis adapter omits SQL NULL values, even if the underlying builder does not.\n\nThe default column-reader behavior would be equivalent to:\n\n    (defn default-column-reader\n      [^ResultSet rs ^ResultSetMetaData rsmeta ^Integer i]\n      (.getObject rs i))\n\nYour column-reader can use the result set metadata to determine whether\nto call `.getObject` or some other method to read the column's value.\n\n`read-column-by-index` is still called on the result of that read, if\nit is not `nil`.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.optional#as-maps-adapter"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.types",
   :name "as-ref-cursor",
   :arglists ([obj]),
   :doc
   "Wrap a Clojure value in a thunk with metadata to implement `set-parameter`\nso that `.setObject()` is called with the `java.sql.Types/REF_CURSOR` SQL type.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.types#as-ref-cursor"}
  {:platform "clj",
   :type :protocol,
   :namespace "next.jdbc.protocols",
   :name "Executable",
   :doc
   "Protocol for executing SQL operations.\n\nImplementations are provided for `Connection`, `DataSource`,\n`PreparedStatement`, and `Object`, on the assumption that an `Object` can be\nturned into a `DataSource` and therefore used to get a `Connection`.",
   :members
   ({:type :var,
     :name -execute,
     :arglists ([this sql-params opts]),
     :doc
     "Produce a 'reducible' that, when reduced, executes the SQL and\nprocesses the rows of the `ResultSet` directly."}
    {:type :var,
     :name -execute-all,
     :arglists ([this sql-params opts]),
     :doc
     "Executes the SQL and produces (by default) a vector of\nfully-realized, datafiable hash maps from the `ResultSet`."}
    {:type :var,
     :name -execute-one,
     :arglists ([this sql-params opts]),
     :doc
     "Executes the SQL or DDL and produces the first row of the `ResultSet`\nas a fully-realized, datafiable hash map (by default)."}),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.protocols#Executable"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc",
   :name "execute-batch!",
   :arglists
   ([ps param-groups]
    [ps param-groups opts]
    [connectable sql param-groups opts]),
   :doc
   "Given a `PreparedStatement` and a vector containing parameter groups,\ni.e., a vector of vector of parameters, use `.addBatch` to add each group\nof parameters to the prepared statement (via `set-parameters`) and then\ncall `.executeBatch`. A vector of update counts is returned.\n\nAn options hash map may also be provided, containing `:batch-size` which\ndetermines how to partition the parameter groups for submission to the\ndatabase. If omitted, all groups will be submitted as a single command.\nIf you expect the update counts to be larger than `Integer/MAX_VALUE`,\nyou can specify `:large true` and `.executeLargeBatch` will be called\ninstead.\n\nAlternatively, given a connectable, a SQL string, a vector containing\nparameter groups, and an options hash map, create a new `PreparedStatement`\n(after possibly creating a new `Connection`), and execute the SQL with\nthe specified parameter groups. That new `PreparedStatement` (and the\nnew `Connection`, if created) will be closed automatically after use.\n\nBy default, returns a Clojure vector of update counts. Some databases\nallow batch statements to also return generated keys and you can attempt that\nif you ensure the `PreparedStatement` is created with `:return-keys true`\nand you also provide `:return-generated-keys true` in the options passed\nto `execute-batch!`. Some databases will only return one generated key\nper batch, some return all the generated keys, some will throw an exception.\nIf that is supported, `execute-batch!` will return a vector of hash maps\ncontaining the generated keys as fully-realized, datafiable result sets,\nwhose content is database-dependent.\n\nMay throw `java.sql.BatchUpdateException` if any part of the batch fails.\nYou may be able to call `.getUpdateCounts` on that exception object to\nget more information about which parts succeeded and which failed.\n\nFor additional caveats and database-specific options you may need, see:\nhttps://cljdoc.org/d/com.github.seancorfield/next.jdbc/CURRENT/doc/getting-started/prepared-statements#caveats\n\nNot all databases support batch execution.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc#execute-batch!"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.types",
   :name "as-integer",
   :arglists ([obj]),
   :doc
   "Wrap a Clojure value in a thunk with metadata to implement `set-parameter`\nso that `.setObject()` is called with the `java.sql.Types/INTEGER` SQL type.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.types#as-integer"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.result-set",
   :name "as-lower-arrays",
   :arglists ([rs opts]),
   :doc
   "Given a `ResultSet` and options, return a `RowBuilder` / `ResultSetBuilder`\nthat produces a vector of lower-case column names followed by vectors of\nrow values.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.result-set#as-lower-arrays"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.types",
   :name "as-decimal",
   :arglists ([obj]),
   :doc
   "Wrap a Clojure value in a thunk with metadata to implement `set-parameter`\nso that `.setObject()` is called with the `java.sql.Types/DECIMAL` SQL type.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.types#as-decimal"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.types",
   :name "as-varbinary",
   :arglists ([obj]),
   :doc
   "Wrap a Clojure value in a thunk with metadata to implement `set-parameter`\nso that `.setObject()` is called with the `java.sql.Types/VARBINARY` SQL type.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.types#as-varbinary"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.transaction",
   :name "*nested-tx*",
   :doc
   "Controls the behavior when a nested transaction is attempted.\n\nPossible values are:\n* `:allow` -- the default: assumes you know what you are doing!\n* `:ignore` -- the same behavior as `clojure.java.jdbc`: the nested\n    transaction is simply ignored and any SQL operations inside it are\n    executed in the context of the outer transaction.\n* `:prohibit` -- any attempt to create a nested transaction will throw\n    an exception: this is the safest but most restrictive approach so\n    that you can make sure you don't accidentally have any attempts\n    to create nested transactions (since that might be a bug in your code).",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.transaction#*nested-tx*"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.types",
   :name "as-timestamp-with-timezone",
   :arglists ([obj]),
   :doc
   "Wrap a Clojure value in a thunk with metadata to implement `set-parameter`\nso that `.setObject()` is called with the `java.sql.Types/TIMESTAMP_WITH_TIMEZONE` SQL type.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.types#as-timestamp-with-timezone"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.optional",
   :name "MapResultSetOptionalBuilder",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.optional#MapResultSetOptionalBuilder"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.types",
   :name "as-time-with-timezone",
   :arglists ([obj]),
   :doc
   "Wrap a Clojure value in a thunk with metadata to implement `set-parameter`\nso that `.setObject()` is called with the `java.sql.Types/TIME_WITH_TIMEZONE` SQL type.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.types#as-time-with-timezone"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.prepare",
   :name "create",
   :arglists
   ([con
     sql
     params
     {:keys
      [return-keys
       result-type
       concurrency
       cursors
       fetch-size
       max-rows
       timeout],
      :as opts}]),
   :doc
   "This is an implementation detail -- use `next.jdbc/prepare` instead.\n\nGiven a `Connection`, a SQL string, some parameters, and some options,\nreturn a `PreparedStatement` representing that.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.prepare#create"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.quoted",
   :name "ansi",
   :arglists ([s]),
   :doc "ANSI \"quoting\"\n",
   :members (),
   :path "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.quoted#ansi"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.sql",
   :name "find-by-keys",
   :arglists
   ([connectable table key-map] [connectable table key-map opts]),
   :doc
   "Syntactic sugar over `execute!` to make certain common queries easier.\n\nGiven a connectable object, a table name, and either a hash map of\ncolumns and values to search on or a vector of a SQL where clause and\nparameters, returns a vector of hash maps of rows that match.\n\nIf `:all` is passed instead of a hash map or vector -- the query will\nselect all rows in the table, subject to any pagination options below.\n\nIf `:columns` is passed, only that specified subset of columns will be\nreturned in each row (otherwise all columns are selected).\n\nIf the `:order-by` option is present, add an `ORDER BY` clause. `:order-by`\nshould be a vector of column names or pairs of column name / direction,\nwhich can be `:asc` or `:desc`.\n\nIf the `:top` option is present, the SQL Server `SELECT TOP ?` syntax\nis used and the value of the option is inserted as an additional parameter.\n\nIf the `:limit` option is present, the MySQL `LIMIT ? OFFSET ?` syntax\nis used (using the `:offset` option if present, else `OFFSET ?` is omitted).\nPostgreSQL also supports this syntax.\n\nIf the `:offset` option is present (without `:limit`), the standard\n`OFFSET ? ROWS FETCH NEXT ? ROWS ONLY` syntax is used (using the `:fetch`\noption if present, else `FETCH...` is omitted).",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.sql#find-by-keys"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc",
   :name "get-connection",
   :arglists
   ([spec] [spec opts] [spec user password] [spec user password opts]),
   :doc
   "Given some sort of specification of a database, return a new `Connection`.\n\n  In general, this should be used via `with-open`:\n\n```clojure\n  (with-open [con (get-connection spec opts)]\n    (run-some-ops con))\n```\n\n  If you call `get-connection` on a `DataSource`, it just calls `.getConnection`\n  and applies the `:auto-commit` and/or `:read-only` options, if provided.\n\n  If you call `get-connection` on anything else, it will call `get-datasource`\n  first to try to get a `DataSource`, and then call `get-connection` on that.\n\n  If you want different per-connection username/password values, you can\n  either put `:user` and `:password` into the `opts` hash map or pass them\n  as positional arguments.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc#get-connection"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.result-set",
   :name "as-lower-maps",
   :arglists ([rs opts]),
   :doc
   "Given a `ResultSet` and options, return a `RowBuilder` / `ResultSetBuilder`\nthat produces bare vectors of hash map rows, with lower-case keys.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.result-set#as-lower-maps"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.result-set",
   :name "as-arrays-adapter",
   :arglists ([builder-fn column-reader]),
   :doc
   "Given an array builder function (e.g., `as-unqualified-arrays`) and a column\nreading function, return a new builder function that uses that column reading\nfunction instead of `.getObject` so you can override the default behavior.\n\nThe default column-reader behavior would be equivalent to:\n\n    (defn default-column-reader\n      [^ResultSet rs ^ResultSetMetaData rsmeta ^Integer i]\n      (.getObject rs i))\n\nYour column-reader can use the result set metadata to determine whether\nto call `.getObject` or some other method to read the column's value.\n\n`read-column-by-index` is still called on the result of that read.\n\nNote: this is different behavior to `builder-adapter`'s `column-by-index-fn`.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.result-set#as-arrays-adapter"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc",
   :name "with-options",
   :arglists ([connectable opts]),
   :doc
   "Given a connectable/transactable object and a set of (default) options\nthat should be used on all operations on that object, return a new\nwrapper object that can be used in its place.\n\nBear in mind that `get-datasource`, `get-connection`, and `with-transaction`\nreturn plain Java objects, so if you call any of those on this wrapped\nobject, you'll need to re-wrap the Java object `with-options` again. See\nthe Datasources, Connections & Transactions section of Getting Started for\nmore details, and some examples of use with these functions.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc#with-options"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc",
   :name "execute!",
   :arglists
   ([stmt] [connectable sql-params] [connectable sql-params opts]),
   :doc
   "General SQL execution function.\n\nReturns a fully-realized result set. When `:multi-rs true` is provided, will\nreturn multiple result sets, as a vector of result sets. Each result set is\na vector of hash maps, by default, but can be controlled by the `:builder-fn`\noption.\n\nCan be called on a `PreparedStatement`, a `Connection`, or something that can\nproduce a `Connection` via a `DataSource`.",
   :members (),
   :path "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc#execute!"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.types",
   :name "as-boolean",
   :arglists ([obj]),
   :doc
   "Wrap a Clojure value in a thunk with metadata to implement `set-parameter`\nso that `.setObject()` is called with the `java.sql.Types/BOOLEAN` SQL type.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.types#as-boolean"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.types",
   :name "as-real",
   :arglists ([obj]),
   :doc
   "Wrap a Clojure value in a thunk with metadata to implement `set-parameter`\nso that `.setObject()` is called with the `java.sql.Types/REAL` SQL type.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.types#as-real"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.optional",
   :name "as-unqualified-lower-maps",
   :arglists ([rs opts]),
   :doc
   "Given a `ResultSet` and options, return a `RowBuilder` / `ResultSetBuilder`\nthat produces bare vectors of hash map rows, with simple, lower-case keys\nand nil columns omitted.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.optional#as-unqualified-lower-maps"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.prepare",
   :name "statement",
   :arglists
   ([con]
    [con
     {:keys
      [result-type concurrency cursors fetch-size max-rows timeout],
      :as opts}]),
   :doc
   "Given a `Connection` and some options, return a `Statement`.\n",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.prepare#statement"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.result-set",
   :name "MapResultSetBuilder",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.result-set#MapResultSetBuilder"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.result-set",
   :name "get-modified-column-names",
   :arglists ([rsmeta opts]),
   :doc
   "Given `ResultSetMetaData`, return a vector of modified column names, each\nqualified by the table from which it came.\n\nRequires both the `:qualifier-fn` and `:label-fn` options.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.result-set#get-modified-column-names"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.result-set",
   :name "foldable-result-set",
   :arglists ([rs] [rs conn-or-opts] [rs connectable opts]),
   :doc
   "Given a `ResultSet` and an optional connectable, return an `r/CollFold`\nthat can be folded. An options hash map may be provided.\n\nYou are responsible for ensuring the `Connection` for this `ResultSet`\nand the connectable both remain open until the fold is complete!\n\nIf the connectable is omitted, no foreign key navigation would be\navailable in any datafied result. If you want to pass a hash map as the\nconnectable, you must also pass an options hash map.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.result-set#foldable-result-set"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.result-set",
   :name "as-unqualified-maps",
   :arglists ([rs opts]),
   :doc
   "Given a `ResultSet` and options, return a `RowBuilder` / `ResultSetBuilder`\nthat produces bare vectors of hash map rows, with simple keys.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.result-set#as-unqualified-maps"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.types",
   :name "as-char",
   :arglists ([obj]),
   :doc
   "Wrap a Clojure value in a thunk with metadata to implement `set-parameter`\nso that `.setObject()` is called with the `java.sql.Types/CHAR` SQL type.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.types#as-char"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.types",
   :name "as-ref",
   :arglists ([obj]),
   :doc
   "Wrap a Clojure value in a thunk with metadata to implement `set-parameter`\nso that `.setObject()` is called with the `java.sql.Types/REF` SQL type.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.types#as-ref"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.result-set",
   :name "as-maps-adapter",
   :arglists ([builder-fn column-reader]),
   :doc
   "Given a map builder function (e.g., `as-lower-maps`) and a column reading\nfunction, return a new builder function that uses that column reading\nfunction instead of `.getObject` so you can override the default behavior.\n\nThe default column-reader behavior would be equivalent to:\n\n    (defn default-column-reader\n      [^ResultSet rs ^ResultSetMetaData rsmeta ^Integer i]\n      (.getObject rs i))\n\nYour column-reader can use the result set metadata to determine whether\nto call `.getObject` or some other method to read the column's value.\n\n`read-column-by-index` is still called on the result of that read.\n\nNote: this is different behavior to `builder-adapter`'s `column-by-index-fn`.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.result-set#as-maps-adapter"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.types",
   :name "as-array",
   :arglists ([obj]),
   :doc
   "Wrap a Clojure value in a thunk with metadata to implement `set-parameter`\nso that `.setObject()` is called with the `java.sql.Types/ARRAY` SQL type.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.types#as-array"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.result-set",
   :name "get-unqualified-modified-column-names",
   :arglists ([rsmeta opts]),
   :doc
   "Given `ResultSetMetaData`, return a vector of unqualified modified column\nnames.\n\nRequires the `:label-fn` option.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.result-set#get-unqualified-modified-column-names"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.sql.builder",
   :name "for-insert",
   :arglists ([table key-map opts]),
   :doc
   "Given a table name and a hash map of column names and their values,\nreturn a vector of the full `INSERT` SQL string and its parameters.\n\nApplies any `:table-fn` / `:column-fn` supplied in the options.\n\nIf `:suffix` is provided in `opts`, that string is appended to the\n`INSERT ...` statement.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.sql.builder#for-insert"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.plan",
   :name "select-one!",
   :arglists
   ([connectable cols sql-params] [connectable cols sql-params opts]),
   :doc
   "Execute the SQL and params using `next.jdbc/plan` and return just the\nselected columns from just the first row.\n\n`(plan/select-one! ds [:total] [\"select count(*) as total from table\"])`\n;;=> {:total 42}\n\nIf the `cols` argument is a vector of columns to select, then it is\napplied using `select-keys`, otherwise, the `cols` argument is used as\na function directly. That means it can be a simple keyword to return\njust that column -- which is the most common expected usage:\n\n`(plan/select-one! ds :total [\"select count(*) as total from table\"])`\n;;=> 42\n\nThe usual caveats apply about operations on a raw result set that\ncan be done without realizing the whole row.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.plan#select-one!"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.sql.builder",
   :name "as-keys",
   :arglists ([key-map opts]),
   :doc
   "Given a hash map of column names and values, return a string of all the\ncolumn names.\n\nApplies any `:column-fn` supplied in the options.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.sql.builder#as-keys"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.types",
   :name "as-longvarbinary",
   :arglists ([obj]),
   :doc
   "Wrap a Clojure value in a thunk with metadata to implement `set-parameter`\nso that `.setObject()` is called with the `java.sql.Types/LONGVARBINARY` SQL type.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.types#as-longvarbinary"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.date-time",
   :name "read-as-default",
   :arglists ([]),
   :doc
   "After calling this function, `next.jdbc.result-set/ReadableColumn`\nwill be extended to `java.sql.Date` and `java.sql.Timestamp` so that any\ndate or timestamp columns will be read as-is. This is provided for\ncompleteness, to undo the effects of `read-as-instant` or `read-as-local`.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.date-time#read-as-default"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.optional",
   :name "as-maps",
   :arglists ([rs opts]),
   :doc
   "Given a `ResultSet` and options, return a `RowBuilder` / `ResultSetBuilder`\nthat produces bare vectors of hash map rows, with nil columns omitted.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.optional#as-maps"}
  {:platform "clj",
   :type :protocol,
   :namespace "next.jdbc.protocols",
   :name "Transactable",
   :doc
   "Protocol for running SQL operations in a transaction.\n\nImplementations are provided for `Connection`, `DataSource`, and `Object`\n(on the assumption that an `Object` can be turned into a `DataSource`).",
   :members
   ({:type :var,
     :name -transact,
     :arglists ([this body-fn opts]),
     :doc "Run the `body-fn` inside a transaction.\n"}),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.protocols#Transactable"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.result-set",
   :name "ArrayResultSetBuilder",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.result-set#ArrayResultSetBuilder"}
  {:platform "clj",
   :type :protocol,
   :namespace "next.jdbc.result-set",
   :name "InspectableMapifiedResultSet",
   :doc
   "Protocol for exposing aspects of the (current) result set via functions.\n\nThe intent here is to expose information that is associated with either\nthe (current row of the) result set or the result set metadata, via\nfunctions that can be called inside a reducing function being used over\n`next.jdbc/plan`, including situations where the reducing function has\nto realize a row by calling `datafiable-row` but still wants to call\nthese functions on the (realized) row.",
   :members
   ({:type :var,
     :name column-names,
     :arglists ([this]),
     :doc
     "Return a vector of the column names from the result set.\n\nReifies the result builder, in order to construct column names,\nbut should not cause any row realization."}
    {:type :var,
     :name metadata,
     :arglists ([this]),
     :doc
     "Return the raw `ResultSetMetaData` object from the result set.\n\nShould not cause any row realization.\n\nIf `next.jdbc.datafy` has been required, this metadata will be\nfully-realized as a Clojure data structure, otherwise this should\nnot be allowed to 'leak' outside of the reducing function as it may\ndepend on the connection remaining open, in order to be valid."}
    {:type :var,
     :name row-number,
     :arglists ([this]),
     :doc
     "Return the current 1-based row number, if available.\n\nShould not cause any row realization."}),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.result-set#InspectableMapifiedResultSet"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.sql",
   :name "update!",
   :arglists
   ([connectable table key-map where-params]
    [connectable table key-map where-params opts]),
   :doc
   "Syntactic sugar over `execute-one!` to make certain common updates easier.\n\nGiven a connectable object, a table name, a hash map of columns and values\nto set, and either a hash map of columns and values to search on or a vector\nof a SQL where clause and parameters, perform an update on the table.",
   :members (),
   :path "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.sql#update!"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.sql.builder",
   :name "by-keys",
   :arglists ([key-map clause opts]),
   :doc
   "Given a hash map of column names and values and a clause type\n(`:set`, `:where`), return a vector of a SQL clause and its parameters.\n\nApplies any `:column-fn` supplied in the options.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.sql.builder#by-keys"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.datafy",
   :name "*datafy-failure*",
   :doc
   "How datafication failures should be handled, based on `clojure.java.data`.\n\nDefaults to `:qualify`, but can be `:group`, `:omit`, `:qualify`, or `:return`.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.datafy#*datafy-failure*"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.date-time",
   :name "read-as-local",
   :arglists ([]),
   :doc
   "After calling this function, `next.jdbc.result-set/ReadableColumn`\nwill be extended to `java.sql.Date` and `java.sql.Timestamp` so that any\ndate or timestamp columns will automatically be read as `java.time.LocalDate`\nor `java.time.LocalDateTime` respectively.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.date-time#read-as-local"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.optional",
   :name "as-modified-maps",
   :arglists ([rs opts]),
   :doc
   "Given a `ResultSet` and options, return a `RowBuilder` / `ResultSetBuilder`\nthat produces bare vectors of hash map rows, with modified keys and nil\ncolumns omitted.\n\nRequires both the `:qualifier-fn` and `:label-fn` options.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.optional#as-modified-maps"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.result-set",
   :name "get-column-names",
   :arglists ([rsmeta _]),
   :doc
   "Given `ResultSetMetaData`, return a vector of column names, each qualified by\nthe table from which it came.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.result-set#get-column-names"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.types",
   :name "as-datalink",
   :arglists ([obj]),
   :doc
   "Wrap a Clojure value in a thunk with metadata to implement `set-parameter`\nso that `.setObject()` is called with the `java.sql.Types/DATALINK` SQL type.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.types#as-datalink"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc",
   :name "snake-kebab-opts",
   :doc
   "A hash map of options that will convert Clojure identifiers to\nsnake_case SQL entities (`:table-fn`, `:column-fn`), and will convert\nSQL entities to qualified kebab-case Clojure identifiers (`:builder-fn`).",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc#snake-kebab-opts"}
  {:platform "clj",
   :type :protocol,
   :namespace "next.jdbc.protocols",
   :name "Connectable",
   :doc
   "Protocol for producing a new JDBC connection that should be closed when you\nare finished with it.\n\nImplementations are provided for `DataSource`, `PreparedStatement`, and\n`Object`, on the assumption that an `Object` can be turned into a `DataSource`.",
   :members
   ({:type :var,
     :name get-connection,
     :arglists ([this opts]),
     :doc
     "Produce a new `java.sql.Connection` for use with `with-open`.\n"}),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.protocols#Connectable"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.sql",
   :name "query",
   :arglists ([connectable sql-params] [connectable sql-params opts]),
   :doc
   "Syntactic sugar over `execute!` to provide a query alias.\n\nGiven a connectable object, and a vector of SQL and its parameters,\nreturns a vector of hash maps of rows that match.",
   :members (),
   :path "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.sql#query"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.types",
   :name "as-clob",
   :arglists ([obj]),
   :doc
   "Wrap a Clojure value in a thunk with metadata to implement `set-parameter`\nso that `.setObject()` is called with the `java.sql.Types/CLOB` SQL type.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.types#as-clob"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.result-set",
   :name "as-arrays",
   :arglists ([rs opts]),
   :doc
   "Given a `ResultSet` and options, return a `RowBuilder` / `ResultSetBuilder`\nthat produces a vector of column names followed by vectors of row values.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.result-set#as-arrays"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.connection",
   :name "component",
   :arglists ([clazz db-spec] [clazz db-spec close-fn]),
   :doc
   "Takes the same arguments as `->pool` but returns an entity compatible\nwith Stuart Sierra's Component: when `com.stuartsierra.component/start`\nis called on it, it builds a connection pooled datasource, and returns\nan entity that can either be invoked as a function with no arguments\nto return that datasource, or can have `com.stuartsierra.component/stop`\ncalled on it to shutdown the datasource (and return a new startable\nentity).\n\nBy default, the datasource is shutdown by calling `.close` on it.\nIf the datasource class implements `java.io.Closeable` then a direct,\ntype-hinted call to `.close` will be used, with no reflection,\notherwise Java reflection will be used to find the first `.close`\nmethod in the datasource class that takes no arguments and returns `void`.\n\nIf neither of those behaviors is appropriate, you may supply a third\nargument to this function -- `close-fn` -- which performs whatever\naction is appropriate to your chosen datasource class.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.connection#component"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.sql.builder",
   :name "as-?",
   :arglists ([key-map _]),
   :doc
   "Given a hash map of column names and values, or a vector of column names,\nreturn a string of `?` placeholders for them.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.sql.builder#as-?"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.quoted",
   :name "postgres",
   :doc "PostgreSQL \"quoting\" (ANSI)\n",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.quoted#postgres"}
  {:platform "clj",
   :type :protocol,
   :namespace "next.jdbc.result-set",
   :name "RowBuilder",
   :doc
   "Protocol for building rows in various representations.\n\nThe default implementation for building hash maps: `MapResultSetBuilder`",
   :members
   ({:type :var,
     :name ->row,
     :arglists ([_]),
     :doc "Called once per row to create the basis of each row.\n"}
    {:type :var,
     :name column-count,
     :arglists ([_]),
     :doc "Return the number of columns in each row.\n"}
    {:type :var,
     :name row!,
     :arglists ([_ row]),
     :doc
     "Called once per row to finalize each row once it is complete.\n"}
    {:type :var,
     :name with-column,
     :arglists ([_ row i]),
     :doc
     "Called with the row and the index of the column to be added;\nthis is expected to read the column value from the `ResultSet`!"}
    {:type :var,
     :name with-column-value,
     :arglists ([_ row col v]),
     :doc
     "Called with the row, the column name, and the value to be added;\nthis is a low-level function, typically used by `with-column`."}),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.result-set#RowBuilder"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.types",
   :name "as-timestamp",
   :arglists ([obj]),
   :doc
   "Wrap a Clojure value in a thunk with metadata to implement `set-parameter`\nso that `.setObject()` is called with the `java.sql.Types/TIMESTAMP` SQL type.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.types#as-timestamp"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.sql.builder",
   :name "for-insert-multi",
   :arglists ([table cols rows opts]),
   :doc
   "Given a table name, a vector of column names, and a vector of row values\n(each row is a vector of its values), return a vector of the full `INSERT`\nSQL string and its parameters.\n\nApplies any `:table-fn` / `:column-fn` supplied in the options.\n\nIf `:suffix` is provided in `opts`, that string is appended to the\n`INSERT ...` statement.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.sql.builder#for-insert-multi"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.result-set",
   :name "as-kebab-maps",
   :arglists ([rs opts]),
   :doc
   "Given a `ResultSet` and options, return a `RowBuilder` / `ResultSetBuilder`\nthat produces bare vectors of hash map rows, with kebab-case keys.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.result-set#as-kebab-maps"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.result-set",
   :name "as-unqualified-arrays",
   :arglists ([rs opts]),
   :doc
   "Given a `ResultSet` and options, return a `RowBuilder` / `ResultSetBuilder`\nthat produces a vector of simple column names followed by vectors of row\nvalues.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.result-set#as-unqualified-arrays"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.types",
   :name "as-time",
   :arglists ([obj]),
   :doc
   "Wrap a Clojure value in a thunk with metadata to implement `set-parameter`\nso that `.setObject()` is called with the `java.sql.Types/TIME` SQL type.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.types#as-time"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.connection",
   :name "->pool",
   :arglists ([clazz db-spec]),
   :doc
   "Given a (connection pooled datasource) class and a database spec, return a\nconnection pool object built from that class and the database spec.\n\nAssumes the `clazz` has a `.setJdbcUrl` method (which HikariCP and c3p0 do).\n\nIf you already have a JDBC URL and want to use this method, pass `:jdbcUrl`\nin the database spec (instead of `:dbtype`, `:dbname`, etc).\n\nProperties for the connection pool object can be passed as mixed case\nkeywords that correspond to setter methods (just as `:jdbcUrl` maps to\n`.setJdbcUrl`). `clojure.java.data/to-java` is used to construct the\nobject and call the setters.\n\nNote that the result is not type-hinted (because there's no common base\nclass or interface that can be assumed). In particular, connection pooled\ndatasource objects may need to be closed but they don't necessarily implement\n`java.io.Closeable` (HikariCP does, c3p0 does not).",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.connection#->pool"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc",
   :name "get-datasource",
   :arglists ([spec]),
   :doc
   "Given some sort of specification of a database, return a `DataSource`.\n\nA specification can be a JDBC URL string (which is passed to the JDBC\ndriver as-is), or a hash map.\n\nFor the hash map, there are two formats accepted:\n\nIn the first format, these keys are required:\n* `:dbtype` -- a string indicating the type of the database\n* `:dbname` -- a string indicating the name of the database to be used\n\nThe following optional keys are commonly used:\n* `:user` -- the username to authenticate with\n* `:password` -- the password to authenticate with\n* `:host` -- the hostname or IP address of the database (default: `127.0.0.1`);\n    can be `:none` which means the host/port segment of the JDBC URL should\n    be omitted entirely (for 'local' databases)\n* `:port` -- the port for the database connection (the default is database-\n    specific -- see below)\n* `:classname` -- if you need to override the default for the `:dbtype`\n    (or you want to use a database that next.jdbc does not know about!)\n\nThe following optional keys can be used to control how JDBC URLs are\nassembled. This may be needed for `:dbtype` values that `next.jdbc`\ndoes not recognize:\n* `:dbname-separator` -- override the `/` or `:` that normally precedes\n    the database name in the JDBC URL\n* `:host-prefix` -- override the `//` that normally precedes the IP\n    address or hostname in the JDBC URL\n\nIn the second format, this key is required:\n* `:jdbcUrl` -- a JDBC URL string\n\nAny additional options provided will be passed to the JDBC driver's\n`.getConnection` call as a `java.util.Properties` structure.\n\nDatabase types supported (for `:dbtype`), and their defaults:\n* `derby` -- `org.apache.derby.jdbc.EmbeddedDriver` -- also pass `:create true`\n    if you want the database to be automatically created\n* `duckdb` -- `org.duckdb.DuckDBDriver` -- embedded database\n* `h2` -- `org.h2.Driver` -- for an on-disk database\n* `h2:mem` -- `org.h2.Driver` -- for an in-memory database\n* `hsqldb`, `hsql` -- `org.hsqldb.jdbcDriver`\n* `jtds:sqlserver`, `jtds` -- `net.sourceforge.jtds.jdbc.Driver` -- `1433`\n* `mariadb` -- `org.mariadb.jdbc.Driver` -- `3306`\n* `mysql` -- `com.mysql.cj.jdbc.Driver`, `com.mysql.jdbc.Driver` -- `3306`\n* `oracle:oci` -- `oracle.jdbc.OracleDriver` -- `1521`\n* `oracle:thin`, `oracle` -- `oracle.jdbc.OracleDriver` -- `1521`\n* `oracle:sid` -- `oracle.jdbc.OracleDriver` -- `1521` -- uses the legacy `:`\n    separator for the database name but otherwise behaves like `oracle:thin`\n* `postgresql`, `postgres` -- `org.postgresql.Driver` -- `5432`\n* `pgsql` -- `com.impossibl.postgres.jdbc.PGDriver` -- no default port\n* `redshift` -- `com.amazon.redshift.jdbc.Driver` -- no default port\n* `sqlite` -- `org.sqlite.JDBC`\n* `sqlserver`, `mssql` -- `com.microsoft.sqlserver.jdbc.SQLServerDriver` -- `1433`\n* `timesten:client` -- `com.timesten.jdbc.TimesTenClientDriver`\n* `timesten:direct` -- `com.timesten.jdbc.TimesTenDriver`\n\nFor more details about `:dbtype` and `:classname` values, see:\nhttps://cljdoc.org/d/com.github.seancorfield/next.jdbc/CURRENT/api/next.jdbc.connection#dbtypes",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc#get-datasource"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.result-set",
   :name "as-unqualified-modified-arrays",
   :arglists ([rs opts]),
   :doc
   "Given a `ResultSet` and options, return a `RowBuilder` / `ResultSetBuilder`\nthat produces a vector of simple, modified column names followed by\nvectors of row values.\n\nRequires the `:label-fn` option.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.result-set#as-unqualified-modified-arrays"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.result-set",
   :name "clob-column-reader",
   :arglists ([rs _ i]),
   :doc
   "An example column-reader that still uses `.getObject` but expands CLOB\ncolumns into strings.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.result-set#clob-column-reader"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.result-set",
   :name "get-unqualified-column-names",
   :arglists ([rsmeta _]),
   :doc
   "Given `ResultSetMetaData`, return a vector of unqualified column names.\n",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.result-set#get-unqualified-column-names"}
  {:platform "clj",
   :type :protocol,
   :namespace "next.jdbc.result-set",
   :name "ReadableColumn",
   :doc
   "Protocol for reading objects from the `java.sql.ResultSet`. Default\nimplementations (for `Object` and `nil`) return the argument, and the\n`Boolean` implementation ensures a canonicalized `true`/`false` value,\nbut it can be extended to provide custom behavior for special types.\nExtension via metadata is supported.",
   :members
   ({:type :var,
     :name read-column-by-index,
     :arglists ([val rsmeta idx]),
     :doc
     "Function for transforming values after reading them via a column index.\n"}
    {:type :var,
     :name read-column-by-label,
     :arglists ([val label]),
     :doc
     "Function for transforming values after reading them via a column label.\n"}),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.result-set#ReadableColumn"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.result-set",
   :name "as-maps",
   :arglists ([rs opts]),
   :doc
   "Given a `ResultSet` and options, return a `RowBuilder` / `ResultSetBuilder`\nthat produces bare vectors of hash map rows.\n\nThis is the default `:builder-fn` option.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.result-set#as-maps"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.sql",
   :name "insert-multi!",
   :arglists
   ([connectable table cols rows] [connectable table cols rows opts]),
   :doc
   "Syntactic sugar over `execute!` to make inserting columns/rows easier.\n\nGiven a connectable object, a table name, a sequence of column names, and\na vector of rows of data (vectors of column values), inserts the data as\nmultiple rows in the database and attempts to return a vector of maps of\ngenerated keys.\n\nNote: this expands to a single SQL statement with placeholders for every\nvalue being inserted -- for large sets of rows, this may exceed the limits\non SQL string size and/or number of parameters for your JDBC driver or your\ndatabase!",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.sql#insert-multi!"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.quoted",
   :name "oracle",
   :doc "Oracle \"quoting\" (ANSI)\n",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.quoted#oracle"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.types",
   :name "as-nvarchar",
   :arglists ([obj]),
   :doc
   "Wrap a Clojure value in a thunk with metadata to implement `set-parameter`\nso that `.setObject()` is called with the `java.sql.Types/NVARCHAR` SQL type.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.types#as-nvarchar"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.types",
   :name "as-varchar",
   :arglists ([obj]),
   :doc
   "Wrap a Clojure value in a thunk with metadata to implement `set-parameter`\nso that `.setObject()` is called with the `java.sql.Types/VARCHAR` SQL type.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.types#as-varchar"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.specs",
   :name "jdbc-url-format?",
   :arglists ([url]),
   :doc
   "JDBC URLs must begin with `jdbc:` followed by the `dbtype` and\na second colon. Note: `clojure.java.jdbc` incorrectly allowed\n`jdbc:` to be omitted at the beginning of a JDBC URL.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.specs#jdbc-url-format?"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.types",
   :name "as-nchar",
   :arglists ([obj]),
   :doc
   "Wrap a Clojure value in a thunk with metadata to implement `set-parameter`\nso that `.setObject()` is called with the `java.sql.Types/NCHAR` SQL type.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.types#as-nchar"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.optional",
   :name "as-unqualified-maps",
   :arglists ([rs opts]),
   :doc
   "Given a `ResultSet` and options, return a `RowBuilder` / `ResultSetBuilder`\nthat produces bare vectors of hash map rows, with simple keys and nil\ncolumns omitted.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.optional#as-unqualified-maps"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.types",
   :name "as-bit",
   :arglists ([obj]),
   :doc
   "Wrap a Clojure value in a thunk with metadata to implement `set-parameter`\nso that `.setObject()` is called with the `java.sql.Types/BIT` SQL type.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.types#as-bit"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.quoted",
   :name "sql-server",
   :arglists ([s]),
   :doc "SQL Server [quoting]\n",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.quoted#sql-server"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.result-set",
   :name "get-unqualified-lower-column-names",
   :arglists ([rsmeta opts]),
   :doc
   "Given `ResultSetMetaData`, return a vector of unqualified column names.\n",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.result-set#get-unqualified-lower-column-names"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.date-time",
   :name "read-as-instant",
   :arglists ([]),
   :doc
   "After calling this function, `next.jdbc.result-set/ReadableColumn`\nwill be extended to (`java.sql.Date` and) `java.sql.Timestamp` so that any\ntimestamp columns will automatically be read as `java.time.Instant`.\n\nNote that `java.sql.Date` columns will still be returns as-is because they\ncannot be converted to an instant (they lack a time component).",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.date-time#read-as-instant"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.types",
   :name "as-struct",
   :arglists ([obj]),
   :doc
   "Wrap a Clojure value in a thunk with metadata to implement `set-parameter`\nso that `.setObject()` is called with the `java.sql.Types/STRUCT` SQL type.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.types#as-struct"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.types",
   :name "as-java-object",
   :arglists ([obj]),
   :doc
   "Wrap a Clojure value in a thunk with metadata to implement `set-parameter`\nso that `.setObject()` is called with the `java.sql.Types/JAVA_OBJECT` SQL type.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.types#as-java-object"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.sql.builder",
   :name "for-update",
   :arglists ([table key-map where-params opts]),
   :doc
   "Given a table name, a vector of column names to set and their values, and\neither a hash map of column names and values or a vector of SQL (where clause)\nand its parameters, return a vector of the full `UPDATE` SQL string and its\nparameters.\n\nApplies any `:table-fn` / `:column-fn` supplied in the options.\n\nIf `:suffix` is provided in `opts`, that string is appended to the\n`UPDATE ...` statement.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.sql.builder#for-update"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.result-set",
   :name "as-modified-maps",
   :arglists ([rs opts]),
   :doc
   "Given a `ResultSet` and options, return a `RowBuilder` / `ResultSetBuilder`\nthat produces bare vectors of hash map rows, with modified keys.\n\nRequires both the `:qualifier-fn` and `:label-fn` options.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.result-set#as-modified-maps"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.sql.builder",
   :name "for-order-col",
   :arglists ([col opts]),
   :doc
   "Given a column name, or a pair of column name and direction,\nreturn the sub-clause for addition to `ORDER BY`.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.sql.builder#for-order-col"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc",
   :name "transact",
   :arglists ([transactable f] [transactable f opts]),
   :doc
   "Given a transactable object and a function (taking a `Connection`),\nexecute the function over the connection in a transactional manner.\n\nSee `with-transaction` for supported options.",
   :members (),
   :path "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc#transact"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.types",
   :name "as-longvarchar",
   :arglists ([obj]),
   :doc
   "Wrap a Clojure value in a thunk with metadata to implement `set-parameter`\nso that `.setObject()` is called with the `java.sql.Types/LONGVARCHAR` SQL type.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.types#as-longvarchar"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.result-set",
   :name "clob->string",
   :arglists ([clob]),
   :doc "Given a CLOB column value, read it as a string.\n",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.result-set#clob->string"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.prepare",
   :name "set-parameters",
   :arglists ([ps params]),
   :doc
   "Given a `PreparedStatement` and a vector of parameter values, update the\n`PreparedStatement` with those parameters and return it.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.prepare#set-parameters"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.types",
   :name "as-blob",
   :arglists ([obj]),
   :doc
   "Wrap a Clojure value in a thunk with metadata to implement `set-parameter`\nso that `.setObject()` is called with the `java.sql.Types/BLOB` SQL type.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.types#as-blob"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.sql.builder",
   :name "for-delete",
   :arglists ([table where-params opts]),
   :doc
   "Given a table name and either a hash map of column names and values or a\nvector of SQL (where clause) and its parameters, return a vector of the\nfull `DELETE` SQL string and its parameters.\n\nApplies any `:table-fn` / `:column-fn` supplied in the options.\n\nIf `:suffix` is provided in `opts`, that string is appended to the\n`DELETE ...` statement.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.sql.builder#for-delete"}
  {:platform "clj",
   :type :var,
   :namespace "next.jdbc.types",
   :name "as-bigint",
   :arglists ([obj]),
   :doc
   "Wrap a Clojure value in a thunk with metadata to implement `set-parameter`\nso that `.setObject()` is called with the `java.sql.Types/BIGINT` SQL type.",
   :members (),
   :path
   "/d/seancorfield/next.jdbc/1.2.659/api/next.jdbc.types#as-bigint"}],
 :docs
 [{:name "Readme",
   :path "/d/seancorfield/next.jdbc/1.2.659/doc/readme",
   :doc
   "next.jdbc The next generation of clojure.java.jdbc: a new low-level Clojure wrapper for JDBC-based access to databases. Featured in Jacek Schae's Learn Reitit Pro online course! TL;DR The latest versions on Clojars and on cljdoc: The documentation on cljdoc.org is for the current version of next.jdbc: Getting Started API Reference Migrating from clojure.java.jdbc Feedback via issues or in the #sql channel on the Clojurians Slack or the #sql stream on the Clojurians Zulip. The documentation on GitHub is for develop since the 1.2.659 release -- see the CHANGELOG and then read the corresponding updated documentation on GitHub if you want. Older versions of next.jdbc were published under the seancorfield group ID and you can find older seancorfield/next.jdbc documentation on cljdoc.org. This project follows the version scheme MAJOR.MINOR.COMMITS where MAJOR and MINOR provide some relative indication of the size of the change, but do not follow semantic versioning. In general, all changes endeavor to be non-breaking (by moving to new names rather than by breaking existing names). COMMITS is an ever-increasing counter of commits since the beginning of this repository. Motivation Why another JDBC library? Why a different API from clojure.java.jdbc? Performance: there's a surprising amount of overhead in how ResultSet objects are converted to sequences of hash maps in clojure.java.jdbc  which can be really noticeable for large result sets  so I wanted a better way to handle that. There's also quite a bit of overhead and complexity in all the conditional logic and parsing that is associated with db-spec-as-hash-map. A more modern API, based on using qualified keywords and transducers etc: :qualifier and reducible-query in recent clojure.java.jdbc versions were steps toward that but there's a lot of \"legacy\" API in the library and I want to present a more focused, more streamlined API so folks naturally use the IReduceInit / transducer approach from day one and benefit from qualified keywords. Simplicity: clojure.java.jdbc uses a variety of ways to execute SQL which can lead to inconsistencies and surprises  query, execute!, and db-do-commands are all different ways to execute different types of SQL statement so you have to remember which is which and you often have to watch out for restrictions in the underlying JDBC API. Those were my three primary drivers. In addition, the db-spec-as-hash-map approach in clojure.java.jdbc has caused a lot of frustration and confusion in the past, especially with the wide range of conflicting options that are supported. next.jdbc is heavily protocol-based so it's easier to mix'n'match how you use it with direct Java JDBC code (and the protocol-based approach contributes to the improved performance overall). There's a much clearer path of db-spec -> DataSource -> Connection now, which should steer people toward more connection reuse and better performing apps. I also wanted datafy/nav support baked right in (it was added to clojure.java.jdbc back in December 2018 as an undocumented, experimental API in a separate namespace). It is the default behavior for execute! and execute-one!. The protocol-based function next.jdbc.result-set/datafiable-row can be used with plan if you need to add datafy/nav support to rows you are creating in your reduction. As next.jdbc moved from alpha to beta, the last breaking change was made (renaming reducible! to plan) and the API should be considered stable. Only accretive and fixative changes will be made from now on. After a month of alpha builds being available for testing, the first beta build was released on May 24th, 2019. A release candidate followed on June 4th and the \"gold\" (1.0.0) release was on June 12th. In addition to the small, core API in next.jdbc, there are \"syntactic sugar\" SQL functions (insert!, query, update!, and delete!) available in next.jdbc.sql that are similar to the main API in clojure.java.jdbc. See Migrating from clojure.java.jdbc for more detail about the differences. Usage The primary concepts behind next.jdbc are that you start by producing a javax.sql.DataSource. You can create a pooled datasource object using your preferred library (c3p0, hikari-cp, etc). You can use next.jdbc's get-datasource function to create a DataSource from a db-spec hash map or from a JDBC URL (string). The underlying protocol, Sourceable, can be extended to allow more things to be turned into a DataSource (and can be extended via metadata on an object as well as via types). From a DataSource, either you or next.jdbc can create a java.sql.Connection via the get-connection function. You can specify an options hash map to get-connection to modify the connection that is created: :read-only, :auto-commit. The primary SQL execution API in next.jdbc is: plan -- yields an IReduceInit that, when reduced, executes the SQL statement and then reduces over the ResultSet with as little overhead as possible. execute! -- executes the SQL statement and produces a vector of realized hash maps, that use qualified keywords for the column names, of the form :<table>/<column>. If you join across multiple tables, the qualified keywords will reflect the originating tables for each of the columns. If the SQL produces named values that do not come from an associated table, a simple, unqualified keyword will be used. The realized hash maps returned by execute! are Datafiable and thus Navigable (see Clojure 1.10's datafy and nav functions, and tools like Cognitect's REBL). Alternatively, you can specify {:builder-fn rs/as-arrays} and produce a vector with column names followed by vectors of row values. rs/as-maps is the default for :builder-fn but there are also rs/as-unqualified-maps and rs/as-unqualified-arrays if you want unqualified :<column> column names (and there are also lower-case variants of all of these). execute-one! -- executes the SQL or DDL statement and produces a single realized hash map. The realized hash map returned by execute-one! is Datafiable and thus Navigable. In addition, there are API functions to create PreparedStatements (prepare) from Connections, which can be passed to plan, execute!, or execute-one!, and to run code inside a transaction (the transact function and the with-transaction macro). Since next.jdbc uses raw Java JDBC types, you can use with-open directly to reuse connections and ensure they are cleaned up correctly:   (let [my-datasource (jdbc/get-datasource {:dbtype \"...\" :dbname \"...\" ...})]\n    (with-open [connection (jdbc/get-connection my-datasource)]\n      (jdbc/execute! connection [...])\n      (reduce my-fn init-value (jdbc/plan connection [...]))\n      (jdbc/execute! connection [...])))\n Usage scenarios There are three intended usage scenarios that have driven the design of the API: Execute a SQL statement and process it in a single eager operation, which may allow for the results to be streamed from the database (how to persuade JDBC to do that is database-specific!), and which cleans up resources before returning the result -- even if the reduction is short-circuited via reduced. This usage is supported by plan. This is likely to be the fastest approach and should be the first option you consider for SQL queries. Execute a SQL or DDL statement to obtain a single, fully-realized, Datafiable hash map that represents either the first row from a ResultSet, the first generated keys result (again, from a ResultSet), or the first result where neither of those are available (next.jdbc yields {:next.jdbc/update-count N} when it can only return an update count). This usage is supported by execute-one!. This is probably your best choice for most non-query operations. Execute a SQL statement to obtain a fully-realized, Datafiable result set -- a vector of hash maps. This usage is supported by execute!. You can also produce a vector of column names/row values (next.jdbc.result-set/as-arrays). In addition, convenience functions -- \"syntactic sugar\" -- are provided to insert rows, run queries, update rows, and delete rows, using the same names as in clojure.java.jdbc. These are in next.jdbc.sql since they involve SQL creation -- they are not considered part of the core API. More Detailed Documentation Getting Started Friendly SQL Functions Tips & Tricks Result Set Builders Prepared Statements Transactions All The Options datafy, nav, and :schema Migration from clojure.java.jdbc License Copyright  2018-2021 Sean Corfield Distributed under the Eclipse Public License version 1.0."}
  {:name "Changes",
   :path "/d/seancorfield/next.jdbc/1.2.659/doc/changes",
   :doc
   "Change Log Only accretive/fixative changes will be made from now on. 1.2.659 -- 2021-05-05 Address #164 by making clj-commons/camel-snake-kebab an unconditional dependency. [Being a conditional dependency that could be brought in at runtime caused problems with GraalVM-based native compilation as well as with multi-project monorepos] Add Tips & Tricks section about working with PostgreSQL \"interval\" types (via PR #163 from @snorremd). Address #162 by adding GraalVM to the test matrix (thank you @DeLaGuardo). Update several dependency versions. 1.1.646 -- 2021-03-15 Fix #161 by allowing execute-batch! to work with datasources and connections, and providing the SQL statement directly. 1.1.643 -- 2021-03-06 Change coordinates to com.github.seancorfield/next.jdbc (although new versions will continue to be deployed to seancorfield/next.jdbc for a while -- see the Clojars Verified Group Names policy). Documented next.jdbc.transaction/*nested-tx* more thoroughly since that difference from clojure.java.jdbc has come up in conversation a few times recently. Fix #158 by documenting (and testing) :allowMultiQueries true as an option for MySQL/MariaDB to allow multiple statements to be executed and multiple result sets to be returned. Fix #157 by copying next.jdbc.prepare/execute-batch! to next.jdbc/execute-batch! (to avoid a circular dependency that previously relied on requiring next.jdbc.result-set at runtime -- which was problematic for GraalVM-based native compilation); next.jdbc.prepare/execute-batch! is deprecated: it will continue to exist and work, but is no longer documented. In addition, next.jdbc.prepare/execute-batch! now relies on a private volatile! in order to reference next.jdbc.result-set/datafiable-result-set so that it is GraalVM-friendly. Note: code that requires next.jdbc.prepare and uses execute-batch! without also requiring something that causes next.jdbc.result-set to be loaded will no longer return generated keys from execute-batch! but that's an almost impossible path since nearly all code that uses execute-batch! will have called next.jdbc/prepare to get the PreparedStatement in the first place. 1.1.613 -- 2020-11-05 Fix #144 by ensuring camel-snake-case is properly required before use in an uberjar context. 1.1.610 -- 2020-10-19 Fix #140 by adding \"duckdb\" to next.jdbc.connection/dbtypes. Change next.jdbc.types/as-* functions to use a thunk instead of a vector to convey metadata, so that wrapped values do not get unpacked by HoneySQL. Refactor reducing and folding code around ResultSet, so that reducible-result-set and foldable-result-set can be exposed for folks who want more control over processing result sets obtained from database metadata. datafiable-result-set can now be called without the connectable and/or opts arguments; a nil connectable now disables foreign key navigation in datafied results (rather than throwing an obscure exception). 1.1.588 -- 2020-09-09 Fix #139 by adding next.jdbc.plan/select-one! and next.jdbc.plan/select!. If ResultSet.getMetaData() returns null, we assume the column count is zero, i.e., an empty result set. This should \"never happen\" but some JDBC drivers are badly behaved and their idea of an \"empty result set\" does not match the JDBC API spec. 1.1.582 -- 2020-08-05 Fix #138 by exposing next.jdbc.connection/jdbc-url to build :jdbcUrl values that can be passed to ->pool or component. 1.1.581 -- 2020-08-03 Fix #137 by adding support for specifying username and password per-connection (if your datasource supports this). Document SQLite handling of bool and bit columns in a new Tips & Tricks section, inspired by #134. Address #133 by adding :return-generated-keys as an option on execute-batch!. 1.1.569 -- 2020-07-10 Fix #132 by adding specs for next.jdbc/with-options and next.jdbc.prepare/statement; correct spec for next.jdbc.connection/component. PR #131 from @Briaoeuidhtns. Fix #130 by implementing clojure.lang.ILookup on the three builder adapters. Fix #129 by adding with-column-value to RowBuilder and a more generic builder-adapter. Fix #128 by adding a test for the \"not found\" arity of lookup on mapified result sets. Fix #121 by conditionally adding next.jdbc/snake-kebab-opts, next.jdbc/unqualified-snake-kebab-opts, next.jdbc.result-set/as-kebab-maps, and next.jdbc.result-set/as-unqualified-kebab-maps (which are present only if camel-snake-kebab is on your classpath). Correct MySQL batch statement rewrite tip: it's :rewriteBatchedStatements true (plural). Also surface the batch statement tips in the Tips & Tricks page. Clarify how combining is interleaving with reducing in Reducing and Folding with plan. Use \"JDBC URL\" consistently everywhere (instead of \"JDBC URI\" in several places). 1.1.547 -- 2020-06-29 Address #125 by making the result of plan foldable (in the clojure.core.reducers sense). Address #124 by extending next.jdbc.sql.builder/for-query to support :top (SQL Server), :limit / :offset (MySQL/PostgreSQL), :offset / :fetch (SQL Standard) for find-by-keys. Address #117 by adding next.jdbc.transaction/*nested-tx* to provide control over how attempts to create nested transactions should be handled. Address #116 by adding a :multi-rs option to execute! to retrieve multiple result sets, for example from stored procedure calls or T-SQL scripts. Allow :all to be passed into find-by-keys instead of an example hash map or a where clause vector so all rows will be returned (expected to be used with :offset etc to support simple pagination of an entire table). Add :columns option to find-by-keys (and get-by-id) to specify a subset of columns to be returned in each row. This can also specify an alias for the column and allows for computed expressions to be selected with an alias. 1.0.478 -- 2020-06-24 Address #123 by adding next.jdbc.types namespace, full of auto-generated as-xxx functions, one for each of the java.sql.Types values. 1.0.476 -- 2020-06-22 Extend default options behavior to next.jdbc.sql functions. 1.0.475 -- 2020-06-22 Add tests for \"jtds\" database driver (against MS SQL Server), making it officially supported. Switch from OpenTable Embedded PostgreSQL to Zonky's version, so that testing can move forward from PostgreSQL 10.11 to 12.2.0. Fix potential reflection warnings caused by next.jdbc.prepare/statement being incorrectly type-hinted. Address #122 by adding next.jdbc/with-options that lets you wrap up a connectable along with default options that should be applied to all operations on that connectable. Address #119 by clarifying realization actions in the docstrings for row-number, column-names, and metadata. Address #115 by adding equivalent of db-do-commands in the clojure.java.jdbc migration guide. Add log4j2 as a test dependency so that I have better control over logging (which makes debugging easier!). 1.0.462 -- 2020-05-31 Addition of next.jdbc.datafy to provide more datafy/nav introspection (see the additional section in datafy, nav, and :schema for details). Addition of next.jdbc.result-set/metadata to provide (datafied) result set metadata within plan. 1.0.445 -- 2020-05-23 Enhanced support in plan for \"metadata\" access: row-number and column-names can be called on the abstract row (even after calling datafiable-row). In addition, Associative access via numeric \"keys\" will read columns by index, and row abstractions now support Indexed access via nth (which will also read columns by index). Fixes #110. Support for Stuart Sierra's Component library, via next.jdbc.connection/component. See updated Getting Started guide for usage. Add example of getting generated keys from execute-batch!. Add MySQL-specific result set streaming tip. Add array handling example to PostgreSQL Tips & Tricks. PR #108 from @maxp. Investigate possible solutions for #106 (mutable transaction thread safety) -- experimental locking on Connection object. 1.0.424 -- 2020-04-10 In Tips & Tricks, noted that MySQL returns BLOB columns as byte[] instead of java.sql.Blob. Address #103, #104 by adding a section on timeouts to Tips & Tricks. Fix #102 by allowing keywords or strings in :return-keys. Fix #101 by tightening the spec on a JDBC URL to correctly reflect that it must start with jdbc:. Add support for calling .getLoginTimeout/.setLoginTimeout on the reified DataSource returned by get-datasource when called on a hash map \"db-spec\" or JDBC URL string. Documentation improvements based on feedback (mostly from Slack), including a section on database metadata near the end of Getting Started. 1.0.409 -- 2020-03-16 Address #100 by adding support for MariaDB (@green-coder). Set NEXT_JDBC_TEST_MARIADB=true as well as NEXT_JDBC_TEST_MYSQL=true in order to run tests against MariaDB. 1.0.405 -- 2020-03-14 (no code changes -- just documentation) Improve documentation around plan so reduce etc is more obvious. Attempt to drive readers to cljdoc.org instead of the GitHub version (which is harder to navigate). 1.0.395 -- 2020-03-02 Add read-as-instant and read-as-local functions to next.jdbc.date-time to extend ReadableColumn so that SQL DATE and TIMESTAMP columns can be read as Java Time types. Specifically call out PostgreSQL as needing next.jdbc.date-time to enable automatic conversion of java.util.Date objects to SQL timestamps for prepared statements (#95). Split Tips & Tricks into its own page, with a whole new section on using JSON data types with PostgreSQL (#94 -- thank you @vharmain). Bump dependencies to latest. 1.0.384 -- 2020-02-28 Add PostgreSQL streaming option information to Tips & Tricks (#87). Minor documentation fixes (including #85, #92, #93). Improve Unknown dbtype exception message (to clarify that :classname is also missing, #90). Fix #88 by using 1-arity keyword call when table name unavailable (or :qualifier-fn returns nil or an empty string); also allows :qualifier-fn function to be called on empty table name (so :qualifier-fn (constantly \"qual\") will now work much like clojure.java.jdbc's :qualifier \"qual\" worked). Address #89, #91 by making minor performance tweaks to next.jdbc.result-set functions. Planning to move to MAJOR.MINOR.COMMITS versioning scheme (1.0.384). 1.0.13 -- 2019-12-20 Fix #82 by adding clojure.java.data-based support for setting arbitrary properties on Connection and PreparedStatement objects, post-creation. Note: this uses the Java reflection API under the hood. Adds next.jdbc.prepare/statement to create Statement objects with all the options available to prepare except :return-keys. Update org.clojure/java.data to 0.1.5 (for property setting). Additional clarifications in the documentation based on feedback on Slack. 1.0.12 -- 2019-12-11 Address #81 by splitting the SQL-building functions out of next.jdbc.sql into next.jdbc.sql.builder. Fix #80 by avoiding the auto-commit restore after a failed rollback in a failed transaction. Address #78 by documenting the :connectionInitSql workaround for HikariCP/PostgreSQL and non-default schemas. 1.0.11 -- 2019-12-07 Fix #76 by avoiding conversions on java.sql.Date and java.sql.Timestamp. Add testing against Microsoft SQL Server (run tests with environment variables NEXT_JDBC_TEST_MSSQL=yes and MSSQL_SA_PASSWORD set to your local -- 127.0.0.1:1433 -- SQL Server sa user password; assumes that it can create and drop fruit and fruit_time tables in the model database). Add testing against MySQL (run tests with environment variables NEXT_JDBC_TEST_MYSQL=yes and MYSQL_ROOT_PASSWORD set to your local -- 127.0.0.1:3306 -- MySQL root user password; assumes you have already created an empty database called clojure_test). Bump several JDBC driver versions for up-to-date testing. Minor documentation fixes. 1.0.10 -- 2019-11-14 Fix #75 by adding support for java.sql.Statement to plan, execute!, and execute-one!. Address #74 by making several small changes to satisfy Eastwood. Fix #73 by providing a new, optional namespace next.jdbc.date-time that can be required if your database driver needs assistance converting java.util.Date (PostgreSQL!) or the Java Time types to SQL timestamp (or SQL date/time). Fix link to All The Options in Migration from clojure.java.jdbc. PR #71 (@laurio). Address #70 by adding CLOB & BLOB SQL Types to the Tips & Tricks section of Friendly SQL Functions and by adding next.jdbc.result-set/clob-column-reader and next.jdbc.result-set/clob->string helper to make it easier to deal with CLOB column data. Clarify what execute! and execute-one! produce when the result set is empty ([] and nil respectively, and there are now tests for this). Similarly for find-by-keys and get-by-id. Add MS SQL Server section to Tips & Tricks to note that it returns an empty string for table names by default (so table-qualified column names are not available). Using the :result-type (scroll) and :concurrency options will cause table names to be returned. Clarify that Friendly SQL Functions are deliberately simple (hint: they will not be enhanced or expanded -- use plan, execute!, and execute-one! instead, with a DSL library if you want!). Improve migration docs: explicitly recommend the use of a datasource for code that needs to work with both clojure.java.jdbc and next.jdbc; add caveats about column name conflicts (in several places). Improve datafy/nav documentation around :schema. Update org.clojure/java.data to \"0.1.4\" (0.1.2 fixes a number of reflection warnings). 1.0.9 -- 2019-10-11 Address #69 by trying to clarify when to use execute-one! vs execute! vs plan. Address #68 by clarifying that builder functions do not affect the \"fake result set\" containing :next.jdbc/update-count. Fix #67 by adding :jdbcUrl version spec. Add next.jdbc.optional/as-maps-adapter to provide a way to override the default result set reading behavior of using .getObject when omitting SQL NULL values from result set maps. 1.0.8 -- 2019-09-27 Fix #66 by adding support for a db-spec hash map format containing a :jdbcUrl key (consistent with ->pool) so that you can create a datasource from a JDBC URL string and additional options. Address #65 by adding a HugSQL \"quick start\" to the Friendly SQL Functions section of the docs. Add next.jdbc.specs/unstrument. PR #64 (@gerred). Address #63 by improving documentation around qualified column names and :qualifier (clojure.java.jdbc) migration, with a specific caveat about Oracle not fully supporting .getTableName(). 1.0.7 -- 2019-09-09 Address #60 by supporting simpler schema entry formats: :table/column is equivalent to the old [:table :column :one] and [:table/column] is equivalent to the old [:table :column :many]. The older formats will continue to be supported but should be considered deprecated. PR #62 (@seancorfield). Added test for using ANY(?) and arrays in PostgreSQL for IN (?,,,?) style queries. Added a Tips & Tricks section to Friendly SQL Functions with database-specific suggestions, that starts with this one. Improved documentation in several areas. 1.0.6 -- 2019-08-24 Improved documentation around insert-multi! and execute-batch! (addresses #57). Fix #54 by improving documentation around data type conversions (and the ReadableColumn and SettableParameter protocols). Fix #52 by using a US-locale function in the \"lower\" result set builders to avoid unexpected character changes in column names in locales such as Turkish. If you want the locale-sensitive behavior, pass clojure.string/lower-case into one of the \"modified\" result set builders. Add next.jdbc.result-set/as-maps-adapter and next.jdbc.result-set/as-arrays-adapter to provide a way to override the default result set reading behavior of using .getObject. Update org.clojure/test.check to \"0.10.0\". 1.0.5 -- 2019-08-05 Fix #51 by implementing IPersistentMap fully for the \"mapified\" result set inside plan. This adds support for dissoc and cons (which will both realize a row), count (which returns the column count but does not realize a row), empty (returns an empty hash map without realizing a row), etc. Improved documentation around connection pooling (HikariCP caveats). 1.0.4 -- 2019-07-24 Fix #50 by adding machinery to test against (embedded) PostgreSQL! Improved documentation for connection pooled datasources (including adding a Component example); clarified the recommendations for globally overriding default options (write a wrapper namespace that suits your usage). Note: this release is primarily to fix the cljdoc.org documentation via repackaging the JAR file. 1.0.3 -- 2019-07-23 Fix #48 by adding next.jdbc.connection/->pool and documenting how to use HikariCP and c3p0 in the Getting Started docs (as well as adding tests for both libraries). Documentation improvements, including examples of extending ReadableColumn and SettableParameter. Updated test dependencies (testing against more recent versions of several drivers). 1.0.2 -- 2019-07-15 Fix #47 by refactoring database specs to be a single hash map instead of pouring multiple maps into one. Fix #46 by allowing :host to be :none which tells next.jdbc to omit the host/port section of the JDBC URL, so that local databases can be used with :dbtype/:classname for database types that next.jdbc does not know. Also added :dbname-separator and :host-prefix to the \"db-spec\" to allow fine-grained control over how the JDBC URL is assembled. Fix #45 by adding TimesTen driver support. Fix #44 so that insert-multi! with an empty rows vector returns []. Fix #43 by adjusting the spec for insert-multi! to \"require less\" of the cols and rows arguments. Fix #42 by adding specs for execute-batch! and set-parameters in next.jdbc.prepare. Fix #41 by improving docstrings and documentation, especially around prepared statement handling. Fix #40 by adding next.jdbc/execute-batch! (previously next.jdbc.prepare/execute-batch!). Added asserts in next.jdbc.sql as more informative errors for cases that would generate SQL exceptions (from malformed SQL). Added spec for :order-by to reflect what is actually permitted. Expose next.jdbc.connect/dbtypes as a table of known database types and aliases, along with their class name(s), port, and other JDBC string components. 1.0.1 -- 2019-07-03 Fix #37 by adjusting the spec for with-transaction to \"require less\" of the :binding vector. Fix #36 by adding type hint in with-transaction macro. Fix #35 by explaining the database-specific options needed to ensure insert-multi! performs a single, batched operation. Fix #34 by explaining save points (in the Transactions documentation). Fix #33 by updating the spec for the example key-map in find-by-keys, update!, and delete! to reflect that you cannot pass an empty map to these functions (and added tests to ensure the calls fail with spec errors). 1.0.0 \"gold\" -- 2019-06-12 Address #31 by making reify'd objects produce a more informative string representation if they are printed (e.g., misusing plan by not reducing it or not mapping an operation over the rows). Fix #26 by exposing next.jdbc.result-set/datafiable-result-set so that various java.sql.DatabaseMetaData methods that return result metadata information in ResultSets can be easily turned into a fully realized result set. 1.0.0-rc1 -- 2019-06-04 Fix #24 by adding return type hints to next.jdbc functions. Fix #22 by adding next.jdbc.optional with six map builders that omit NULL columns from the row hash maps. Documentation improvements (#27, #28, and #29), including changing \"connectable\" to \"transactable\" for the transact function and the with-transaction macro (for consistency with the name of the underlying protocol). Fix #30 by adding modified variants of column name functions and builders. The lower variants have been rewritten in terms of these new modified variants. This adds :label-fn and :qualifier-fn options that mirror :column-fn and :table-fn for row builders. 1.0.0-beta1 -- 2019-05-24 Set up CircleCI testing (just local DBs for now). Address #21 by adding next.jdbc.specs and documenting basic usage. Fix #19 by caching loaded database driver classes. Address #16 by renaming reducible! to plan (BREAKING CHANGE!). Address #3 by deciding to maintain this library outside Clojure Contrib. Alpha Builds 1.0.0-alpha13 -- 2019-05-04 -- Fix #18 by removing more keys from properties when creating connections. 1.0.0-alpha12 -- 2019-04-26 -- Fix #17 by renaming :next.jdbc/sql-string to :next.jdbc/sql-params (BREAKING CHANGE!) and pass whole vector. 1.0.0-alpha11 -- 2019-04-24 -- Rename :gen-fn to :builder-fn (BREAKING CHANGE!); Fix #13 by adding documentation for datafy/nav/:schema; Fix #15 by automatically adding :next.jdbc/sql-string (as of 1.0.0-alpha12: :next.jdbc/sql-params) into the options hash map, so custom builders can depend on the SQL string. 1.0.0-alpha9 -- 2019-04-22 -- Fix #14 by respecting :gen-fn (as of 1.0.0-alpha11: :builder-fn) in execute-one! for PreparedStatement. 1.0.0-alpha8 -- 2019-04-21 -- Initial publicly announced release."}
  {:name "Getting Started",
   :path "/d/seancorfield/next.jdbc/1.2.659/doc/getting-started",
   :doc
   "Getting Started with next.jdbc The next.jdbc library provides a simpler, faster alternative to the clojure.java.jdbc Contrib library and is the next step in the evolution of that library. It is designed to work with Clojure 1.10 or later, supports datafy/nav, and by default produces hash maps with automatically qualified keywords, indicating source tables and column names (labels), if your database supports that. Installation You must be using Clojure 1.10 or later. 1.10.1 is the most recent stable version of Clojure (as of November 3rd, 2020). You can add next.jdbc to your project with either: com.github.seancorfield/next.jdbc {:mvn/version \"1.2.659\"}\n for deps.edn or: [com.github.seancorfield/next.jdbc \"1.2.659\"]\n for project.clj or build.boot. In addition, you will need to add dependencies for the JDBC drivers you wish to use for whatever databases you are using. For example: MySQL: mysql/mysql-connector-java {:mvn/version \"8.0.19\"} (search for latest version) PostgreSQL: org.postgresql/postgresql {:mvn/version \"42.2.10\"} (search for latest version) Microsoft SQL Server: com.microsoft.sqlserver/mssql-jdbc {:mvn/version \"8.2.1.jre8\"} (search for latest version) Note: these are the versions that next.jdbc is tested against but there may be more recent versions and those should generally work too -- click the \"search for latest version\" link to see all available versions of those drivers on Maven Central. You can see the full list of drivers and versions that next.jdbc is tested against in the project's deps.edn file, but many other JDBC drivers for other databases should also work (e.g., Oracle, Red Shift). An Example REPL Session To start using next.jdbc, you need to create a datasource (an instance of javax.sql.DataSource). You can use next.jdbc/get-datasource with either a \"db-spec\" -- a hash map describing the database you wish to connect to -- or a JDBC URL string. Or you can construct a datasource from one of the connection pooling libraries out there, such as HikariCP or c3p0 -- see Connection Pooling below. For the examples in this documentation, we will use a local H2 database on disk, and we'll use the Clojure CLI tools and deps.edn: ;; deps.edn\n{:deps {org.clojure/clojure {:mvn/version \"1.10.3\"}\n        com.github.seancorfield/next.jdbc {:mvn/version \"1.2.659\"}\n        com.h2database/h2 {:mvn/version \"1.4.199\"}}}\n Create & Populate a Database In this REPL session, we'll define an H2 datasource, create a database with a simple table, and then add some data and query it: > clj\nClojure 1.10.1\nuser=> (require '[next.jdbc :as jdbc])\nnil\nuser=> (def db {:dbtype \"h2\" :dbname \"example\"})\n#'user/db\nuser=> (def ds (jdbc/get-datasource db))\n#'user/ds\nuser=> (jdbc/execute! ds [\"\ncreate table address (\n  id int auto_increment primary key,\n  name varchar(32),\n  email varchar(255)\n)\"])\n[#:next.jdbc{:update-count 0}]\nuser=> (jdbc/execute! ds [\"\ninsert into address(name,email)\n  values('Sean Corfield','sean@corfield.org')\"])\n[#:next.jdbc{:update-count 1}]\nuser=> (jdbc/execute! ds [\"select * from address\"])\n[#:ADDRESS{:ID 1, :NAME \"Sean Corfield\", :EMAIL \"sean@corfield.org\"}]\nuser=>\n The \"db-spec\" hash map We described the database with just :dbtype and :dbname because it is created as a local file and needs no authentication. For most databases, you would need :user and :password for authentication, and if the database is running on a remote machine you would need :host and possibly :port (next.jdbc tries to guess the correct port based on the :dbtype). Note: You can see the full list of :dbtype values supported in next.jdbc/get-datasource's docstring. If you need this programmatically, you can get it from the next.jdbc.connection/dbtypes hash map. If those lists differ, the hash map is the definitive list (and I'll need to fix the docstring!). The docstring of that Var explains how to tell next.jdbc about additional databases. If you already have a JDBC URL (string), you can use that as-is instead of the db-spec hash map. If you have a JDBC URL and still need additional options passed into the JDBC driver, you can use a hash map with the :jdbcUrl key specifying the string and whatever additional options you need. execute! & execute-one! We used execute! to create the address table, to insert a new row into it, and to query it. In all three cases, execute! returns a vector of hash maps with namespace-qualified keys, representing the result set from the operation, if available. If the result set contains no rows, execute! returns an empty vector []. When no result set is available, next.jdbc returns a \"result set\" containing the \"update count\" from the operation (which is usually the number of rows affected; note that :builder-fn does not affect this fake \"result set\"). By default, H2 uses uppercase names and next.jdbc returns these as-is. If you only want a single row back -- the first row of any result set, generated keys, or update counts -- you can use execute-one! instead. Continuing the REPL session, we'll insert another address and ask for the generated keys to be returned, and then we'll query for a single row: user=> (jdbc/execute-one! ds [\"\ninsert into address(name,email)\n  values('Someone Else','some@elsewhere.com')\n\"] {:return-keys true})\n#:ADDRESS{:ID 2}\nuser=> (jdbc/execute-one! ds [\"select * from address where id = ?\" 2])\n#:ADDRESS{:ID 2, :NAME \"Someone Else\", :EMAIL \"some@elsewhere.com\"}\nuser=>\n Since we used execute-one!, we get just one row back (a hash map). This also shows how you provide parameters to SQL statements -- with ? in the SQL and then the corresponding parameter values in the vector after the SQL string. If the result set contains no rows, execute-one! returns nil. When no result is available, and next.jdbc returns a fake \"result set\" containing the \"update count\", execute-one! returns just a single hash map with the key next.jdbc/update-count and the number of rows updated. In the same way that you would use execute-one! if you only want one row or one update count, compared to execute! for multiple rows or a vector containing an update count, you can also ask execute! to return multiple result sets -- such as might be returned from a stored procedure call, or a T-SQL script (for SQL Server), or multiple statements (for MySQL) -- instead of just one. If you pass the :multi-rs true option to execute!, you will get back a vector of results sets, instead of just one result set: a vector of zero or more vectors. The result may well be a mix of vectors containing realized rows and vectors containing update counts, reflecting the results from specific SQL operations in the stored procedure or script. Note: In general, you should use execute-one! for DDL operations since you will only get back an update count. If you have a SQL statement that you know will only return an update count, execute-one! is the right choice. If you have a SQL statement that you know will only return a single row in the result set, you probably want to use execute-one!. If you use execute-one! for a SQL statement that would return multiple rows in a result set, even though you will only get the first row back (as a hash map), the full result set will still be retrieved from the database -- it does not limit the SQL in any way. Options & Result Set Builders All functions in next.jdbc (except get-datasource) can accept, as the optional last argument, a hash map containing a variety of options that control the behavior of the next.jdbc functions. We saw :return-keys provided as an option to the execute-one! function above and mentioned the :builder-fn option just above that. As noted, the default behavior is to return rows as hash maps with namespace-qualified keywords identifying the column names with the table name as the qualifier. There's a whole chapter on result set builders but here's a quick example showing how to get unqualified, lower case keywords instead: user=> (require '[next.jdbc.result-set :as rs])\nnil\nuser=> (jdbc/execute-one! ds [\"\ninsert into address(name,email)\n  values('Someone Else','some@elsewhere.com')\n\"] {:return-keys true :builder-fn rs/as-unqualified-lower-maps})\n{:id 3}\nuser=> (jdbc/execute-one! ds [\"select * from address where id = ?\" 3]\n                          {:builder-fn rs/as-unqualified-lower-maps})\n{:id 3, :name \"Someone Else\", :email \"some@elsewhere.com\"}\nuser=>\n Relying on the default result set builder -- and table-qualified column names -- is the recommended approach to take, if possible, with a few caveats: MS SQL Server produces unqualified column names by default (see Tips & Tricks for how to get table names back from MS SQL Server), Oracle's JDBC driver doesn't support .getTableName() so it will only produce unqualified column names (also mentioned in Tips & Tricks), If your SQL query joins tables in a way that produces duplicate column names, and you use unqualified column names, then those duplicated column names will conflict and you will get only one of them in your result -- use aliases in SQL (as) to make the column names distinct, If your SQL query joins a table to itself under different aliases, the qualified column names will conflict because they are based on the underlying table name provided by the JDBC driver rather the alias you used in your query -- again, use aliases in SQL to make those column names distinct. If you want to pass the same set of options into several operations, you can use next.jdbc/with-options to wrap your datasource (or connection) in a way that will pass \"default options\". Here's the example above rewritten with that: user=> (require '[next.jdbc.result-set :as rs])\nnil\nuser=> (def ds-opts (jdbc/with-options ds {:builder-fn rs/as-unqualified-lower-maps}))\n#'user/ds-opts\nuser=> (jdbc/execute-one! ds-opts [\"\ninsert into address(name,email)\n  values('Someone Else','some@elsewhere.com')\n\"] {:return-keys true})\n{:id 4}\nuser=> (jdbc/execute-one! ds-opts [\"select * from address where id = ?\" 4])\n{:id 4, :name \"Someone Else\", :email \"some@elsewhere.com\"}\nuser=>\n Note: See the next.jdbc/with-option examples in the Datasources, Connections & Transactions below for some caveats around using this function. In addition, two pre-built option hash maps are available in next.jdbc, that leverage the camel-snake-kebab library: snake-kebab-opts -- provides :column-fn, :table-fn, :label-fn, :qualifier-fn, and :builder-fn that will convert Clojure identifiers in :kebab-case to SQL entities in snake_case and will produce result sets with qualified :kebab-case names from SQL entities that use snake_case, unqualified-snake-kebab-opts -- provides :column-fn, :table-fn, :label-fn, :qualifier-fn, and :builder-fn that will convert Clojure identifiers in :kebab-case to SQL entities in snake_case and will produce result sets with unqualified :kebab-case names from SQL entities that use snake_case. Note: Using camel-snake-kebab might also be helpful if your database has camelCase table and column names, although you'll have to provide :column-fn and :table-fn yourself as ->camelCase from that library. Either way, consider relying on the default result set builder first and avoid converting column and table names (see Advantages of 'snake case': portability and ubiquity for an interesting discussion on kebab-case vs snake_case -- I do not agree with all of the author's points in that article, particularly his position against qualified keywords, but his argument for retaining snake_case around system boundaries is compelling). plan & Reducing Result Sets While the execute! and execute-one! functions are fine for retrieving result sets as data, most of the time you want to process that data efficiently without necessarily converting the entire result set into a Clojure data structure, so next.jdbc provides a SQL execution function that works with reduce and with transducers to consume the result set without the intermediate overhead of creating Clojure data structures for every row. We're going to create a new table that contains invoice items so we can see how to use plan without producing data structures: user=> (jdbc/execute-one! ds [\"\ncreate table invoice (\n  id int auto_increment primary key,\n  product varchar(32),\n  unit_price decimal(10,2),\n  unit_count int unsigned,\n  customer_id int unsigned\n)\"])\n#:next.jdbc{:update-count 0}\nuser=> (jdbc/execute-one! ds [\"\ninsert into invoice (product, unit_price, unit_count, customer_id)\nvalues ('apple', 0.99, 6, 100),\n       ('banana', 1.25, 3, 100),\n       ('cucumber', 2.49, 2, 100)\n\"])\n#:next.jdbc{:update-count 3}\nuser=> (reduce\n         (fn [cost row]\n           (+ cost (* (:unit_price row)\n                      (:unit_count row))))\n         0\n         (jdbc/plan ds [\"select * from invoice where customer_id = ?\" 100]))\n14.67M\n The call to jdbc/plan returns an IReduceInit object but does not actually run the SQL. Only when the returned object is reduced is the connection obtained from the data source, the SQL executed, and the computation performed. The connection is closed automatically when the reduction is complete. The row in the reduction is an abstraction over the underlying (mutable) ResultSet object -- it is not a Clojure data structure. Because of that, you can simply access the columns via their SQL labels as shown -- you do not need to use the column-qualified name, and you do not need to worry about the database returning uppercase column names (SQL labels are not case sensitive). Here's the same computation rewritten using transduce: user=> (transduce\n         (map #(* (:unit_price %) (:unit_count %)))\n         +\n         0\n         (jdbc/plan ds [\"select * from invoice where customer_id = ?\" 100]))\n14.67M\n or composing the transforms: user=> (transduce\n         (comp (map (juxt :unit_price :unit_count))\n               (map #(apply * %)))\n         +\n         0\n         (jdbc/plan ds [\"select * from invoice where customer_id = ?\" 100]))\n14.67M\n If you just wanted the total item count: user=> (transduce\n         (map :unit_count)\n         +\n         0\n         (jdbc/plan ds [\"select * from invoice where customer_id = ?\" 100]))\n11\n You can use other functions that perform reductions to process the result of plan, such as obtaining a set of unique products from an invoice: user=> (into #{}\n             (map :product)\n             (jdbc/plan ds [\"select * from invoice where customer_id = ?\" 100]))\n#{\"apple\" \"banana\" \"cucumber\"}\n Any operation that can perform key-based lookup can be used here without creating hash maps from the rows: get, contains?, find (returns a MapEntry of whatever key you requested and the corresponding column value), or direct keyword access as shown above. Any operation that would require a Clojure hash map, such as assoc or anything that invokes seq (keys, vals), will cause the full row to be expanded into a hash map, such as produced by execute! or execute-one!, which implements Datafiable and Navigable and supports lazy navigation via foreign keys, explained in datafy, nav, and the :schema option. This means that select-keys can be used to create regular Clojure hash map from (a subset of) columns in the row, without realizing the row, and it will not implement Datafiable or Navigable. If you wish to create a Clojure hash map that supports that lazy navigation, you can call next.jdbc.result-set/datafiable-row, passing in the current row, a connectable, and an options hash map, just as you passed into plan. Compare the difference in output between these four expressions (see below for a simpler way to do this): ;; selects specific keys (as simple keywords):\nuser=> (into []\n             (map #(select-keys % [:id :product :unit_price :unit_cost :customer_id]))\n             (jdbc/plan ds [\"select * from invoice where customer_id = ?\" 100]))\n;; selects specific keys (as qualified keywords):\nuser=> (into []\n             (map #(select-keys % [:invoice/id :invoice/product\n                                   :invoice/unit_price :invoice/unit_cost\n                                   :invoice/customer_id]))\n             (jdbc/plan ds [\"select * from invoice where customer_id = ?\" 100]))\n;; selects specific keys (as qualified keywords -- ignoring the table name):\nuser=> (into []\n             (map #(select-keys % [:foo/id :bar/product\n                                   :quux/unit_price :wibble/unit_cost\n                                   :blah/customer_id]))\n             (jdbc/plan ds [\"select * from invoice where customer_id = ?\" 100]))\n;; do not do this:\nuser=> (into []\n             (map #(into {} %))\n             (jdbc/plan ds [\"select * from invoice where customer_id = ?\" 100]))\n;; do this if you just want realized rows with default qualified names:\nuser=> (into []\n             (map #(rs/datafiable-row % ds {}))\n             (jdbc/plan ds [\"select * from invoice where customer_id = ?\" 100]))\n The latter produces a vector of hash maps, just like the result of execute!, where each \"row\" follows the case conventions of the database, the keys are qualified by the table name, and the hash map is datafiable and navigable. The third expression produces a result that looks identical but has stripped all the metadata away: it has still called rs/datafiable-row to fully-realize a datafiable and navigable hash map but it has then \"poured\" that into a new, empty hash map, losing the metadata. In addition to the hash map operations described above, the abstraction over the ResultSet can also respond to a couple of functions in next.jdbc.result-set: next.jdbc.result-set/row-number - returns the 1-based row number, by calling .getRow() on the ResultSet, next.jdbc.result-set/column-names - returns a vector of column names from the ResultSet, as created by the result set builder specified, next.jdbc.result-set/metadata - returns the ResultSetMetaData object, datafied (so the result will depend on whether you have required next.jdbc.datafy). Note: Apache Derby requires the following options to be provided in order to call .getRow() (and therefore row-number): {:concurrency :read-only, :cursors :close, :result-type :scroll-insensitive} If you realize a row, by calling datafiable-row on the abstract row passed into the reducing function, you can still call row-number and column-names on that realized row. These functions are not available on the realized rows returned from execute! or execute-one!, only within reductions over plan. The order of the column names returned by column-names matches SQL's natural order, based on the operation performed, and will also match the order of column values provided in the reduction when using an array-based result set builder (plan provides just the column values, one row at a time, when using an array-based builder, without the leading vector of column names that you would get from execute!: if you call datafiable-row on such a row, you will get a realized vector of column values). Note: since plan expects you to process the result set via reduction, you should not use it for DDL or for SQL statements that only produce update counts. As of 1.1.588, two helper functions are available to make some plan operations easier: next.jdbc.plan/select-one! -- reduces over plan and returns part of just the first row, next.jdbc.plan/select! -- reduces over plan and returns a sequence of parts of each row. select! accepts a vector of column names to extract or a function to apply to each row. It is equivalent to the following: ;; select! with vector of column names:\nuser=> (into [] (map #(select-keys % cols)) (jdbc/plan ...))\n;; select! with a function:\nuser=> (into [] (map f) (jdbc/plan ...))\n The :into option lets you override the default of [] as the first argument to into. select-one! performs the same transformation on just the first row returned from a reduction over plan, equivalent to the following: ;; select-one! with vector of column names:\nuser=> (reduce (fn [_ row] (reduced (select-keys row cols))) nil (jdbc/plan ...))\n;; select-one! with a function:\nuser=> (reduce (fn [_ row] (reduced (f row))) nil (jdbc/plan ...))\n For example: ;; select columns:\nuser=> (plan/select-one!\n        ds [:n] [\"select count(*) as n from invoice where customer_id = ?\" 100])\n{:n 3}\n;; apply a function:\nuser=> (plan/select-one!\n        ds :n [\"select count(*) as n from invoice where customer_id = ?\" 100])\n3\n Here are some of the above sequence-producing operations, showing their select! equivalent: user=> (require '[next.jdbc.plan :as plan])\nnil\nuser=> (into #{}\n             (map :product)\n             (jdbc/plan ds [\"select * from invoice where customer_id = ?\" 100]))\n#{\"apple\" \"banana\" \"cucumber\"}\n;; or:\nuser=> (plan/select! ds\n                     :product\n                     [\"select * from invoice where customer_id = ?\" 100]\n                     {:into #{}}) ; product a set, rather than a vector\n#{\"apple\" \"banana\" \"cucumber\"}\n;; selects specific keys (as simple keywords):\nuser=> (into []\n             (map #(select-keys % [:id :product :unit_price :unit_cost :customer_id]))\n             (jdbc/plan ds [\"select * from invoice where customer_id = ?\" 100]))\n;; or:\nuser=> (plan/select! ds\n                     [:id :product :unit_price :unit_cost :customer_id]\n                     [\"select * from invoice where customer_id = ?\" 100])\n;; selects specific keys (as qualified keywords):\nuser=> (into []\n             (map #(select-keys % [:invoice/id :invoice/product\n                                   :invoice/unit_price :invoice/unit_cost\n                                   :invoice/customer_id]))\n             (jdbc/plan ds [\"select * from invoice where customer_id = ?\" 100]))\n;; or:\nuser=> (plan/select! ds\n                     [:invoice/id :invoice/product\n                      :invoice/unit_price :invoice/unit_cost\n                      :invoice/customer_id]\n                     [\"select * from invoice where customer_id = ?\" 100])\n;; selects specific keys (as qualified keywords -- ignoring the table name):\nuser=> (into []\n             (map #(select-keys % [:foo/id :bar/product\n                                   :quux/unit_price :wibble/unit_cost\n                                   :blah/customer_id]))\n             (jdbc/plan ds [\"select * from invoice where customer_id = ?\" 100]))\n;; or:\nuser=> (plan/select! ds\n                     [:foo/id :bar/product\n                      :quux/unit_price :wibble/unit_cost\n                      :blah/customer_id]\n                     [\"select * from invoice where customer_id = ?\" 100])\n Note: you need to be careful when using stateful transducers, such as partition-by, when reducing over the result of plan. Since plan returns an IReduceInit, the resource management (around the ResultSet) only applies to the reduce operation: many stateful transducers have a completing function that will access elements of the result sequence -- and this will usually fail after the reduction has cleaned up the resources. This is an inherent problem with stateful transducers over resource-managing reductions with no good solution. Datasources, Connections & Transactions In the examples above, we created a datasource and then passed it into each function call. When next.jdbc is given a datasource, it creates a java.sql.Connection from it, uses it for the SQL operation (by creating and populating a java.sql.PreparedStatement from the connection and the SQL string and parameters passed in), and then closes it. If you're not using a connection pooling datasource (see below), that can be quite an overhead: setting up database connections to remote servers is not cheap! If you want to run multiple SQL operations without that overhead each time, you can create the connection yourself and reuse it across several operations using with-open and next.jdbc/get-connection: (with-open [con (jdbc/get-connection ds)]\n  (jdbc/execute! con ...)\n  (jdbc/execute! con ...)\n  (into [] (map :column) (jdbc/plan con ...)))\n If any of these operations throws an exception, the connection will still be closed but operations prior to the exception will have already been committed to the database. If you want to reuse a connection across multiple operations but have them all rollback if an exception occurs, you can use next.jdbc/with-transaction: (jdbc/with-transaction [tx ds]\n  (jdbc/execute! tx ...)\n  (jdbc/execute! tx ...)\n  (into [] (map :column) (jdbc/plan tx ...)))\n If with-transaction is given a datasource, it will create and close the connection for you. If you pass in an existing connection, with-transaction will set up a transaction on that connection and, after either committing or rolling back the transaction, will restore the state of the connection and leave it open: (with-open [con (jdbc/get-connection ds)]\n  (jdbc/execute! con ...) ; committed\n  (jdbc/with-transaction [tx con] ; will commit or rollback this group:\n    (jdbc/execute! tx ...)\n    (jdbc/execute! tx ...)\n    (into [] (map :column) (jdbc/plan tx ...)))\n  (jdbc/execute! con ...)) ; committed\n You can read more about working with transactions further on in the documentation. Note: Because get-datasource and get-connection return plain JDBC objects (javax.sql.DataSource and java.sql.Connection respectively), next.jdbc/with-options cannot flow options across those calls, so if you are explicitly managing connections or transactions as above, you would need to have local bindings for the wrapped versions: (with-open [con (jdbc/get-connection ds)]\n  (let [con-opts (jdbc/with-options con some-options)]\n    (jdbc/execute! con-opts ...) ; committed\n    (jdbc/with-transaction [tx con-opts] ; will commit or rollback this group:\n      (let [tx-opts (jdbc/with-options tx (:options con-opts)]\n        (jdbc/execute! tx-opts ...)\n        (jdbc/execute! tx-opts ...)\n        (into [] (map :column) (jdbc/plan tx-opts ...))))\n    (jdbc/execute! con-opts ...))) ; committed\n Prepared Statement Caveat Not all databases support using a PreparedStatement for every type of SQL operation. You might have to create a java.sql.Statement instead, directly from a java.sql.Connection and use that, without parameters, in plan, execute!, or execute-one!. See the following example: (require '[next.jdbc.prepare :as prep])\n\n(with-open [con (jdbc/get-connection ds)]\n  (jdbc/execute! (prep/statement con) [\"...just a SQL string...\"])\n  (jdbc/execute! con [\"...some SQL...\" \"and\" \"parameters\"]) ; uses PreparedStatement\n  (into [] (map :column) (jdbc/plan (prep/statement con) [\"...\"])))\n Connection Pooling next.jdbc makes it easy to use either HikariCP or c3p0 for connection pooling. First, you need to add the connection pooling library as a dependency, e.g., com.zaxxer/HikariCP {:mvn/version \"3.3.1\"}\n;; or:\ncom.mchange/c3p0 {:mvn/version \"0.9.5.4\"}\n Check those libraries' documentation for the latest version to use! Then import the appropriate classes into your code: (ns my.main\n  (:require [next.jdbc :as jdbc]\n            [next.jdbc.connection :as connection])\n  (:import (com.zaxxer.hikari HikariDataSource)\n           ;; or:\n           (com.mchange.v2.c3p0 ComboPooledDataSource PooledDataSource)))\n Finally, create the connection pooled datasource. db-spec here contains the regular next.jdbc options (:dbtype, :dbname, and maybe :host, :port, :classname etc -- or the :jdbcUrl format mentioned above). Those are used to construct the JDBC URL that is passed into the datasource object (by calling .setJdbcUrl on it). You can also specify any of the connection pooling library's options, as mixed case keywords corresponding to any simple setter methods on the class being passed in, e.g., :connectionTestQuery, :maximumPoolSize (HikariCP), :maxPoolSize, :preferredTestQuery (c3p0). Some important notes regarding HikariCP: Authentication credentials must use :username (if you are using c3p0 or regular, non-pooled, connections, then the db-spec hash map must contain :user). When using :dbtype \"jtds\", you must specify :connectionTestQuery \"SELECT 1\" (or some other query to verify the health of a connection) because the jTDS JDBC driver does not implement .isValid() so HikariCP requires a specific test query instead (c3p0 does not rely on this method so it works with jTDS without needing :preferredTestQuery). When using PostgreSQL, and trying to set a default :schema via HikariCP, you will need to specify :connectionInitSql \"COMMIT;\" until this HikariCP issue is addressed. You will generally want to create the connection pooled datasource at the start of your program (and close it before you exit, although that's not really important since it'll be cleaned up when the JVM shuts down): (defn -main [& args]\n  (with-open [^HikariDataSource ds (connection/->pool HikariDataSource db-spec)]\n    (jdbc/execute! ds ...)\n    (jdbc/execute! ds ...)\n    (do-other-stuff ds args)\n    (into [] (map :column) (jdbc/plan ds ...))))\n;; or:\n(defn -main [& args]\n  (with-open [^PooledDataSource ds (connection/->pool ComboPooledDataSource db-spec)]\n    (jdbc/execute! ds ...)\n    (jdbc/execute! ds ...)\n    (do-other-stuff ds args)\n    (into [] (map :column) (jdbc/plan ds ...))))\n You only need the type hints on ds if you plan to call methods on it via Java interop, such as .close (or using with-open to auto-close it) and you want to avoid reflection. If you are using Component, a connection pooled datasource is a good candidate since it has a start/stop lifecycle. next.jdbc has support for Component built-in, via the next.jdbc.connection/component function which creates a Component-compatible entity which you can start and then invoke as a function with no arguments to obtain the DataSource within. (ns my.data.program\n  (:require [com.stuartsierra.component :as component]\n            [next.jdbc :as jdbc]\n            [next.jdbc.connection :as connection])\n  (:import (com.zaxxer.hikari HikariDataSource)))\n\n;; HikariCP requires :username instead of :user in the db-spec:\n(def ^:private db-spec {:dbtype \"...\" :dbname \"...\" :username \"...\" :password \"...\"})\n\n(defn -main [& args]\n  ;; connection/component takes the same arguments as connection/->pool:\n  (let [ds (component/start (connection/component HikariDataSource db-spec))]\n    (try\n      ;; \"invoke\" the data source component to get the javax.sql.DataSource:\n      (jdbc/execute! (ds) ...)\n      (jdbc/execute! (ds) ...)\n      ;; can pass the data source component around other code:\n      (do-other-stuff ds args)\n      (into [] (map :column) (jdbc/plan (ds) ...))\n      (finally\n        ;; stopping the component will close the connection pool:\n        (component/stop ds)))))\n Working with Additional Data Types By default, next.jdbc relies on the JDBC driver to handle all data type conversions when reading from a result set (to produce Clojure values from SQL values) or setting parameters (to produce SQL values from Clojure values). Sometimes that means that you will get back a database-specific Java object that would need to be manually converted to a Clojure data structure, or that certain database column types require you to manually construct the appropriate database-specific Java object to pass into a SQL operation. You can usually automate those conversions using either the ReadableColumn protocol (for converting database-specific types to Clojure values) or the SettableParameter protocol (for converting Clojure values to database-specific types). In particular, PostgreSQL does not seem to perform a conversion from java.util.Date to a SQL data type automatically. You can require the next.jdbc.date-time namespace to enable that conversion. If you are working with Java Time, some JDBC drivers will automatically convert java.time.Instant (and java.time.LocalDate and java.time.LocalDateTime) to a SQL data type automatically, but others will not. Requiring next.jdbc.date-time will enable those automatic conversions for all databases. Note: next.jdbc.date-time also provides functions you can call to enable automatic conversion of SQL date/timestamp types to Clojure data types when reading result sets. If you need specific conversions beyond that to happen automatically, consider extending the ReadableColumn protocol, mentioned above. The next.jdbc.types namespace provides over three dozen convenience functions for \"type hinting\" values so that the JDBC driver might automatically handle some conversions that the default parameter setting function does not. Each function is named for the corresponding SQL type, prefixed by as-: as-bigint, as-other, as-real, etc. An example of where this helps is when dealing with PostgreSQL enumerated types: the default behavior, when passed a string that should correspond to an enumerated type, is to throw an exception that column \"...\" is of type ... but expression is of type character varying. You can wrap such strings with (as-other \"...\") which tells PostgreSQL to treat this as java.sql.Types/OTHER when setting the parameter. Processing Database Metadata JDBC provides several features that let you introspect the database to obtain lists of tables, views, and so on. next.jdbc does not provide any specific functions for this but you can easily get this metadata from a java.sql.Connection and turn it into Clojure data as follows: (with-open [con (p/get-connection ds opts)]\n  (-> (.getMetaData con) ; produces java.sql.DatabaseMetaData\n      ;; return a java.sql.ResultSet describing all tables and views:\n      (.getTables nil nil nil (into-array [\"TABLE\" \"VIEW\"]))\n      (rs/datafiable-result-set ds opts)))\n Several methods on DatabaseMetaData return a ResultSet object, e.g., .getCatalogs(), .getClientInfoProperties(), .getSchemas(). All of those can be handled in a similar manner to the above. See the Oracle documentation for java.sql.DatabaseMetaData (Java 11) for more details. Support from Specs As you are developing with next.jdbc, it can be useful to have assistance from clojure.spec in checking calls to next.jdbc's functions, to provide explicit argument checking and/or better error messages for some common mistakes, e.g., trying to pass a plain SQL string where a vector (containing a SQL string, and no parameters) is expected. You can enable argument checking for functions in next.jdbc, next.jdbc.connection, next.jdbc.prepare, and next.jdbc.sql by requiring the next.jdbc.specs namespace and instrumenting the functions. A convenience function is provided: (require '[next.jdbc.specs :as specs])\n(specs/instrument) ; instruments all next.jdbc API functions\n\n(jdbc/execute! ds \"SELECT * FROM fruit\")\nCall to #'next.jdbc/execute! did not conform to spec.\n In the :problems output, you'll see the :path [:sql :sql-params] and :pred vector? for the :val \"SELECT * FROM fruit\". Without the specs' assistance, this mistake would produce a more cryptic error, a ClassCastException, that a Character cannot be cast to a String, from inside next.jdbc.prepare. A convenience function also exists to revert that instrumentation: (specs/unstrument) ; undoes the instrumentation of all next.jdbc API functions\n Friendly SQL Functions :>"}
  {:name "Friendly SQL Functions",
   :path
   "/d/seancorfield/next.jdbc/1.2.659/doc/friendly-sql-functions",
   :doc
   "Friendly SQL Functions In Getting Started, we used execute! and execute-one! for all our SQL operations, except when we were reducing a result set. These functions (and plan) all expect a \"connectable\" and a vector containing a SQL string followed by any parameter values required. A \"connectable\" can be a javax.sql.DataSource, a java.sql.Connection, or something that can produce a datasource (when get-datasource is called on it). It can also be a java.sql.PreparedStatement but we'll cover that a bit later... Because string-building isn't always much fun, next.jdbc.sql also provides some \"friendly\" functions for basic CRUD operations: insert! and insert-multi! -- for inserting one or more rows into a table -- \"Create\", query -- an alias for execute! when using a vector of SQL and parameters -- \"Read\", update! -- for updating one or more rows in a table -- \"Update\", delete! -- for deleting one or more rows in a table -- \"Delete\". as well as these more specific \"read\" operations: find-by-keys -- a query on one or more column values, specified as a hash map or WHERE clause, get-by-id -- a query to return a single row, based on a single column value, usually the primary key. These functions are described in more detail below. They are deliberately simple and intended to cover only the most common, basic SQL operations. The primary API (plan, execute!, execute-one!) is the recommended approach for everything beyond that. If you need more expressiveness, consider one of the following libraries to build SQL/parameter vectors, or run queries: HoneySQL -- a composable DSL for creating SQL/parameter vectors from Clojure data structures seql -- a simplified EQL-inspired query language, built on next.jdbc (as of release 0.1.6) SQLingvo -- a composable DSL for creating SQL/parameter vectors Walkable -- full EQL query language support for creating SQL/parameter vectors If you prefer to write your SQL separately from your code, take a look at HugSQL -- HugSQL documentation -- which has a next.jdbc adapter, as of version 0.5.1. See below for a \"quick start\" for using HugSQL with next.jdbc. insert! Given a table name (as a keyword) and a hash map of column names and values, this performs a single row insertion into the database: (sql/insert! ds :address {:name \"A. Person\" :email \"albert@person.org\"})\n;; equivalent to\n(jdbc/execute-one! ds [\"INSERT INTO address (name,email) VALUES (?,?)\"\n                       \"A.Person\" \"albert@person.org\"] {:return-keys true})\n insert-multi! Given a table name (as a keyword), a vector of column names, and a vector of row value vectors, this performs a multi-row insertion into the database: (sql/insert-multi! ds :address\n  [:name :email]\n  [[\"Stella\" \"stella@artois.beer\"]\n   [\"Waldo\" \"waldo@lagunitas.beer\"]\n   [\"Aunt Sally\" \"sour@lagunitas.beer\"]])\n;; equivalent to\n(jdbc/execute! ds [\"INSERT INTO address (name,email) VALUES (?,?), (?,?), (?,?)\"\n                   \"Stella\" \"stella@artois.beer\"\n                   \"Waldo\" \"waldo@lagunitas.beer\"\n                   \"Aunt Sally\" \"sour@lagunitas.beer\"] {:return-keys true})\n Note: this expands to a single SQL statement with placeholders for every value being inserted -- for large sets of rows, this may exceed the limits on SQL string size and/or number of parameters for your JDBC driver or your database. Several databases have a limit of 1,000 parameter placeholders. Oracle does not support this form of multi-row insert, requiring a different syntax altogether. You should look at next.jdbc/execute-batch! for an alternative approach. query Given a vector of SQL and parameters, execute it: (sql/query ds [\"select * from address where name = ?\" \"Stella\"])\n;; equivalent to\n(jdbc/execute! ds [\"SELECT * FROM address WHERE name = ?\" \"Stella\"])\n Note that the single argument form of execute!, taking just a PreparedStatement, is not supported by query. update! Given a table name (as a keyword), a hash map of columns names and values to set, and either a hash map of column names and values to match on or a vector containing a partial WHERE clause and parameters, perform an update operation on the database: (sql/update! ds :address {:name \"Somebody New\"} {:id 2})\n;; equivalent to\n(sql/update! ds :address {:name \"Somebody New\"} [\"id = ?\" 2])\n;; equivalent to\n(jdbc/execute-one! ds [\"UPDATE address SET name = ? WHERE id = ?\"\n                       \"Somebody New\" 2])\n delete! Given a table name (as a keyword) and either a hash map of column names and values to match on or a vector containing a partial WHERE clause and parameters, perform a delete operation on the database: (sql/delete! ds :address {:id 8})\n;; equivalent to\n(sql/delete! ds :address [\"id = ?\" 8])\n;; equivalent to\n(jdbc/execute-one! ds [\"DELETE FROM address WHERE id = ?\" 8])\n find-by-keys Given a table name (as a keyword) and either a hash map of column names and values to match on or a vector containing a partial WHERE clause and parameters, execute a query on the database: (sql/find-by-keys ds :address {:name \"Stella\" :email \"stella@artois.beer\"})\n;; equivalent to\n(sql/find-by-keys ds :address [\"name = ? AND email = ?\"\n                               \"Stella\" \"stella@artois.beer\"])\n;; equivalent to\n(jdbc/execute! ds [\"SELECT * FROM address WHERE name = ? AND email = ?\"\n                   \"Stella\" \"stella@artois.beer\"])\n The default behavior is to return all the columns in each row. You can specify a subset of columns to return using the :columns option. It takes a vector and each element of the vector can be: a simple keyword representing the column name (:column-fn will be applied, if provided), a pair of keywords representing the column name and an alias (:column-fn will be applied to both, if provided), a pair consisting of a string and a keyword, representing a SQL expression and an alias (:column-fn will be applied to the alias, if provided). (sql/find-by-keys ds :address {:name \"Stella\"} {:columns [[:email :address]]})\n;; equivalent to\n(jdbc/execute! ds [\"SELECT email AS address FROM address WHERE name = ?\"\n                   \"Stella\"])\n\n(sql/find-by-keys ds :address {:name \"Stella\"} {:columns [[\"count(*)\" :n]]})\n;; equivalent to\n(jdbc/execute! ds [\"SELECT count(*) AS n FROM address WHERE name = ?\"\n                   \"Stella\"])\n Note: the SQL string provided for a column is copied exactly as-is into the generated SQL -- you are responsible for ensuring it is legal SQL! find-by-keys supports an :order-by option which can specify a vector of column names to sort the results by. Elements may be column names or pairs of a column name and the direction to sort: :asc or :desc: (sql/find-by-keys ds :address\n                  {:name \"Stella\" :email \"stella@artois.beer\"}\n                  {:order-by [[:id :desc]]})\n;; equivalent to\n(jdbc/execute! ds [\"SELECT * FROM address WHERE name = ? AND email = ? ORDER BY id DESC\"\n                   \"Stella\" \"stella@artois.beer\"])\n find-by-keys also supports basic pagination with :offset and :fetch options which both accept numeric values and adds OFFSET ? ROWS FETCH NEXT ? ROWS ONLY to the generated query. To support MySQL and SQLite, you can specify :limit instead :fetch which adds LIMIT ? OFFSET ? to the generated query instead. If you want to match all rows in a table -- perhaps with the pagination options in effect -- you can pass the keyword :all instead of either a hash map of column names and values or a vector containing a partial WHERE clause and parameters. (sql/find-by-keys ds :address :all {:order-by [:id] :offset 5 :fetch 10})\n;; equivalent to\n(jdbc/execute! ds [\"SELECT * FROM address ORDER BY id OFFSET ? ROWS FETCH NEXT ? ROWS ONLY\" 5 10])\n If no rows match, find-by-keys returns [], just like execute!. get-by-id Given a table name (as a keyword) and a primary key value, with an optional primary key column name, execute a query on the database: (sql/get-by-id ds :address 2)\n;; equivalent to\n(sql/get-by-id ds :address 2 {}) ; empty options map\n;; equivalent to\n(sql/get-by-id ds :address 2 :id {}) ; empty options map\n;; equivalent to\n(jdbc/execute-one! ds [\"SELECT * FROM address WHERE id = ?\" 2])\n Note that in order to override the default primary key column name (of :id), you need to specify both the column name and an options hash map. If no rows match, get-by-id returns nil, just like execute-one!. Table & Column Entity Names By default, next.jdbc.sql functions construct SQL strings with the entity names exactly matching the (unqualified) keywords provided. If you are trying to use a table name or column name that is a reserved name in SQL for your database, you will need to tell those functions to quote those names. The namespace next.jdbc.quoted provides five functions that cover the most common types of entity quoting, and a modifier function for quoting dot-separated names (e.g., that include schemas): ansi -- wraps entity names in double quotes, mysql -- wraps entity names in back ticks, sql-server -- wraps entity names in square brackets, oracle -- an alias for ansi, postgres -- an alias for ansi. schema -- wraps a quoting function to support dbo.table style entity names. These quoting functions can be provided to any of the friendly SQL functions above using the :table-fn and :column-fn options, in a hash map provided as the (optional) last argument in any call. If you want to provide your own entity naming function, you can do that: (defn snake-case [s] (str/replace s #\"-\" \"_\"))\n\n(sql/insert! ds :my-table {:some \"data\"} {:table-fn snake-case})\n next.jdbc provides snake-kebab-opts and unqualified-snake-kebab-opts which are hash maps containing :column-fn and :table-fn that use the ->snake_case function from the camel-snake-kebab library which performs a more sophisticated transformation. Note: The entity naming function is passed a string, the result of calling name on the keyword passed in. Also note that the default quoting functions do not handle schema-qualified names, such as dbo.table_name -- sql-server would produce [dbo.table_name] from that. Use the schema function to wrap the quoting function if you need that behavior, e.g,. {:table-fn (schema sql-server)} which would produce [dbo].[table_name]. HugSQL Quick Start Here's how to get up and running quickly with next.jdbc and HugSQL. For more detail, consult the HugSQL documentation. Add the following dependencies to your project (in addition to com.github.seancorfield/next.jdbc and whichever JDBC drivers you need):         com.layerware/hugsql-core {:mvn/version \"0.5.1\"}\n        com.layerware/hugsql-adapter-next-jdbc {:mvn/version \"0.5.1\"}\n Check the HugSQL documentation for the latest versions to use! Write your SQL in .sql files that are on the classpath (somewhere under src or resources). For our purposes, assume a SQL file db/example.sql containing your first set of definitions. In your namespace, add these requires:             [hugsql.core :as hugsql]\n            [hugsql.adapter.next-jdbc :as adapter]\n            [next.jdbc :as jdbc]\n At program startup you'll need to call these functions (either at the top-level of your namespace on inside your initialization function): ;; regular SQL functions\n(hugsql/def-db-fns \"db/example.sql\"\n                   {:adapter (adapter/hugsql-adapter-next-jdbc)})\n\n;; development/advanced usage functions that produce a vector containing\n;; SQL and parameters that could be passed to jdbc/execute! etc\n(hugsql/def-sqlvec-fns \"db/example.sql\"\n                       {:adapter (adapter/hugsql-adapter-next-jdbc)})\n Those calls will add function definitions to that namespace based on what is in the .sql files. Now set up your db-spec and datasource as usual with next.jdbc: (def db-spec {:dbtype \"h2:mem\" :dbname \"example\"}) ; assumes H2 driver in deps.edn\n\n(def ds (jdbc/get-datasource db-spec))\n Borrowing from Princess Bride examples from the HugSQL documentation, you can now do things like this: (create-characters-table ds)\n;;=> [#:next.jdbc{:update-count 0}]\n(insert-character ds {:name \"Westley\", :specialty \"love\"})\n;;=> 1\n By default, for compatibility with their default adapter (clojure.java.jdbc), the next.jdbc adapter uses the next.jdbc.result-set/as-unqualified-lower-maps builder function. You can specify a different builder function when you pass in the adapter: ;; add require next.jdbc.result-set :as rs to your ns\n\n(hugsql/def-db-fns \"db/example.sql\"\n                   {:adapter (adapter/hugsql-adapter-next-jdbc\n                              {:builder-fn rs/as-maps})})\n\n;; now you'll get qualified as-is hash maps back:\n(character-by-id ds {:id 1})\n;;=> #:CHARACTERS{:ID 1, :NAME \"Westley\", :SPECIALTY \"love\", :CREATED_AT #inst \"2019-09-27T18:52:54.413000000-00:00\"}\n <: Getting Started | Tips & Tricks :>"}
  {:name "Tips & Tricks",
   :path "/d/seancorfield/next.jdbc/1.2.659/doc/tips-tricks",
   :doc
   "Tips & Tricks This page contains various tips and tricks that make it easier to use next.jdbc with a variety of databases. It is mostly organized by database, but there are a few that are cross-database and those are listed first. CLOB & BLOB SQL Types Columns declared with the CLOB or BLOB SQL types are typically rendered into Clojure result sets as database-specific custom types but they should implement java.sql.Clob or java.sql.Blob (as appropriate). In general, you can only read the data out of those Java objects during the current transaction, which effectively means that you need to do it either inside the reduction (for plan) or inside the result set builder (for execute! or execute-one!). If you always treat these types the same way for all columns across the whole of your application, you could simply extend next.jdbc.result-set/ReadableColumn to java.sql.Clob (and/or java.sql.Blob). Here's an example for reading CLOB into a String: (extend-protocol rs/ReadableColumn\n  java.sql.Clob\n  (read-column-by-label [^java.sql.Clob v _]\n    (with-open [rdr (.getCharacterStream v)] (slurp rdr)))\n  (read-column-by-index [^java.sql.Clob v _2 _3]\n    (with-open [rdr (.getCharacterStream v)] (slurp rdr))))\n There is a helper in next.jdbc.result-set to make this easier -- clob->string: (extend-protocol rs/ReadableColumn\n  java.sql.Clob\n  (read-column-by-label [^java.sql.Clob v _]\n    (rs/clob->string v))\n  (read-column-by-index [^java.sql.Clob v _2 _3]\n    (rs/clob->string v)))\n As noted in Result Set Builders, there is also clob-column-reader that can be used with the as-*-adapter result set builder functions. No helper or column reader is provided for BLOB data since it is expected that the semantics of any given binary data will be application specific. For a raw byte[] you could probably use:     (.getBytes v 1 (.length v)) ; BLOB has 1-based byte index!\n Consult the java.sql.Blob documentation for more ways to process it. Note: the standard MySQL JDBC driver seems to return BLOB data as byte[] instead of java.sql.Blob. Handling Timeouts JDBC provides a number of ways in which you can decide how long an operation should run before it times out. Some of these timeouts are specified in seconds and some are in milliseconds. Some are handled via connection properties (or JDBC URL parameters), some are handled via methods on various JDBC objects. Here's how to specify various timeouts using next.jdbc: connectTimeout -- can be specified via the \"db-spec\" hash map or in a JDBC URL, it is the number of milliseconds that JDBC should wait for the initial (socket) connection to complete. Database-specific (may be MySQL only?). loginTimeout -- can be set via .setLoginTimeout() on a DriverManager or DataSource, it is the number of seconds that JDBC should wait for a connection to the database to be made. next.jdbc exposes this on the javax.sql.DataSource object it reifies from calling get-datasource on a \"db-spec\" hash map or JDBC URL string. queryTimeout -- can be set via .setQueryTimeout() on a Statement (or PreparedStatement), it is the number of seconds that JDBC should wait for a SQL statement to complete. Since this is the most commonly used type of timeout, next.jdbc exposes this via the :timeout option which can be passed to any function that may construct a Statement or PreparedStatement. socketTimeout -- can be specified via the \"db-spec\" hash map or in a JDBC URL, it is the number of milliseconds that JDBC should wait for socket operations to complete. Database-specific (MS SQL Server and MySQL support this, other databases may too). Examples: ;; connectTimeout / socketTimeout via db-spec:\n(def db-spec {:dbtype \"mysql\" :dbname \"example\" :user \"root\" :password \"secret\"\n              ;; milliseconds:\n              :connectTimeout 60000 :socketTimeout 30000}))\n\n;; socketTimeout via JDBC URL:\n(def db-url (str \"jdbc:sqlserver://localhost;user=sa;password=secret\"\n                 ;; milliseconds:\n                 \";database=model;socketTimeout=10000\"))\n\n;; loginTimeout via DataSource:\n(def ds (jdbc/get-datasource db-spec))\n(.setLoginTimeout ds 20) ; seconds\n\n;; queryTimeout via options:\n(jdbc/execute! ds [\"select * from some_table\"] {:timeout 5}) ; seconds\n\n;; queryTimeout via method call:\n(let [ps (jdbc/prepare ds [\"select * from some_table\"])]\n  (.setQueryTimeout ps 10) ; seconds\n  (jdbc/execute! ps))\n Reducing and Folding with plan Most of this documentation describes using plan specifically for reducing and notes that you can avoid the overhead of realizing rows from the ResultSet into Clojure data structures if your reducing function uses only functions that get column values by name. If you perform any function on the row that would require an actual hash map or a sequence, the row will be realized into a full Clojure hash map via the builder function passed in the options (or via next.jdbc.result-set/as-maps by default). One of the benefits of reducing over plan is that you can stream very large result sets, very efficiently, without having the entire result set in memory (assuming your reducing function doesn't build a data structure that is too large!). See the tips below on Streaming Result Sets. The result of plan is also foldable in the clojure.core.reducers sense. While you could use execute! to produce a vector of fully-realized rows as hash maps and then fold that vector (Clojure's vectors support fork-join parallel reduce-combine), that wouldn't be possible for very large result sets. If you fold the result of plan, the result set will be partitioned and processed using fork-join parallel reduce-combine. Unlike reducing over plan, each row is realized into a Clojure data structure and each batch is forked for reduction as soon as that many rows have been realized. By default, fold's batch size is 512 but you can specify a different value in the 4-arity call. Once the entire result set has been read, the last (partial) batch is forked for reduction. The combining operations are forked and interleaved with the reducing operations, so the order (of forked tasks) is batch-1, batch-2, combine-1-2, batch-3, combine-1&2-3, batch-4, combine-1&2&3-4, etc. The amount of parallelization you get will depend on many factors including the number of processors, the speed of your reducing function, the speed of your combining function, and the speed with which result sets can actually be streamed from your database. There is no back pressure here so if your reducing function is slow, you may end up with more of the realized result set in memory than your system can cope with. MS SQL Server In MS SQL Server, the generated key from an insert comes back as :GENERATED_KEYS. By default, you won't get table names as qualifiers with Microsoft's JDBC driver (you might with the jTDS drive -- I haven't tried that recently). See this MSDN forum post about .getTableName() for details. According to one of the answers posted there, if you specify :result-type and :concurrency in the options for execute!, execute-one!, plan, or prepare, that will cause SQL Server to return table names for columns. :result-type needs to be :scoll-sensitive or :scroll-insensitive for this to work. :concurrency can be :read-only or :updatable. MS SQL Server supports execution of multiple statements when surrounded by begin/end and can return multiple result sets, when requested via :multi-rs true on execute!. (jdbc/execute! db-spec [\"begin select * from table1; select * from table2; end\"] {:multi-rs true})\n;; vector of result sets:\n=> [[{.. table1 row ..} {.. table1 row ..}]\n    [{.. table2 row ..} {.. table2 row ..} {..}]]\n MySQL & MariaDB In MySQL, the generated key from an insert comes back as :GENERATED_KEY. In MariaDB, the generated key from an insert comes back as :insert_id. MySQL generally stores tables as files so they are case-sensitive if your O/S is (Linux) or case-insensitive if your O/S is not (Mac, Windows) but the column names are generally case-insensitive. This can matter when if you use next.jdbc.result-set/as-lower-maps because that will lower-case the table names (as well as the column names) so if you are round-tripping based on the keys you get back, you may produce an incorrect table name in terms of case. You'll also need to be careful about :table-fn/:column-fn because of this. It's also worth noting that column comparisons are case-insensitive so WHERE foo = 'BAR' will match \"bar\" or \"BAR\" etc. MySQL has a connection option, :allowMultiQueries true, that allows you to pass multiple SQL statements in a single operation and can return multiple result sets, when requested via :multi-rs true. (def db-spec {:dbtype \"mysql\" .. :allowMultiQueries true})\n;; equivalent to allowMultiQueries=true in the JDBC URL\n(jdbc/execute! db-spec [\"select * from table1; select * from table2\"] {:multi-rs true})\n;; vector of result sets:\n=> [[{.. table1 row ..} {.. table1 row ..}]\n    [{.. table2 row ..} {.. table2 row ..} {..}]]\n Compare this with MS SQL Server above: MySQL does not support begin/end here. This is not the default behavior because allowing multiple statements in a single operation is generally considered a bit of a risk as it can make it easier for SQL injection attacks to be performed. Batch Statements Even when using next.jdbc/execute-batch!, MySQL will still send multiple statements to the database unless you specify :rewriteBatchedStatements true as part of the db-spec hash map or JDBC URL when the datasource is created. Streaming Result Sets You should be able to get MySQL to stream very large result sets (when you are reducing over plan) by setting the following options: :fetch-size Integer/MIN_VALUE -- when running plan (or when creating a PreparedStatement). Note: it's possible that other options may be required as well -- I have not verified this yet -- see, for example, the additional options PostgreSQL requires, below. Oracle Ah, dear old Oracle! Over the years of maintaining clojure.java.jdbc and now next.jdbc, I've had all sorts of bizarre and non-standard behavior reported from Oracle users. The main issue I'm aware of with next.jdbc is that Oracle's JDBC drivers all return an empty string from ResultSetMetaData.getTableName() so you won't get qualified keywords in the result set hash maps. Sorry! PostgreSQL When you use :return-keys true with execute! or execute-one! (or you use insert!), PostgreSQL returns the entire inserted row (unlike nearly every other database that just returns any generated keys!). If you have a query where you want to select where a column is IN a sequence of values, you can use col = ANY(?) with a native array of the values instead of IN (?,?,?,,,?) and a sequence of values. What does this mean for your use of next.jdbc? In plan, execute!, and execute-one!, you can use col = ANY(?) in the SQL string and a single primitive array parameter, such as (int-array [1 2 3 4]). That means that in next.jdbc.sql's functions that take a where clause (find-by-keys, update!, and delete!) you can specify [\"col = ANY(?)\" (int-array data)] for what would be a col IN (?,?,?,,,?) where clause for other databases and require multiple values. Batch Statements Even when using next.jdbc/execute-batch!, PostgreSQL will still send multiple statements to the database unless you specify :reWriteBatchedInserts true as part of the db-spec hash map or JDBC URL when the datasource is created. Streaming Result Sets You can get PostgreSQL to stream very large result sets (when you are reducing over plan) by setting the following options: :auto-commit false -- when opening the connection :fetch-size 4000, :concurrency :read-only, :cursors :close, :result-type :forward-only -- when running plan (or when creating a PreparedStatement). Working with Arrays ResultSet protocol extension to read SQL arrays as Clojure vectors. (import  '[java.sql Array])\n(require '[next.jdbc.result-set :as rs])\n\n(extend-protocol rs/ReadableColumn\n  Array\n  (read-column-by-label [^Array v _]    (vec (.getArray v)))\n  (read-column-by-index [^Array v _ _]  (vec (.getArray v))))\n\n Insert and read vector example: create table example(\n  tags varchar[]\n);\n \n(execute-one! db-spec\n  [\"insert into example(tags) values (?)\"\n    (into-array String [\"tag1\" \"tag2\"])])\n\n(execute-one! db-spec\n  [\"select * from example limit 1\"])\n\n;; => #:example{:tags [\"tag1\" \"tag2\"]}\n Note: PostgreSQL JDBC driver supports only 7 primitive array types, but not array types like UUID[] - PostgreSQL Extensions to the JDBC API. Working with Date and Time By default, PostgreSQL's JDBC driver does not always perform conversions from java.util.Date to a SQL data type. You can enable this by extending SettableParameter to the appropriate (Java) types, or by simply requiring next.jdbc.date-time. In addition, if you want java.time.Instant, java.time.LocalDate, and java.time.LocalDateTime to be automatically converted to SQL data types, requiring next.jdbc.date-time will enable those as well (by extending SettableParameter for you). next.jdbc.date-time also includes functions that you can call at application startup to extend ReadableColumn to either return java.time.Instant or java.time.LocalDate/java.time.LocalDateTime (as well as a function to restore the default behavior of returning java.sql.Date and java.sql.Timestamp). Working with Interval Postgres has a nonstandard SQL type Interval that is implemented in the Postgres driver as the org.postgresql.util.PGInterval type. In many cases you would want to work with intervals as java.time.Duration type by default. You can support Duration instances by extending SettableParameter to the java.time.Duration type. Conversely you can support converting PGIntervals back to Durations by extending ReadableColumn to the org.postgresql.util.PGInterval type. (import '[org.postgresql.util PGInterval])\n(import '[java.sql PreparedStatement])\n(import '[java.time Duration])\n(require '[next.jdbc.result-set :as rs])\n(require '[next.jdbc.prepare :as p])\n\n(defn ->pg-interval\n  \"Takes a Dudration instance and converts it into a PGInterval\n   instance where the interval is created as a number of seconds.\"\n  [^java.time.Duration duration]\n  (doto (PGInterval.)\n    (.setSeconds (.getSeconds duration))))\n\n(extend-protocol p/SettableParameter\n  ;; Convert durations to PGIntervals before inserting into db\n  java.time.Duration\n  (set-parameter [^java.time.Duration v ^PreparedStatement s ^long i]\n    (.setObject s i (->pg-interval v))))\n\n\n(defn <-pg-interval\n  \"Takes a PGInterval instance and converts it into a Duration\n   instance. Ignore sub-second units.\"\n  [^org.postgresql.util.PGInterval interval]\n  (-> Duration/ZERO\n      (.plusSeconds (.getSeconds interval))\n      (.plusMinutes (.getMinutes interval))\n      (.plusHours (.getHours interval))\n      (.plusDays (.getDays interval))))\n\n(extend-protocol rs/ReadableColumn\n  ;; Convert PGIntervals back to durations\n  org.postgresql.util.PGInterval\n  (read-column-by-label [^org.postgresql.util.PGInterval v _]\n    (<-pg-interval v))\n  (read-column-by-index [^org.postgresql.util.PGInterval v _2 _3]\n    (<-pg-interval v)))\n Working with Enumerated Types PostgreSQL has a SQL extension for defining enumerated types and the default set-parameter implementation will not work for those. You can use next.jdbc.types/as-other to wrap string values in a way that the JDBC driver will convert them to enumerated type values: CREATE TYPE language AS ENUM('en','fr','de');\n\nCREATE TABLE person (\n  ...\n  speaks language NOT NULL,\n  ...\n);\n (require '[next.jdbc.sql :as sql]\n         '[next.jdbc.types :refer [as-other]])\n\n(sql/insert! ds :person {:speaks (as-other \"fr\")})\n That call produces a vector [\"fr\"] with metadata that implements set-parameter such that .setObject() is called with java.sql.Types/OTHER which allows PostgreSQL to \"convert\" the string \"fr\" to the corresponding language enumerated type value. Working with JSON and JSONB PostgreSQL has good support for storing, querying and manipulating JSON data. Basic Clojure data structures (lists, vectors, and maps) transform pretty well to JSON data. With a little help next.jdbc can automatically convert Clojure data to JSON and back for us. First we define functions for JSON encoding and decoding. We're using metosin/jsonista in these examples but you could use any JSON library, such as Cheshire or clojure.data.json. (require '[jsonista.core :as json])\n\n;; :decode-key-fn here specifies that JSON-keys will become keywords:\n(def mapper (json/object-mapper {:decode-key-fn keyword}))\n(def ->json json/write-value-as-string)\n(def <-json #(json/read-value % mapper))\n Next we create helper functions to transform Clojure data to and from PostgreSQL Objects containing JSON: (import '(org.postgresql.util PGobject))\n\n(defn ->pgobject\n  \"Transforms Clojure data to a PGobject that contains the data as\n  JSON. PGObject type defaults to `jsonb` but can be changed via\n  metadata key `:pgtype`\"\n  [x]\n  (let [pgtype (or (:pgtype (meta x)) \"jsonb\")]\n    (doto (PGobject.)\n      (.setType pgtype)\n      (.setValue (->json x)))))\n\n(defn <-pgobject\n  \"Transform PGobject containing `json` or `jsonb` value to Clojure\n  data.\"\n  [^org.postgresql.util.PGobject v]\n  (let [type  (.getType v)\n        value (.getValue v)]\n    (if (#{\"jsonb\" \"json\"} type)\n      (when value\n        (with-meta (<-json value) {:pgtype type}))\n      value)))\n Finally we extend next.jdbc.prepare/SettableParameter and next.jdbc.result-set/ReadableColumn protocols to make the conversion between clojure data and PGobject JSON automatic: (require '[next.jdbc.prepare :as prepare])\n(require '[next.jdbc.result-set :as rs])\n\n(import  '[java.sql PreparedStatement])\n\n(set! *warn-on-reflection* true)\n\n;; if a SQL parameter is a Clojure hash map or vector, it'll be transformed\n;; to a PGobject for JSON/JSONB:\n(extend-protocol prepare/SettableParameter\n  clojure.lang.IPersistentMap\n  (set-parameter [m ^PreparedStatement s i]\n    (.setObject s i (->pgobject m)))\n\n  clojure.lang.IPersistentVector\n  (set-parameter [v ^PreparedStatement s i]\n    (.setObject s i (->pgobject v))))\n\n;; if a row contains a PGobject then we'll convert them to Clojure data\n;; while reading (if column is either \"json\" or \"jsonb\" type):\n(extend-protocol rs/ReadableColumn\n  org.postgresql.util.PGobject\n  (read-column-by-label [^org.postgresql.util.PGobject v _]\n    (<-pgobject v))\n  (read-column-by-index [^org.postgresql.util.PGobject v _2 _3]\n    (<-pgobject v)))\n Inserting and Querying JSON Let's assume we have following table: create table demo (\n  id          serial primary key,\n  doc_jsonb   jsonb,\n  doc_json    json\n)\n We can now insert Clojure data into json and jsonb fields: (require '[next.jdbc :as jdbc])\n(require '[next.jdbc.sql :as sql])\n\n(def db { ...db-spec here... })\n(def ds (jdbc/get-datasource db))\n\n(def test-map\n  {:some-key \"some val\" :nested {:a 1} :null-val nil :vector [1 2 3]})\n\n(def data1\n  {:doc_jsonb test-map\n   :doc_json  (with-meta test-map {:pgtype \"json\"})})\n\n(sql/insert! ds :demo data1)\n\n(def test-vector\n    [{:a 1} nil 2 \"lalala\" []])\n\n(def data2\n    {:doc_jsonb test-vector\n     :doc_json  (with-meta test-vector {:pgtype \"json\"})})\n\n(sql/insert! ds :demo data2)\n And those columns are nicely transformed into Clojure data when querying: (sql/get-by-id ds :demo 1)\n=> #:demo{:id 1,\n          :doc_json\n          {:some-key \"some val\",\n           :nested {:a 1},\n           :vector [1 2 3],\n           :null-val nil},\n          :doc_jsonb\n          {:some-key \"some val\",\n           :nested {:a 1},\n           :vector [1 2 3],\n           :null-val nil}}\n\n(sql/get-by-id ds :demo 2)\n=> #:demo{:id 2,\n          :doc_json [{:a 1} nil 2 \"lalala\" []],\n          :doc_jsonb [{:a 1} nil 2 \"lalala\" []]}\n\n;; Query by value of JSON field 'some-key'\n(sql/query ds [(str \"select id, doc_jsonb::json->'nested' as foo\"\n                    \"  from demo where doc_jsonb::json->>'some-key' = ?\")\n               \"some val\"])\n=> [{:demo/id 1, :foo {:a 1}}]\n JSON or JSONB? A json column stores JSON data as strings (reading and writing is fast but manipulation is slow, field order is preserved) A jsonb column stores JSON data in binary format (manipulation is significantly faster but reading and writing is a little slower) If you're unsure whether you want to use json or jsonb, use jsonb. SQLite SQLite supports both bool and bit column types but, unlike pretty much every other database out there, it yields 0 or 1 as the column value instead of false or true. This means that with SQLite alone, you can't just rely on bool or bit columns being treated as truthy/falsey values in Clojure. You can work around this using a builder that handles reading the column directly as a Boolean: (jdbc/execute! ds [\"select * from some_table\"]\n               {:builder-fn (rs/builder-adapter\n                             rs/as-maps\n                             (fn [builder ^ResultSet rs ^Integer i]\n                               (let [rsm ^ResultSetMetaData (:rsmeta builder)]\n                                 (rs/read-column-by-index\n                                   (if (#{\"BIT\" \"BOOL\" \"BOOLEAN\"} (.getColumnTypeName rsm i))\n                                     (.getBoolean rs i)\n                                     (.getObject rs i))\n                                   rsm\n                                   i))))})\n If you are using plan, you'll most likely be accessing columns by just the label (as a keyword) and avoiding the result set building machinery completely. In such cases, you'll still get bool and bit columns back as 0 or 1 and you'll need to explicitly convert them on a per-column basis since you should know which columns need converting: (reduce (fn [acc row]\n          (conj acc (-> (select-keys row [:name :is_active])\n                        (update :is_active pos?))))\n        []\n        (jdbc/plan ds [\"select * from some_table\"]))\n <: Friendly SQL Functions | Result Set Builders :>"}
  {:name "Result Set Builders",
   :path "/d/seancorfield/next.jdbc/1.2.659/doc/result-set-builders",
   :doc
   "RowBuilder and ResultSetBuilder In Getting Started, it was noted that, by default, execute! and execute-one! return result sets as (vectors of) hash maps with namespace-qualified keys as-is. If your database naturally produces uppercase column names from the JDBC driver, that's what you'll get. If it produces mixed-case names, that's what you'll get. Note: Some databases do not return the table name in the metadata by default. If you run into this, you might try adding :ResultSetMetaDataOptions \"1\" to your db-spec (so it is passed as a property to the JDBC driver when you create connections). If your database supports that, it will perform additional work to try to add table names to the result set metadata. It has been reported that Oracle just plain old does not support table names at all in its JDBC drivers. The default builder for rows and result sets creates qualified keywords that match whatever case the JDBC driver produces. That builder is next.jdbc.result-set/as-maps but there are several options available: as-maps -- table-qualified keywords as-is, the default, e.g., :ADDRESS/ID, :myTable/firstName, as-unqualified-maps -- simple keywords as-is, e.g., :ID, :firstName, as-lower-maps -- table-qualified lower-case keywords, e.g., :address/id, :mytable/firstname, as-unqualified-lower-maps -- simple lower-case keywords, e.g., :id, :firstname, as-arrays -- table-qualified keywords as-is (vector of column names, followed by vectors of row values), as-unqualified-arrays -- simple keywords as-is, as-lower-arrays -- table-qualified lower-case keywords, as-unqualified-lower-arrays -- simple lower-case keywords. The reason behind the default is to a) be a simple transform, b) produce qualified keys in keeping with Clojure's direction (with clojure.spec etc), and c) not mess with the data. as-arrays is (slightly) faster than as-maps since it produces less data (vectors of values instead of vectors of hash maps), but the lower options will be slightly slower since they include (conditional) logic to convert strings to lower-case. The unqualified options may be slightly faster than their qualified equivalents but make no attempt to keep column names unique if your SQL joins across multiple tables. Note: This is a deliberate difference from clojure.java.jdbc which would make column names unique by appending numeric suffixes. It was always poor practice to rely on clojure.java.jdbc's renaming behavior and it added quite an overhead to result set building, which is why next.jdbc does not support it -- use explicit column aliasing in your SQL instead if you want unqualified column names! In addition, the following generic builders can take :label-fn and :qualifier-fn options to control how the label and qualified are processed. The lower variants above are implemented in terms of these, passing a lower-case function for both of those options. as-modified-maps -- table-qualified keywords, as-unqualified-modified-maps -- simple keywords, as-modified-arrays -- table-qualified keywords, as-unqualified-modified-arrays -- simple keywords. An example builder that converts snake_case database table/column names to kebab-case keywords: (defn as-kebab-maps [rs opts]\n  (let [kebab #(str/replace % #\"_\" \"-\")]\n    (result-set/as-modified-maps rs (assoc opts :qualifier-fn kebab :label-fn kebab))))\n However, a version of as-kebab-maps is built-in, as is as-unqualified-kebab-maps, which both use the ->kebab-case function from the camel-snake-kebab library with as-modified-maps and as-unqualified-modified-maps respectively. And finally there are two styles of adapters for the existing builders that let you override the default way that columns are read from result sets. The first style takes a column-reader function, which is called with the ResultSet, the ResultSetMetaData, and the column index, and is expected to read the raw column value from the result set and return it. The result is then passed through read-column-by-index (from ReadableColumn, which may be implemented directly via protocol extension or via metadata on the result of the column-reader function): as-maps-adapter -- adapts an existing map builder function with a new column reader, as-arrays-adapter -- adapts an existing array builder function with a new column reader. The default column-reader function behavior would be: (defn default-column-reader\n  [^ResultSet rs ^ResultSetMetaData rsmeta ^Integer i]\n  (.getObject rs i))\n An example column reader is provided -- clob-column-reader -- that still uses .getObject but will expand java.sql.Clob values into string (using the clob->string helper function):     {:builder-fn (result-set/as-maps-adapter\n                  result-set/as-maps\n                  result-set/clob-column-reader)}\n As of 1.1.569, the second style of adapter relies on with-column-value from RowBuilder (see below) and allows you to take complete control of the column reading process. This style takes a column-by-index-fn function, which is called with the builder itself, the ResultSet, and the column index, and is expected to read the raw column value from the result set and perform any and all processing on it, before returning it. The result is added directly to the current row with no further processing. builder-adapter -- adapts any existing builder function with a new column reading function. The default column-by-index-fn function behavior would be: (defn default-column-by-index-fn\n  [builder ^ResultSet rs ^Integer i]\n  (result-set/read-column-by-index (.getObject rs i) (:rsmeta builder) i))\n Because the builder itself is passed in, the vector of processed column names is available as (:cols builder) (in addition to the ResultSetMetaData as (:rsmeta builder)). This allows you to take different actions based on the metadata or the column name, as well as bypassing the read-column-by-index call if you wish. The older as-*-adapter functions are now implemented in terms of this builder-adapter because with-column-value abstracts away how the new column's value is added to the row being built. RowBuilder Protocol This protocol defines five functions and is used whenever next.jdbc needs to materialize a row from a ResultSet as a Clojure data structure: (->row builder) -- produces a new row (a (transient {}) by default), (column-count builder) -- returns the number of columns in each row, (with-column builder row i) -- given the row so far, fetches column i from the current row of the ResultSet, converts it to a Clojure value, and adds it to the row (for as-maps this is a call to .getObject, a call to read-column-by-index -- see the ReadableColumn protocol below, and a call to assoc!), (with-column-value builder row col v) -- given the row so far, the column name, and the column value, add the column name/value to the row in the appropriate way: this is a low-level utility, intended to be used in builders (or adapters) that want to control more of the value handling process -- in general, with-column will be implemented by calling with-column-value, (row! builder row) -- completes the row (a (persistent! row) call by default). execute! and execute-one! call these functions for each row they need to build. plan may call these functions if the reducing function causes a row to be materialized. ResultSet Protocol This protocol defines three functions and is used whenever next.jdbc needs to materialize a result set (multiple rows) from a ResultSet as a Clojure data structure: (->rs builder) -- produces a new result set (a (transient []) by default), (with-row builder rs row) -- given the result set so far and a new row, returns the updated result set (a (conj! rs row) call by default), (rs! builder rs) -- completes the result set (a (persistent! rs) call by default). Only execute! expects this protocol to be implemented. execute-one! and plan do not call these functions. Result Set Builder Functions The as-* functions described above are all implemented in terms of these protocols. They are passed the ResultSet object and the options hash map (as passed into various next.jdbc functions). They return an implementation of the protocols that is then used to build rows and the result set. Note that the ResultSet passed in is mutable and is advanced from row to row by the SQL execution function, so each time ->row is called, the underlying ResultSet object points at each new row in turn. By contrast, ->rs (which is only called by execute!) is invoked before the ResultSet is advanced to the first row. The result set builder implementation is also assumed to implement clojure.lang.ILookup such that the keys :cols and :rsmeta are supported and should map to the vector of column names that the builder will produce and the ResultSetMetaData object (which can be obtained from the ResultSet, if necessary). This is intended to allow plan and various builder adapters to access certain information that may be needed for processing results. The default builder implementations (for maps and arrays) are both records with fields rsmeta and cols (in addition to rs -- the ResultSet itself). The adapters provided in next.jdbc.result-set returned reified implementations that delegate field lookup to the underlying builder implementation. The options hash map for any next.jdbc function can contain a :builder-fn key and the value is used as the row/result set builder function. The tests for next.jdbc.result-set include a record-based builder function as an example of how you can extend this to satisfy your needs. Note: When next.jdbc cannot obtain a ResultSet object and returns {:next.jdbc/count N} instead, the builder function is not applied -- the :builder-fn option does not affect the shape of the result. The options hash map passed to the builder function will contain a :next.jdbc/sql-params key, whose value is the SQL + parameters vector passed into the top-level next.jdbc functions (plan, execute!, and execute-one!). There is also a convenience function, datafiable-result-set, that accepts a ResultSet object (and a connectable and an options hash map) and returns a fully realized result set, per the :builder-fn option (or as-maps if that option is omitted). The array-based builders warrant special mention: When used with execute!, the array-based builders will produce a data structure that is a vector of vectors, with the first element being a vector of column names and subsequent elements being vectors of column values in the same corresponding order. The order of column names and values follows the \"natural\" order from the SQL operation, as determined by the underlying ResultSet. When used with execute-one!, the array-based builders will produce a single vector containing the column values in the \"natural\" SQL order but you will not get the corresponding column names back. When used with plan, the array-based builders will cause each abstract row to represent a vector of column values rather than a hash map which limits the operations you can perform on the abstraction to just Associative (get with a numeric key), Counted (count), and Indexed (nth). All other operations will either realize a vector, as if by calling datafiable-row, or will fail if the operation does not make sense on a vector (as opposed to a hash map). next.jdbc.optional This namespace contains variants of the six as-maps-style builders above that omit keys from the row hash maps if the corresponding column is NULL. This is in keeping with Clojure's views of \"optionality\" -- that optional elements should simply be omitted -- and is provided as an \"opt-in\" style of rows and result sets. ReadableColumn As mentioned above, when with-column is called, the expectation is that the row builder will call .getObject on the current state of the ResultSet object with the column index and will then call read-column-by-index, passing the column value, the ResultSetMetaData, and the column index. That function is part of the ReadableColumn protocol that you can extend to handle conversion of arbitrary database-specific types to Clojure values. It is extensible via metadata so the value you return can have metadata specifying the implementation of read-column-by-index. If you need more control over how values are read from the ResultSet object, you can use next.jdbc.result-set/as-maps-adapter (or next.jdbc.result-set/as-arrays-adapter, or the more low-level but more generic next.jdbc.result-set/builder-adapter) which takes an existing builder function and a column reading function and returns a new builder function that calls your column reading function (with the ResultSet object, the ResultSetMetaData object, and the column index -- or the builder itself, the ResultSet object, and the column index in the case of builder-adapter) instead of calling .getObject directly. Note that the as-* adapters still call read-column-by-index on the value your column reading function returns. In addition, inside plan, as each value is looked up by name in the current state of the ResultSet object, the read-column-by-label function is called, again passing the column value and the column label (the name used in the SQL to identify that column). This function is also part of the ReadableColumn protocol. The default implementation of this protocol is for these two functions to return nil as nil, a Boolean value as a canonical true or false value (unfortunately, JDBC drivers cannot be relied on to return unique values here!), and for all other objects to be returned as-is. next.jdbc makes no assumptions beyond nil and Boolean, but common extensions here could include converting java.sql.Date to java.time.LocalDate and java.sql.Timestamp to java.time.Instant for example: (extend-protocol rs/ReadableColumn\n  java.sql.Date\n  (read-column-by-label [^java.sql.Date v _]\n    (.toLocalDate v))\n  (read-column-by-index [^java.sql.Date v _2 _3]\n    (.toLocalDate v))\n  java.sql.Timestamp\n  (read-column-by-label [^java.sql.Timestamp v _]\n    (.toInstant v))\n  (read-column-by-index [^java.sql.Timestamp v _2 _3]\n    (.toInstant v)))\n Remember that a protocol extension will apply to all code running in your application so with the above code all timestamp values coming from the database will be converted to java.time.Instant for all queries. If you want to control behavior across different calls, consider the adapters described above (as-maps-adapter, as-arrays-adapter, and builder-adapter, and think about using metadata to implement the rs/ReadableColumn protocol instead of extending it). Note that the converse, converting Clojure values to database-specific types is handled by the SettableParameter protocol, discussed in the next section (Prepared Statements). <: Tips & Tricks | Prepared Statements :>"}
  {:name "Prepared Statements",
   :path "/d/seancorfield/next.jdbc/1.2.659/doc/prepared-statements",
   :doc
   "Prepared Statements Under the hood, whenever you ask next.jdbc to execute some SQL (via plan, execute!, execute-one! or the \"friendly\" SQL functions) it calls prepare to create a java.sql.PreparedStatement, adds in the parameters you provide, and then calls .execute on it. Then it attempts to get a ResultSet from that and either return it or process it. If you asked for generated keys to be returned, that ResultSet will contain those generated keys if your database supports it, otherwise it will be whatever the .execute function produces. If no ResultSet is available at all, next.jdbc will ask for the count of updated rows and return that as if it were a result set. Note: Some databases do not support all SQL operations via PreparedStatement, in which case you may need to create a java.sql.Statement instead, via next.jdbc.prepare/statement, and pass that into plan, execute!, or execute-one!, along with the SQL you wish to execute. Note that such statement execution may not have parameters. See the Prepared Statement Caveat in Getting Started for an example. If you have a SQL operation that you intend to run multiple times on the same java.sql.Connection, it may be worth creating the prepared statement yourself and reusing it. next.jdbc/prepare accepts a connection and a vector of SQL and optional parameters and returns a java.sql.PreparedStatement which can be passed to plan, execute!, or execute-one! as the first argument. It is your responsibility to close the prepared statement after it has been used. If you need to pass an option map to plan, execute!, or execute-one! when passing a statement or prepared statement, you must pass nil or [] as the second argument: (with-open [con (jdbc/get-connection ds)]\n  (with-open [ps (jdbc/prepare con [\"...\" ...])]\n    (jdbc/execute-one! ps nil {...})))\n  (with-open [stmt (jdbc/statement con)]\n    (jdbc/execute-one! stmt nil {...})))\n You can provide the parameters in the prepare call or you can provide them via a call to set-parameters (discussed in more detail below). ;; assuming require next.jdbc.prepare :as p\n(with-open [con (jdbc/get-connection ds)\n            ps  (jdbc/prepare con [\"...\"])]\n  (jdbc/execute-one! (p/set-parameters ps [...])))\n Prepared Statement Parameters If parameters are provided in the vector along with the SQL statement, in the call to prepare, then set-parameter is behind the scenes called for each of them. This is part of the SettableParameter protocol: (set-parameter v ps i) -- by default this calls (.setObject ps i v) (for nil and Object) This can be extended to any Clojure data type, to provide a customized way to add specific types of values as parameters to any PreparedStatement. For example, to have all java.time.Instant, java.time.LocalDate and java.time.LocalDateTime objects converted to java.sql.Timestamp automatically: (extend-protocol p/SettableParameter\n  java.time.Instant\n  (set-parameter [^java.time.Instant v ^PreparedStatement ps ^long i]\n    (.setTimestamp ps i (java.sql.Timestamp/from v)))\n  java.time.LocalDate\n  (set-parameter [^java.time.LocalDate v ^PreparedStatement ps ^long i]\n    (.setTimestamp ps i (java.sql.Timestamp/valueOf (.atStartOfDay v))))\n  java.time.LocalDateTime\n  (set-parameter [^java.time.LocalDateTime v ^PreparedStatement ps ^long i]\n    (.setTimestamp ps i (java.sql.Timestamp/valueOf v))))\n Note: those conversions can also be enabled by requiring the next.jdbc.date-time namespace. You can also extend this protocol via metadata so you can do it on a per-object basis if you need: (with-meta obj {'next.jdbc.prepare/set-parameter (fn [v ps i]...)})\n The next.jdbc.types namespace provides functions to wrap values with per-object implementations of set-parameter for every standard java.sql.Types value. Each is named as-xxx corresponding to java.sql.Types/XXX. The converse, converting database-specific types to Clojure values is handled by the ReadableColumn protocol, discussed in the previous section (Result Set Builders). As noted above, next.jdbc.prepare/set-parameters is available for you to call on any existing PreparedStatement to set or update the parameters that will be used when the statement is executed: (set-parameters ps params) -- loops over a sequence of parameter values and calls set-parameter for each one, as above. If you need more specialized parameter handling than the protocol can provide, then you can create prepared statements explicitly, instead of letting next.jdbc do it for you, and then calling your own variant of set-parameters to install those parameters. Batched Parameters By default, next.jdbc assumes that you are providing a single set of parameter values and then executing the prepared statement. If you want to run a single prepared statement with multiple groups of parameters, you might want to take advantage of the increased performance that may come from using JDBC's batching machinery. You could do this manually: ;; assuming require next.jdbc.prepare :as p\n(with-open [con (jdbc/get-connection ds)\n            ps  (jdbc/prepare con [\"insert into status (id,name) values (?,?)\"])]\n  (p/set-parameters ps [1 \"Approved\"])\n  (.addBatch ps)\n  (p/set-parameters ps [2 \"Rejected\"])\n  (.addBatch ps)\n  (p/set-parameters ps [3 \"New\"])\n  (.addBatch ps)\n  (.executeBatch ps)) ; returns int[]\n Here we set parameters and add them in batches to the prepared statement, then we execute the prepared statement in batch mode. You could also do the above like this, assuming you have those groups of parameters in a sequence: (with-open [con (jdbc/get-connection ds)\n            ps  (jdbc/prepare con [\"insert into status (id,name) values (?,?)\"])]\n  (run! #(.addBatch (p/set-parameters ps %))\n        [[1 \"Approved\"] [2 \"Rejected\"] [3 \"New\"]])\n  (.executeBatch ps)) ; returns int[]\n Both of those are somewhat ugly and contain a fair bit of boilerplate and Java interop, so a helper function is provided in next.jdbc to automate the execution of batched parameters: (with-open [con (jdbc/get-connection ds)\n            ps  (jdbc/prepare con [\"insert into status (id,name) values (?,?)\"])]\n  (jdbc/execute-batch! ps [[1 \"Approved\"] [2 \"Rejected\"] [3 \"New\"]]))\n;; or:\n(jdbc/execute-batch! ds\n                     \"insert into status (id,name) values (?,?)\"\n                     [[1 \"Approved\"] [2 \"Rejected\"] [3 \"New\"]]\n                     ;; options hash map required here to disambiguate\n                     ;; this call from the 2- & 3-arity calls\n                     {})\n By default, this adds all the parameter groups and executes one batched command. It returns a (Clojure) vector of update counts (rather than int[]). If you provide an options hash map, you can specify a :batch-size and the parameter groups will be partitioned and executed as multiple batched commands. This is intended to allow very large sequences of parameter groups to be executed without running into limitations that may apply to a single batched command. If you expect the update counts to be very large (more than Integer/MAX_VALUE), you can specify :large true so that .executeLargeBatch is called instead of .executeBatch. Note: not all databases support .executeLargeBatch. If you want to get the generated keys from an insert done via execute-batch!, you need a couple of extras, compared to the above: (with-open [con (jdbc/get-connection ds)\n            ;; ensure the PreparedStatement will return the keys:\n            ps  (jdbc/prepare con [\"insert into status (id,name) values (?,?)\"]\n                              {:return-keys true})]\n  ;; this will call .getGeneratedKeys for each batch and return them as a\n  ;; vector of datafiable result sets (the keys in map are database-specific):\n  (jdbc/execute-batch! ps [[1 \"Approved\"] [2 \"Rejected\"] [3 \"New\"]]\n                       {:return-generated-keys true}))\n;; or:\n(jdbc/execute-batch! ds\n                     \"insert into status (id,name) values (?,?)\"\n                     [[1 \"Approved\"] [2 \"Rejected\"] [3 \"New\"]]\n                     {:return-keys true ; for creation of PreparedStatement\n                      :return-generated-keys true}) ; for batch result format\n This calls rs/datafiable-result-set behind the scenes so you can also pass a :builder-fn option to execute-batch! if you want something other than qualified as-is hash maps. Note: not all databases support calling .getGeneratedKeys here (everything I test against seems to, except MS SQL Server). Some databases will only return one generated key per batch, rather than a generated key for every row inserted. Caveats There are several caveats around using batched parameters. Some JDBC drivers need a \"hint\" in order to perform the batch operation as a single command for the database. In particular, PostgreSQL requires the :reWriteBatchedInserts true option and MySQL requires :rewriteBatchedStatements true (both non-standard JDBC options, of course!). These should be provided as part of the db-spec hash map when the datasource is created. In addition, if the batch operation fails for a group of parameters, it is database-specific whether the remaining groups of parameters are used, i.e., whether the operation is performed for any further groups of parameters after the one that failed. The result of calling execute-batch! is a vector of integers. Each element of the vector is the number of rows affected by the operation for each group of parameters. execute-batch! may throw a BatchUpdateException and calling .getUpdateCounts (or .getLargeUpdateCounts) on the exception may return an array containing a mix of update counts and error values (a Java int[] or long[]). Some databases don't always return an update count but instead a value indicating the number of rows is not known (but sometimes you can still get the update counts). Finally, some database drivers don't do batched operations at all -- they accept .executeBatch but they run the operation as separate commands for the database rather than a single batched command. <: Result Set Builders | Transactions :>"}
  {:name "Transactions",
   :path "/d/seancorfield/next.jdbc/1.2.659/doc/transactions",
   :doc
   "Transactions The transact function and with-transaction macro were briefly mentioned in the Getting Started section but we'll go into more detail here. Although (transact transactable f) is available, it is expected that you will mostly use (with-transaction [tx transactable] body...) when you want to execute multiple SQL operations in the context of a single transaction so that is what this section focuses on. Connection-level Control By default, all connections that next.jdbc creates are automatically committable, i.e., as each operation is performed, the effect is committed to the database directly before the next operation is performed. Any exceptions only cause the current operation to be aborted -- any prior operations have already been committed. It is possible to tell next.jdbc to create connections that do not automatically commit operations: pass {:auto-commit false} as part of the options map to anything that creates a connection (including get-connection itself). You can then decide when to commit or rollback by calling .commit or .rollback on the connection object itself. You can also create save points ((.setSavepoint con), (.setSavepoint con name)) and rollback to them ((.rollback con save-point)). You can also change the auto-commit state of an open connection at any time ((.setAutoCommit con on-off)). Automatic Commit & Rollback next.jdbc's transaction handling provides a convenient baseline for either committing a group of operations if they all succeed or rolling them all back if any of them fails, by throwing an exception. You can either do this on an existing connection -- and next.jdbc will try to restore the state of the connection after the transaction completes -- or by providing a datasource and letting with-transaction create and manage its own connection: (jdbc/with-transaction [tx my-datasource]\n  (jdbc/execute! tx ...)\n  (jdbc/execute! tx ...)) ; will commit, unless exception thrown\n\n(jdbc/with-transaction [tx my-datasource]\n  (jdbc/execute! tx ...)\n  (when ... (throw ...)) ; will rollback\n  (jdbc/execute! tx ...))\n If with-transaction is given a datasource, it will create and close the connection for you. If you pass in an existing connection, with-transaction will set up a transaction on that connection and, after either committing or rolling back the transaction, will restore the state of the connection and leave it open. You can also provide an options map as the third element of the binding vector (or the third argument to the transact function). The following options are supported: :isolation -- the isolation level for this transaction (see All The Options for specifics), :read-only -- set the transaction into read-only mode (if true), :rollback-only -- set the transaction to always rollback, even on success (if true). The latter can be particularly useful in tests, to run a series of SQL operations during a test and then roll them all back at the end. Manual Rollback Inside a Transaction Instead of throwing an exception (which will propagate through with-transaction and therefore provide no result), you can also explicitly rollback if you want to return a result in that case: (jdbc/with-transaction [tx my-datasource]\n  (let [result (jdbc/execute! tx ...)]\n    (if ...\n      (do\n        (.rollback tx)\n        result)\n      (jdbc/execute! tx ...))))\n Save Points Inside a Transaction In general, transactions are per-connection and do not nest in JDBC. If you nest calls to with-transaction using a DataSource argument (or a db-spec) then you will get separate connections inside each invocation and the transactions will be independent, as permitted by the isolation level. If you nest such calls passing a Connection instead, the inner call will commit (or rollback) all operations on that connection up to that point -- including any performed in the outer call, prior to entering the inner call. The outer call will then commit (or rollback) any additional operations within its scope. This will be confusing at best and most likely buggy behavior! See below for ways to exercise more control over this behavior. If you want the ability to selectively roll back certain groups of operations inside a transaction, you can use named or unnamed save points: (jdbc/with-transaction [tx my-datasource]\n  (let [result (jdbc/execute! tx ...) ; op A\n        sp1    (.setSavepoint tx)] ; unnamed save point\n\n    (jdbc/execute! tx ...) ; op B\n\n    (when ... (.rollback tx sp1)) ; just rolls back op B\n\n    (let [sp2 (.setSavepoint tx \"two\")] ; named save point\n\n      (jdbc/execute! tx ...) ; op C\n\n      (when ... (.rollback tx sp2))) ; just rolls back op C\n\n    result)) ; returns this and will commit op A\n    ;; (and ops B & C if they weren't rolled back above)\n Nesting Transactions As noted above, transactions do not nest in JDBC and next.jdbc's default behavior is to allow you to overlap transactions (i.e., nested calls to with-transaction) and assume you know what you are doing, although it would generally be buggy programming to do so. By contrast, clojure.java.jdbc allowed the nested calls but simply ignored the inner calls and behaved as it you had only the outermost, top-level transaction. That allowed for buggy programming too, in a different way, but could be convenient if you wanted to override any transaction behavior in called code, as you might wish to do with a test fixture that set up and rolled back a transaction at the top-level -- you would just silently lose the effects of any (nested) transactions in the code under test. next.jdbc provides a way to control the behavior via a public, dynamic Var: next.jdbc.transaction/*nested-tx* is initially set to :allow which allows nested calls but makes them overlap (as described above), (binding [next.jdbc.transaction/*nested-tx* :ignore] ...) provides the same behavior as clojure.java.jdbc where nested calls are essentially ignored and only the outermost transaction takes effect, (binding [next.jdbc.transaction/*nested-tx* :prohibit] ...) will cause any attempt to start a nested transaction to throw an exception instead; this could be a useful way to detect the potentially buggy behavior described above (for either :allow or :ignore). <: Prepared Statements | All The Options :>"}
  {:name "All The Options",
   :path "/d/seancorfield/next.jdbc/1.2.659/doc/all-the-options",
   :doc
   "next.jdbc Options This section documents all of the options that are supported by all of the functions in next.jdbc. Nearly every function accepts an optional hash map as the last argument, that can control many of the behaviors of the library. The most general options are described first, followed by more specific options that apply only to certain functions. Datasources and Connections Although get-datasource does not accept options, the \"db spec\" hash map passed in may contain the following options: :dbtype -- a string that identifies the type of JDBC database being used, :dbname -- a string that identifies the name of the actual database being used, :dbname-separator -- an optional string that can be used to override the / or : that is normally placed in front of the database name in the JDBC URL, :host -- an optional string that identifies the IP address or hostname of the server on which the database is running; the default is \"127.0.0.1\"; if :none is specified, next.jdbc will assume this is for a local database and will omit the host/port segment of the JDBC URL, :host-prefix -- an optional string that can be used to override the // that is normally placed in front of the IP address or hostname in the JDBC URL, :port -- an optional integer that identifies the port on which the database is running; for common database types, next.jdbc knows the default so this should only be needed for non-standard setups or \"exotic\" database types, :classname -- an optional string that identifies the name of the JDBC driver class to be used for the connection; for common database types, next.jdbc knows the default so this should only be needed for \"exotic\" database types, :user -- an optional string that identifies the database username to be used when authenticating, :password -- an optional string that identifies the database password to be used when authenticating. Any additional keys provided in the \"db spec\" will be passed to the JDBC driver as Properties when each connection is made. Alternatively, when used with next.jdbc.connection/->pool, additional keys correspond to setters called on the pooled connection object. If you are using HikariCP and next.jdbc.connection/->pool to create a connection pooled datasource, you need to provide :username for the database username (instead of, or as well as, :user). Any path that calls get-connection will accept the following options: :auto-commit -- a Boolean that determines whether operations on this connection should be automatically committed (the default, true) or not; note that setting :auto-commit false is commonly required when you want to stream result set data from a query (along with fetch size etc -- see below), :read-only -- a Boolean that determines whether the operations on this connection should be read-only or not (the default, false). :connection -- a hash map of camelCase properties to set on the Connection object after it is created; these correspond to .set* methods on the Connection class and are set via the Java reflection API (using org.clojure/java.data). If :autoCommit or :readOnly are provided, they will take precedence over the fast, specific options above. If you need additional options set on a connection, you can either use Java interop to set them directly, or provide them as part of the \"db spec\" hash map passed to get-datasource (although then they will apply to all connections obtained from that datasource). Note: If plan, execute!, or execute-one! are passed a DataSource, a \"db spec\" hash map, or a JDBC URL string, they will call get-connection, so they will accept the above options in those cases. Generating SQL Except for query (which is simply an alias for execute!), all the \"friendly\" SQL functions accept the following options (in addition to all the options that plan, execute!, and execute-one! can accept): :table-fn -- the quoting function to be used on the string that identifies the table name, if provided, :column-fn -- the quoting function to be used on any string that identifies a column name, if provided. They also support a :suffix argument which can be used to specify a SQL string that should be appended to the generated SQL string before executing it, e.g., :suffix \"FOR UPDATE\". In addition, find-by-keys accepts the following options (see its docstring for more details): :columns -- specify one or more columns to SELECT to override selecting all columns, :order-by -- specify one or more columns, on which to sort the results, :top / :limit / :offset / :fetch to support pagination of results. In the simple case, the :columns option expects a vector of keywords and each will be processed according to :column-fn, if provided. A column alias can be specified using a vector pair of keywords and both will be processed according to :column-fn, e.g., [:foo [:bar :quux]] would expand to foo, bar AS quux. You can also specify the first element of the pair as a string which will be used as-is in the generated SQL, e.g., [:foo [\"COUNT(*)\" :total]] would expand to foo, COUNT(*) AS total. In the latter case, the alias keyword will still be processed according to :column-fn but the string will be untouched -- you are responsible for any quoting and/or other formatting that might be required to produce a valid SQL expression. Note: get-by-id accepts the same options as find-by-keys but it will only ever produce one row, as a hash map, so sort order and pagination are less applicable, although :columns may be useful. Generating Rows and Result Sets Any function that might realize a row or a result set will accept: :builder-fn -- a function that implements the RowBuilder and ResultSetBuilder protocols; strictly speaking, plan and execute-one! only need RowBuilder to be implemented (and plan only needs that if it actually has to realize a row) but most generation functions will implement both for ease of use. :label-fn -- if :builder-fn is specified as one of next.jdbc.result-set's as-modified-* builders, this option must be present and should specify a string-to-string transformation that will be applied to the column label for each returned column name. :qualifier-fn -- if :builder-fn is specified as one of next.jdbc.result-set's as-modified-* builders, this option should specify a string-to-string transformation that will be applied to the table name for each returned column name. It will be called with an empty string if the table name is not available. It can be omitted for the as-unqualified-modified-* variants. In addition, execute! accepts the :multi-rs true option to return multiple result sets -- as a vector of result sets. Note: Subject to the caveats above about :builder-fn, that means that plan, execute!, execute-one!, and the \"friendly\" SQL functions will all accept these options for generating rows and result sets. Statements & Prepared Statements Any function that creates a Statement or a PreparedStatement will accept the following options (see below for additional options for PreparedStatement): :concurrency -- a keyword that specifies the concurrency level: :read-only, :updatable, :cursors -- a keyword that specifies whether cursors should be closed or held over a commit: :close, :hold, :fetch-size -- an integer that guides the JDBC driver in terms of how many rows to fetch at once; the actual behavior of specifying :fetch-size is database-specific: some JDBC drivers use a zero or negative value here to trigger streaming of result sets -- other JDBC drivers require this to be positive for streaming and may require additional options to be set on the connection as well, :max-rows -- an integer that tells the JDBC driver to limit result sets to this many rows, :result-type -- a keyword that affects how the ResultSet can be traversed: :forward-only, :scroll-insensitive, :scroll-sensitive, :timeout -- an integer that specifies the (query) timeout allowed for SQL operations, in seconds. See Handling Timeouts in Tips & Tricks for more details on this and other possible timeout settings. :statement -- a hash map of camelCase properties to set on the Statement or PreparedStatement object after it is created; these correspond to .set* methods on the Statement class (which PreparedStatement inherits) and are set via the Java reflection API (using org.clojure/java.data). If :fetchSize, :maxRows, or :queryTimeout are provided, they will take precedence over the fast, specific options above. If you specify either :concurrency or :result-type, you must specify both of them. If you specify :cursors, you must also specify :result-type and :concurrency. Note: For MS SQL Server to return table names (for qualified column names), you must specify :result-type with one of the scroll values (and so you must also specify :concurrency). Any function that creates a PreparedStatement will additionally accept the following options: :return-keys -- a truthy value asks that the JDBC driver to return any generated keys created by the operation; it can be true or it can be a vector of keywords identifying column names that should be returned. Not all databases or drivers support all of these options, or all values for any given option. If :return-keys is a vector of column names and that is not supported, next.jdbc will attempt a generic \"return generated keys\" option instead. If that is not supported, next.jdbc will fall back to a regular SQL operation. If other options are not supported, you may get a SQLException. Note: If plan, execute!, or execute-one! are passed a DataSource, a \"db spec\" hash map, or a JDBC URL string, they will call prepare to create a PreparedStatement, so they will accept the above options in those cases. In addition to the above, next.jdbc/execute-batch! (which may create a PreparedStatement if you pass in a SQL string and either a Connection or DataSource) accepts an options hash map that can also contain the following: :batch-size -- an integer that determines how to partition the parameter groups for submitting to the database in batches, :large -- a Boolean flag that indicates whether the batch will produce large update counts (long rather than int values), :return-generated-keys -- a Boolean flag that indicates whether .getGeneratedKeys should be called on the PreparedStatement after each batch is executed (if true, execute-batch! will return a vector of hash maps containing generated keys). Transactions The transact function and with-transaction macro accept the following options: :isolation -- a keyword that identifies the isolation to be used for this transaction: :none, :read-committed, :read-uncommitted, :repeatedable-read, or :serializable; these represent increasingly strict levels of transaction isolation and may not all be available depending on the database and/or JDBC driver being used, :read-only -- a Boolean that indicates whether the transaction should be read-only or not (the default), :rollback-only -- a Boolean that indicates whether the transaction should commit on success (the default) or rollback. Plan Selection The next.jdbc.plan/select! function accepts the following specific option: :into -- a data structure into which the selected result from a plan operation are poured; by default this is []; could be any value that is acceptable as the first argument to into, subject to into accepting the sequence of values produced by the plan reduction. <: Transactions | datafy, nav, and :schema :>"}
  {:name "datafy, nav, and :schema",
   :path "/d/seancorfield/next.jdbc/1.2.659/doc/datafy-nav-and-schema",
   :doc
   "datafy, nav, and the :schema option Clojure 1.10 introduced a new namespace, clojure.datafy, and two new protocols (Datafiable and Navigable) that allow for generalized, lazy navigation around data structures. Cognitect also released REBL -- a graphical, interactive tool for browsing Clojure data structures, based on the new datafy and nav functions. Shortly after REBL's release, I added experimental support to clojure.java.jdbc for datafy and nav that supported lazy navigation through result sets into foreign key relationships and connected rows and tables. next.jdbc bakes that support into result sets produced by execute! and execute-one!. In addition to datafy and nav support in the result sets, as of version 1.0.462, there is a next.jdbc.datafy namespace that can be required to extend these protocols to a number of JDBC object types. See JDBC Datafication near the end of this page for more detail of this. The datafy/nav Lifecycle on Result Sets Here's how the process works, for result sets produced by next.jdbc: execute! and execute-one! produce result sets containing rows that are Datafiable, Tools like REBL can call datafy on result sets to render them as \"pure data\" (which they already are, but this makes them also Navigable), Tools like REBL allow users to \"drill down\" into elements of rows in the \"pure data\" result set, using nav, If a column in a row represents a foreign key into another table, calling nav will fetch the related row(s), Those can in turn be datafy'd and nav'd to continue drilling down through connected data in the database. In addition to execute! and execute-one!, you can call next.jdbc.result-set/datafiable-result-set on any ResultSet object to produce a result set whose rows are Datafiable. Inside a reduction over the result of plan, you can call next.jdbc.result-set/datafiable-row on a row to produce a Datafiable row. That will realize the entire row, including generating column names using the row builder specified (or as-maps by default). Identifying Foreign Keys By default, next.jdbc assumes that a column named <something>id or <something>_id is a foreign key into a table called <something> with a primary key called id. As an example, if you have a table address which has columns id (the primary key), name, email, etc, and a table contact which has various columns including addressid, then if you retrieve a result set based on contact, call datafy on it and then \"drill down\" into the columns, when (nav row :contact/addressid v) is called (where v is the value of that column in that row) next.jdbc's implementation of nav will fetch a single row from the address table, identified by id matching v. You can override this default behavior for any column in any table by providing a :schema option that is a hash map whose keys are column names (usually the table-qualified keywords that next.jdbc produces by default) and whose values are table-qualified keywords, optionally wrapped in vectors, that identity the name of the table to which that column is a foreign key and the name of the key column within that table. The default behavior in the example above is equivalent to this :schema value: (jdbc/execute! ds\n               [\"select * from contact where city = ?\" \"San Francisco\"]\n               ;; a one-to-one or many-to-one relationship\n               {:schema {:contact/addressid :address/id}})\n If you had a table to track the valid/bouncing status of email addresses over time, :deliverability, where email is the non-unique key, you could provide automatic navigation into that using: (jdbc/execute! ds\n               [\"select * from contact where city = ?\" \"San Francisco\"]\n               ;; one-to-many or many-to-many\n               {:schema {:contact/addressid :address/id\n                         :address/email [:deliverability/email]}})\n When you indicate a *-to-many relationship, by wrapping the foreign table/key in a vector, next.jdbc's implementation of nav will fetch a multi-row result set from the target table. If you use foreign key constraints in your database, you could probably generate this :schema data structure automatically from the metadata in your database. Similarly, if you use a library that depends on an entity relationship map (such as seql or walkable), then you could probably generate this :schema data structure from that entity map. Behind The Scenes Making rows datafiable is implemented by adding metadata to each row with a key of clojure.core.protocols/datafy and a function as the value. That function closes over the connectable and options passed in to the execute! or execute-one! call that produced the result set containing those rows. When called (datafy on a row), it adds metadata to the row with a key of clojure.core.protocols/nav and another function as the value. That function also closes over the connectable and options passed in. When that is called (nav on a row, column name, and column value), if a :schema entry exists for that column or it matches the default convention described above, then it will fetch row(s) using next.jdbc's Executable functions -execute-one or -execute-all, passing in the connectable and options closed over. The protocol next.jdbc.result-set/DatafiableRow has a default implementation of datafiable-row for clojure.lang.IObj that just adds the metadata to support datafy. There is also an implementation baked into the result set handling behind plan so that you can call datafiable-row directly during reduction and get a fully-realized row that can be datafy'd (and then navigated). In addition, you can call next.jdbc.result-set/datafiable-result-set on any ResultSet object and get a fully realized, datafiable result set created using any of the result set builders. JDBC Datafication If you require next.jdbc.datafy, the Datafiable protocol is extended to several JDBC object types, so that calling datafy will turn them into hash maps according to Java Bean introspection, similar to clojure.core/bean although next.jdbc uses clojure.java.data/from-java-shallow (from org.clojure/java.data), with some additions as described below. java.sql.Connection -- datafies as a bean; The :metaData property is a java.sql.DatabaseMetaData, which is also datafiable. DatabaseMetaData -- datafies as a bean, with an additional :all-tables property (that is a dummy object); six properties are navigable to produce fully-realized datafiable result sets: all-tables -- produced from (.getTables this nil nil nil nil), this is all the tables and views available from the connection that produced the database metadata, catalogs -- produced from (.getCatalogs this) clientInfoProperties -- all the client properties that the database driver supports, schemas -- produced from (.getSchemas this), tableTypes -- produced from (.getTableTypes this), typeInfo -- produced from (.getTypeInfo this). ParameterMetaData -- datafies as a vector of parameter descriptions; each parameter hash map has: :class (the name of the parameter class -- JVM), :mode (one of :in, :in-out, or :out), :nullability (one of: :null, :not-null, or :unknown), :precision, :scale, :type (the name of the parameter type -- SQL), and :signed (Boolean). ResultSet -- datafies as a bean; if the ResultSet has an associated Statement and that in turn has an associated Connection then an additional key of :rows is provided which is a datafied result set, from next.jdbc.result-set/datafiable-result-set with default options. This is provided as a convenience, purely for datafication of other JDBC data types -- in normal next.jdbc usage, result sets are datafied under full user control. ResultSetMetaData -- datafies as a vector of column descriptions; each column hash map has: :auto-increment, :case-sensitive, :catalog, :class (the name of the column class -- JVM), :currency (Boolean), :definitely-writable, :display-size, :label, :name, :nullability, :precision, :read-only, :searchable, :signed, :scale, :schema, :table, :type, and :writable. Statement -- datafies as a bean. See the Java documentation for these JDBC types for further details on what all the properties from each of these classes mean and which are int, String, or some other JDBC object type. In addition, requiring this namespace will affect how next.jdbc.result-set/metadata behaves inside the reducing function applied to the result of plan. Without this namespace loaded, that function will return a raw ResultSetMetaData object (which must not leak outside the reducing function). With this namespace loaded, that function will, instead, return a Clojure data structure describing the columns in the result set. <: All The Options | Migration from clojure.java.jdbc :>"}
  {:name "Migration from clojure.java.jdbc",
   :path
   "/d/seancorfield/next.jdbc/1.2.659/doc/migration-from-clojure-java-jdbc",
   :doc
   "Migrating from clojure.java.jdbc This page attempts to list all of the differences between clojure.java.jdbc and next.jdbc. Some of them are large and obvious, some of them are small and subtle -- all of them are deliberate design choices. Conceptually clojure.java.jdbc focuses heavily on a db-spec hash map to describe the various ways of interacting with the database and grew from very imperative origins that expose a lot of the JDBC API (multiple types of SQL execution, some operations returned hash maps, others update counts as integers, etc). next.jdbc focuses on using protocols and native Java JDBC types where possible (for performance and simplicity) and strives to present a more modern Clojure API with namespace-qualified keywords in hash maps, reducible SQL operations as part of the primary API, and a streamlined set of SQL execution primitives. Execution always returns a hash map (for one result) or a vector of hash maps (for multiple results) -- even update counts are returned as if they were result sets. Rows and Result Sets clojure.java.jdbc returned result sets (and generated keys) as hash maps with simple, lower-case keys by default. next.jdbc returns result sets (and generated keys) as hash maps with qualified, as-is keys by default: each key is qualified by the name of table from which it is drawn, if known. The as-is default is chosen to a) improve performance and b) not mess with the data. Using a :builder-fn option of next.jdbc.result-set/as-unqualified-maps will produce simple, as-is keys. Using a :builder-fn option of next.jdbc.result-set/as-unqualified-lower-maps will produce simple, lower-case keys -- the most compatible with clojure.java.jdbc's default behavior. Note: clojure.java.jdbc would make column names unique by appending numeric suffixes, for example in a JOIN that produced columns id from multiple tables. next.jdbc does not do this: if you use qualified column names -- the default -- then you would get :sometable/id and :othertable/id, but with unqualified column names you would just get one :id in each row. It was always poor practice to rely on clojure.java.jdbc's renaming behavior and it added quite an overhead to result set building, which is why next.jdbc does not support it -- use explicit column aliasing in your SQL instead if you want unqualified column names! If you used :as-arrays? true, you will most likely want to use a :builder-fn option of next.jdbc.result-set/as-unqualified-lower-arrays. Note: When next.jdbc cannot obtain a ResultSet object and returns {:next.jdbc/count N} instead, these builder functions are not applied -- the :builder-fn option is not used in that situation. Option Handling Because clojure.java.jdbc focuses on a hash map for the db-spec that is passed around, it can hold options that act as defaults for all operations on it. In addition, all operations in clojure.java.jdbc can accept a hash map of options and can pass those options down the call chain. In next.jdbc, get-datasource, get-connection, and prepare all produce Java objects that cannot have any extra options attached. On one hand, that means that it is harder to provide \"default options\", and on the other hand it means you need to be a bit more careful to ensure that you pass the appropriate options to the appropriate function, since they cannot be passed through the call chain via the db-spec. That's where next.jdbc/with-options can come in handy to wrap a connectable (generally a datasource or a connection) but be careful where you are managing connections and/or transactions directly, as mentioned in the Getting Started guide. In All The Options, the appropriate options are shown for each function, as well as which options will get passed down the call chain, e.g., if a function can open a connection, it will accept options for get-connection; if a function can build a result set, it will accept :builder-fn. However, get-datasource, get-connection, and prepare cannot propagate options any further because they produce Java objects as their results -- in particular, prepare can't accept :builder-fn because it doesn't build result sets: only plan, execute-one!, and execute! can use :builder-fn. In particular, this means that you can't globally override the default options (as you could with clojure.java.jdbc by adding your preferred defaults to the db-spec itself). If the default options do not suit your usage and you really don't want to override them in every call, it is recommended that you try to use next.jdbc/with-options first, and if that still doesn't satisfy you, write a wrapper namespace that implements the subset of the dozen API functions (from next.jdbc and next.jdbc.sql) that you want to use, overriding their opts argument with your defaults. Primary API next.jdbc has a deliberately narrow primary API that has (almost) no direct overlap with clojure.java.jdbc: get-datasource -- has no equivalent in clojure.java.jdbc but is intended to emphasize javax.sql.DataSource as a starting point, get-connection -- overlaps with clojure.java.jdbc (and returns a java.sql.Connection) but accepts only a subset of the options (:dbtype/:dbname hash map, String JDBC URL); clojure.java.jdbc/get-connection accepts {:datasource ds} whereas next.jdbc/get-connection accepts the javax.sql.DataSource object directly, prepare -- somewhat similar to clojure.java.jdbc/prepare-statement but it accepts a vector of SQL and parameters (compared to just a raw SQL string), plan -- somewhat similar to clojure.java.jdbc/reducible-query but accepts arbitrary SQL statements for execution, execute! -- has no direct equivalent in clojure.java.jdbc (but it can replace most uses of both query and db-do-commands), execute-one! -- has no equivalent in clojure.java.jdbc (but it can replace most uses of query that currently use :result-set-fn first), transact -- similar to clojure.java.jdbc/db-transaction*, with-transaction -- similar to clojure.java.jdbc/with-db-transaction, with-options -- provides a way to specify \"default options\" over a group of operations, by wrapping the connectable (datasource or connection). If you were using a bare db-spec hash map with :dbtype/:dbname, or a JDBC URL string everywhere, that should mostly work with next.jdbc since most functions accept a \"connectable\", but it would be better to create a datasource first, and then pass that around. Note that clojure.java.jdbc allowed the jdbc: prefix in a JDBC URL to be omitted but next.jdbc requires that prefix! If you were already creating db-spec as a pooled connection datasource -- a {:datasource ds} hashmap -- then passing (:datasource db-spec) to the next.jdbc functions is the simplest migration path. If you are migrating piecemeal and want to support both clojure.java.jdbc and next.jdbc at the same time in your code, you should consider using a datasource as the common way to work with both libraries. You can using next.jdbc's get-datasource or the ->pool function (in next.jdbc.connection) to create the a javax.sql.DataSource and then build a db-spec hash map with it ({:datasource ds}) and pass that around your program. clojure.java.jdbc calls can use that as-is, next.jdbc calls can use (:datasource db-spec), so you don't have to adjust any of your call chains (assuming you're passing db-spec around) and you can migrate one function at a time. If you were using other forms of the db-spec hash map, you'll need to adjust to one of the three modes above, since those are the only ones supported in next.jdbc. The next.jdbc.sql namespace contains several functions with similarities to clojure.java.jdbc's core API: insert! -- similar to clojure.java.jdbc/insert! but only supports inserting a single map, insert-multi! -- similar to clojure.java.jdbc/insert-multi! but only supports inserting columns and a vector of row values, query -- similar to clojure.java.jdbc/query, find-by-keys -- similar to clojure.java.jdbc/find-by-keys but will also accept a partial where clause (vector) instead of a hash map of column name/value pairs, get-by-id -- similar to clojure.java.jdbc/get-by-id, update! -- similar to clojure.java.jdbc/update! but will also accept a hash map of column name/value pairs instead of a partial where clause (vector), delete! -- similar to clojure.java.jdbc/delete! but will also accept a hash map of column name/value pairs instead of a partial where clause (vector). If you were using db-do-commands in clojure.java.jdbc to execute DDL, the following is the equivalent in next.jdbc: (defn do-commands [connectable commands]\n  (if (instance? java.sql.Connection connectable)\n    (with-open [stmt (next.jdbc.prepare/statement connectable)]\n      (run! #(.addBatch stmt %) commands)\n      (into [] (.executeBatch stmt)))\n    (with-open [conn (next.jdbc/get-connection connectable)]\n      (do-commands conn commands))))\n :identifiers and :qualifier If you are using :identifiers, you will need to change to the appropriate :builder-fn option with one of next.jdbc.result-set's as-* functions. clojure.java.jdbc's default is the equivalent of as-unqualified-lower-maps (with the caveat that conflicting column names are not made unique -- see the note above in Rows and Result Sets). If you specified :identifiers identity, you can use as-unqualified-maps. If you provided your own string transformation function, you probably want as-unqualified-modified-maps and also pass your transformation function as the :label-fn option. If you used :qualifier, you can get the same effect with as-modified-maps by passing :qualifier-fn (constantly \"my_qualifier\") (and the appropriate :label-fn -- either identity or clojure.string/lowercase). :entities If you are using :entities, you will need to change to the appropriate :table-fn/:column-fn options. Table naming and column naming can be controlled separately in next.jdbc. Instead of the quoted function, there is the next.jdbc.quoted namespace which contains functions for the common quoting strategies. :result-set-fn and :row-fn If you are using :result-set-fn and/or :row-fn, you will need to change to explicit calls (to the result set function, or to map the row function), or to use the plan approach with reduce or various transducing functions. Note: this means that result sets are never exposed lazily in next.jdbc -- in clojure.java.jdbc you had to be careful that your :result-set-fn was eager, but in next.jdbc you either reduce the result set eagerly (via plan) or you get a fully-realized result set data structure back (from execute! and execute-one!). As with clojure.java.jdbc however, you can still stream result sets from the database and process them via reduction (was reducible-query, now plan). Remember that you can terminate a reduction early by using the reduced function to wrap the final value you produce. Processing Database Metadata There are no metadata-specific functions in next.jdbc but those in clojure.java.jdbc are only a very thin layer over the raw Java calls. Here's how metadata can be handled in next.jdbc: (with-open [con (p/get-connection ds opts)]\n  (-> (.getMetaData con) ; produces java.sql.DatabaseMetaData\n      (.getTables nil nil nil (into-array [\"TABLE\" \"VIEW\"]))\n      (rs/datafiable-result-set ds opts)))\n Several methods on DatabaseMetaData return a ResultSet object. All of those can be handled similarly. Further Minor differences These are mostly drawn from Issue #5 although most of the bullets in that issue are described in more detail above. Keyword options no longer end in ? -- for consistency (in clojure.java.jdbc, some flag options ended in ? and some did not; also some options that ended in ? accepted non-Boolean values, e.g., :as-arrays? and :explain?), with-db-connection has been replaced by just with-open containing a call to get-connection, with-transaction can take a :rollback-only option, but there is no built-in way to change a transaction to rollback dynamically; either throw an exception (all transactions roll back on an exception) or call .rollback directly on the java.sql.Connection object (see Manual Rollback Inside a Transactions and the following section about save points), clojure.java.jdbc implicitly allowed transactions to nest and just silently ignored the inner, nested transactions (so you only really had the top-level, outermost transaction); next.jdbc by default assumes you know what you are doing and so an inner (nested) transaction will commit or rollback the work done so far in outer transaction (and then when that outer transaction ends, the remaining work is rolled back or committed); next.jdbc.transaction/*nested-tx* is a dynamic var that can be bound to :ignore to get the same behavior as clojure.java.jdbc. The extension points for setting parameters and reading columns are now SettableParameter and ReadableColumn protocols. <: datafy, nav, and :schema"}]}
